{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "748bc13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\biz\\anaconda3\\envs\\goemotions\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91f80546",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"../data/test.tsv\", sep=\"\\t\", encoding = \"utf-8\", header=None)\n",
    "\n",
    "test_df.columns = ['text', 'emotions', 'id']\n",
    "\n",
    "test_df['emotions'] = list(map(lambda s : list(map(int, s.split(','))), test_df['emotions']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64f567ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotions_to_categorical(df):\n",
    "    ems = \"\"\"\n",
    "        admiration\n",
    "        amusement\n",
    "        anger\n",
    "        annoyance\n",
    "        approval\n",
    "        caring\n",
    "        confusion\n",
    "        curiosity\n",
    "        desire\n",
    "        disappointment\n",
    "        disapproval\n",
    "        disgust\n",
    "        embarrassment\n",
    "        excitement\n",
    "        fear\n",
    "        gratitude\n",
    "        grief\n",
    "        joy\n",
    "        love\n",
    "        nervousness\n",
    "        optimism\n",
    "        pride\n",
    "        realization\n",
    "        relief\n",
    "        remorse\n",
    "        sadness\n",
    "        surprise\n",
    "        neutral\n",
    "    \"\"\"\n",
    "    res = []\n",
    "\n",
    "    for i in df['emotions']:\n",
    "        tmp = [0 for _ in range(28)]\n",
    "        for j in i:\n",
    "            tmp[j] = 1\n",
    "        res.append(tmp)\n",
    "    tmp_df = pd.DataFrame(res, columns=ems.split())\n",
    "    \n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc91be68",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([test_df, emotions_to_categorical(test_df)], axis=1)\n",
    "\n",
    "test_df = test_df.drop(columns=['emotions', 'id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd8d7036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델 및 토크나이저 불러오기\n",
    "load_directory = \"./model_saved_bert_base\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(load_directory)\n",
    "tokenizer = AutoTokenizer.from_pretrained(load_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cce079b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9affcdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ems = \"\"\"\n",
    "        admiration\n",
    "        amusement\n",
    "        anger\n",
    "        annoyance\n",
    "        approval\n",
    "        caring\n",
    "        confusion\n",
    "        curiosity\n",
    "        desire\n",
    "        disappointment\n",
    "        disapproval\n",
    "        disgust\n",
    "        embarrassment\n",
    "        excitement\n",
    "        fear\n",
    "        gratitude\n",
    "        grief\n",
    "        joy\n",
    "        love\n",
    "        nervousness\n",
    "        optimism\n",
    "        pride\n",
    "        realization\n",
    "        relief\n",
    "        remorse\n",
    "        sadness\n",
    "        surprise\n",
    "        neutral\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9141b169",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.data.loc[index, 'text'])\n",
    "        labels = self.data.loc[index, ems.split()].values\n",
    "        labels = labels.astype('float32')\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(labels, dtype=torch.float)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1acd1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "test_dataset = EmotionDataset(test_df, tokenizer, MAX_LEN)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3478fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device, emotion_names = ['angry', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'neutral']):\n",
    "    \"\"\"\n",
    "    다중 라벨 분류 모델을 평가하는 통합 함수.\n",
    "    정확도, F1-점수를 계산하고, 각 라벨에 대한 개별 Precision-Recall 곡선을 그립니다.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to (device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            probs = torch.sigmoid(logits)\n",
    "            predictions = (probs > 0.5).int()\n",
    "\n",
    "            all_predictions.append(predictions.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "            \n",
    "\n",
    "    all_predictions = np.vstack(all_predictions)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    all_probs = np.vstack(all_probs)\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    \n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_predictions, average='micro'\n",
    "    )\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_predictions, average='macro'\n",
    "    )\n",
    "    \n",
    "    precision_per_label, recall_per_label, f1_per_label, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_predictions, average=None\n",
    "    )\n",
    "\n",
    "    precision_macro_std = np.std(precision_per_label)\n",
    "    recall_macro_std = np.std(recall_per_label)\n",
    "    f1_macro_std = np.std(f1_per_label)\n",
    "\n",
    "    print(\"--- 모델 평가 결과 ---\")\n",
    "    print(f\"전체 샘플에 대한 정확도 (Exact Match Accuracy): {accuracy:.4f}\")\n",
    "    print(\"\\n--- Micro 평균 지표 ---\")\n",
    "    print(f\"Precision (Micro): {precision_micro:.4f}\")\n",
    "    print(f\"Recall (Micro): {recall_micro:.4f}\")\n",
    "    print(f\"F1-Score (Micro): {f1_micro:.4f}\")\n",
    "    print(\"\\n--- Macro 평균 지표 ---\")\n",
    "    print(f\"Precision (Macro): {precision_macro:.4f}\")\n",
    "    print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
    "    print(f\"F1-Score (Macro): {f1_macro:.4f}\")\n",
    "    \n",
    "    print(\"\\n--- 라벨별 지표 ---\")\n",
    "    for i in range(len(emotion_names)):\n",
    "        print(f\"{emotion_names[i]} - Precision: {precision_per_label[i]:.4f}, Recall: {recall_per_label[i]:.4f}, F1-Score: {f1_per_label[i]:.4f}\")\n",
    "    \n",
    "    print(f\"\\nPrecision (Macro) 표준편차: {precision_macro_std:.4f}\")\n",
    "    print(f\"Recall (Macro) 표준편차: {recall_macro_std:.4f}\")\n",
    "    print(f\"F1-Score (Macro) 표준편차: {f1_macro_std:.4f}\")\n",
    "    \n",
    "    # 각 감정별 Precision-Recall 곡선 그리기\n",
    "    n_classes = all_labels.shape[1]\n",
    "    for i in range(n_classes):\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        \n",
    "        precision_curve, recall_curve, _ = precision_recall_curve(all_labels[:, i], all_probs[:, i])\n",
    "        \n",
    "        plt.plot(recall_curve, precision_curve, label=f'{emotion_names[i]}')\n",
    "        plt.plot([0, 1], [1, 0], linestyle='--', color='gray')\n",
    "        plt.xlabel('재현율 (Recall)')\n",
    "        plt.ylabel('정밀도 (Precision)')\n",
    "        plt.title(f'정밀도-재현율 곡선: {emotion_names[i]}')\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    return accuracy, f1_micro, f1_macro\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db7d5d99",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "inconsistent shapes",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m accuracy, f1_micro, f1_macro \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 32\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, test_loader, device, emotion_names)\u001b[0m\n\u001b[0;32m     29\u001b[0m all_labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(all_labels)\n\u001b[0;32m     30\u001b[0m all_probs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(all_probs)\n\u001b[1;32m---> 32\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_predictions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m precision_micro, recall_micro, f1_micro, _ \u001b[38;5;241m=\u001b[39m precision_recall_fscore_support(\n\u001b[0;32m     35\u001b[0m     all_labels, all_predictions, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmicro\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     36\u001b[0m )\n\u001b[0;32m     37\u001b[0m precision_macro, recall_macro, f1_macro, _ \u001b[38;5;241m=\u001b[39m precision_recall_fscore_support(\n\u001b[0;32m     38\u001b[0m     all_labels, all_predictions, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     39\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\biz\\anaconda3\\envs\\goemotions\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    214\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    215\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    216\u001b[0m         )\n\u001b[0;32m    217\u001b[0m     ):\n\u001b[1;32m--> 218\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    224\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    227\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    228\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\biz\\anaconda3\\envs\\goemotions\\lib\\site-packages\\sklearn\\metrics\\_classification.py:363\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    360\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 363\u001b[0m     differing_labels \u001b[38;5;241m=\u001b[39m _count_nonzero(\u001b[43my_true\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m, xp\u001b[38;5;241m=\u001b[39mxp, device\u001b[38;5;241m=\u001b[39mdevice, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    364\u001b[0m     score \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39masarray(differing_labels \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\biz\\anaconda3\\envs\\goemotions\\lib\\site-packages\\scipy\\sparse\\_base.py:577\u001b[0m, in \u001b[0;36m_spbase.__sub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m issparse(other):\n\u001b[0;32m    576\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape:\n\u001b[1;32m--> 577\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent shapes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sub_sparse(other)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m isdense(other):\n",
      "\u001b[1;31mValueError\u001b[0m: inconsistent shapes"
     ]
    }
   ],
   "source": [
    "accuracy, f1_micro, f1_macro = evaluate_model(model, test_loader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goemotions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
