{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "748bc13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\biz\\anaconda3\\envs\\goemotions\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91f80546",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"../data/test.tsv\", sep=\"\\t\", encoding = \"utf-8\", header=None)\n",
    "\n",
    "test_df.columns = ['text', 'emotions', 'id']\n",
    "\n",
    "test_df['emotions'] = list(map(lambda s : list(map(int, s.split(','))), test_df['emotions']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f567ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotions_to_categorical(df):\n",
    "    ems = \"\"\"\n",
    "        admiration\n",
    "        amusement\n",
    "        anger\n",
    "        annoyance\n",
    "        approval\n",
    "        caring\n",
    "        confusion\n",
    "        curiosity\n",
    "        desire\n",
    "        disappointment\n",
    "        disapproval\n",
    "        disgust\n",
    "        embarrassment\n",
    "        excitement\n",
    "        fear\n",
    "        gratitude\n",
    "        grief\n",
    "        joy\n",
    "        love\n",
    "        nervousness\n",
    "        optimism\n",
    "        pride\n",
    "        realization\n",
    "        relief\n",
    "        remorse\n",
    "        sadness\n",
    "        surprise\n",
    "        neutral\n",
    "    \"\"\"\n",
    "    res = []\n",
    "\n",
    "    for i in df['emotions']:\n",
    "        tmp = [0 for _ in range(28)]\n",
    "        for j in i:\n",
    "            tmp[j] = 1\n",
    "        res.append(tmp)\n",
    "    tmp_df = pd.DataFrame(res, columns=ems.split())\n",
    "    \n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc91be68",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([test_df, emotions_to_categorical(test_df)], axis=1)\n",
    "\n",
    "test_df = test_df.drop(columns=['emotions', 'id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd8d7036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 모델 및 토크나이저 불러오기\n",
    "load_directory = \"./model_saved_bert_base_v2\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(load_directory)\n",
    "tokenizer = AutoTokenizer.from_pretrained(load_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cce079b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=28, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9affcdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ems = \"\"\"\n",
    "        admiration\n",
    "        amusement\n",
    "        anger\n",
    "        annoyance\n",
    "        approval\n",
    "        caring\n",
    "        confusion\n",
    "        curiosity\n",
    "        desire\n",
    "        disappointment\n",
    "        disapproval\n",
    "        disgust\n",
    "        embarrassment\n",
    "        excitement\n",
    "        fear\n",
    "        gratitude\n",
    "        grief\n",
    "        joy\n",
    "        love\n",
    "        nervousness\n",
    "        optimism\n",
    "        pride\n",
    "        realization\n",
    "        relief\n",
    "        remorse\n",
    "        sadness\n",
    "        surprise\n",
    "        neutral\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9141b169",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.data.loc[index, 'text'])\n",
    "        labels = self.data.loc[index, ems.split()].values\n",
    "        labels = labels.astype('float32')\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        item = {key: val.squeeze(0) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.tensor(labels, dtype=torch.float)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1acd1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "test_dataset = EmotionDataset(test_df, tokenizer, MAX_LEN)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3478fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device, emotion_names = ems.split()):\n",
    "    \"\"\"\n",
    "    다중 라벨 분류 모델을 평가하는 통합 함수.\n",
    "    정확도, F1-점수를 계산하고, 각 라벨에 대한 개별 Precision-Recall 곡선을 그립니다.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to (device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            probs = torch.sigmoid(logits)\n",
    "            predictions = (probs > 0.5).int()\n",
    "\n",
    "            all_predictions.append(predictions.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "            \n",
    "\n",
    "    all_predictions = np.vstack(all_predictions)\n",
    "    all_labels = np.vstack(all_labels)\n",
    "    all_probs = np.vstack(all_probs)\n",
    "\n",
    "    return all_predictions, all_labels, all_probs, outputs\n",
    "\n",
    "    # accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    \n",
    "    # precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
    "    #     all_labels, all_predictions, average='micro'\n",
    "    # )\n",
    "    # precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "    #     all_labels, all_predictions, average='macro'\n",
    "    # )\n",
    "    \n",
    "    # precision_per_label, recall_per_label, f1_per_label, _ = precision_recall_fscore_support(\n",
    "    #     all_labels, all_predictions, average=None\n",
    "    # )\n",
    "\n",
    "    # precision_macro_std = np.std(precision_per_label)\n",
    "    # recall_macro_std = np.std(recall_per_label)\n",
    "    # f1_macro_std = np.std(f1_per_label)\n",
    "\n",
    "    # print(\"--- 모델 평가 결과 ---\")\n",
    "    # print(f\"전체 샘플에 대한 정확도 (Exact Match Accuracy): {accuracy:.4f}\")\n",
    "    # print(\"\\n--- Micro 평균 지표 ---\")\n",
    "    # print(f\"Precision (Micro): {precision_micro:.4f}\")\n",
    "    # print(f\"Recall (Micro): {recall_micro:.4f}\")\n",
    "    # print(f\"F1-Score (Micro): {f1_micro:.4f}\")\n",
    "    # print(\"\\n--- Macro 평균 지표 ---\")\n",
    "    # print(f\"Precision (Macro): {precision_macro:.4f}\")\n",
    "    # print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
    "    # print(f\"F1-Score (Macro): {f1_macro:.4f}\")\n",
    "    \n",
    "    # print(\"\\n--- 라벨별 지표 ---\")\n",
    "    # for i in range(len(emotion_names)):\n",
    "    #     print(f\"{emotion_names[i]} - Precision: {precision_per_label[i]:.4f}, Recall: {recall_per_label[i]:.4f}, F1-Score: {f1_per_label[i]:.4f}\")\n",
    "    \n",
    "    # print(f\"\\nPrecision (Macro) 표준편차: {precision_macro_std:.4f}\")\n",
    "    # print(f\"Recall (Macro) 표준편차: {recall_macro_std:.4f}\")\n",
    "    # print(f\"F1-Score (Macro) 표준편차: {f1_macro_std:.4f}\")\n",
    "    \n",
    "    # # 각 감정별 Precision-Recall 곡선 그리기\n",
    "    # n_classes = all_labels.shape[1]\n",
    "    # for i in range(n_classes):\n",
    "    #     plt.figure(figsize=(6, 5))\n",
    "        \n",
    "    #     precision_curve, recall_curve, _ = precision_recall_curve(all_labels[:, i], all_probs[:, i])\n",
    "        \n",
    "    #     plt.plot(recall_curve, precision_curve, label=f'{emotion_names[i]}')\n",
    "    #     plt.plot([0, 1], [1, 0], linestyle='--', color='gray')\n",
    "    #     plt.xlabel('재현율 (Recall)')\n",
    "    #     plt.ylabel('정밀도 (Precision)')\n",
    "    #     plt.title(f'정밀도-재현율 곡선: {emotion_names[i]}')\n",
    "    #     plt.grid(True)\n",
    "    #     plt.legend()\n",
    "    #     plt.show()\n",
    "\n",
    "    # return accuracy, f1_micro, f1_macro\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "93209ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, labels, probs, outputs  = evaluate_model(model, test_loader, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fdac6140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotions_to_ekman(li):\n",
    "    # anger disgust fear joy sadness surprise neutral\n",
    "    ekman = [3, 3, 0, 0, 3, 3, 5, 5, 3, 4, 0, 1, 4, 3, 2, 3, 4, 3, 3, 2, 3, 3, 5, 3, 4, 4, 5, 6]\n",
    "    res = []\n",
    "\n",
    "    for i in li:\n",
    "        tmp = [0, 0, 0, 0, 0, 0, 0]\n",
    "        for j in range(len(i)):\n",
    "            if i[j] == 1:\n",
    "                tmp[ekman[j]] = 1\n",
    "        res.append(tmp)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "566976c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ekman = emotions_to_ekman(predictions)\n",
    "labels_ekman = emotions_to_ekman(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "265def91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(all_predictions, all_labels, emotion_names = 'anger disgust fear joy sadness surprise neutral'.split()):\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    \n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_predictions, average='micro'\n",
    "    )\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_predictions, average='macro'\n",
    "    )\n",
    "    \n",
    "    precision_per_label, recall_per_label, f1_per_label, _ = precision_recall_fscore_support(\n",
    "        all_labels, all_predictions, average=None\n",
    "    )\n",
    "\n",
    "    precision_macro_std = np.std(precision_per_label)\n",
    "    recall_macro_std = np.std(recall_per_label)\n",
    "    f1_macro_std = np.std(f1_per_label)\n",
    "\n",
    "    print(\"--- 모델 평가 결과 ---\")\n",
    "    print(f\"전체 샘플에 대한 정확도 (Exact Match Accuracy): {accuracy:.4f}\")\n",
    "    print(\"\\n--- Micro 평균 지표 ---\")\n",
    "    print(f\"Precision (Micro): {precision_micro:.4f}\")\n",
    "    print(f\"Recall (Micro): {recall_micro:.4f}\")\n",
    "    print(f\"F1-Score (Micro): {f1_micro:.4f}\")\n",
    "    print(\"\\n--- Macro 평균 지표 ---\")\n",
    "    print(f\"Precision (Macro): {precision_macro:.4f}\")\n",
    "    print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
    "    print(f\"F1-Score (Macro): {f1_macro:.4f}\")\n",
    "    \n",
    "    print(\"\\n--- 라벨별 지표 ---\")\n",
    "    for i in range(len(emotion_names)):\n",
    "        print(f\"{emotion_names[i]} - Precision: {precision_per_label[i]:.4f}, Recall: {recall_per_label[i]:.4f}, F1-Score: {f1_per_label[i]:.4f}\")\n",
    "    \n",
    "    print(f\"\\nPrecision (Macro) 표준편차: {precision_macro_std:.4f}\")\n",
    "    print(f\"Recall (Macro) 표준편차: {recall_macro_std:.4f}\")\n",
    "    print(f\"F1-Score (Macro) 표준편차: {f1_macro_std:.4f}\")\n",
    "\n",
    "    return accuracy, f1_micro, f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "db7d5d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.5500\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.7723\n",
      "Recall (Micro): 0.5587\n",
      "F1-Score (Micro): 0.6484\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.7323\n",
      "Recall (Macro): 0.4602\n",
      "F1-Score (Macro): 0.5532\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.6848, Recall: 0.2603, F1-Score: 0.3772\n",
      "disgust - Precision: 0.6792, Recall: 0.2927, F1-Score: 0.4091\n",
      "fear - Precision: 0.7105, Recall: 0.5510, F1-Score: 0.6207\n",
      "joy - Precision: 0.8561, Recall: 0.7519, F1-Score: 0.8006\n",
      "sadness - Precision: 0.8114, Recall: 0.3747, F1-Score: 0.5126\n",
      "surprise - Precision: 0.6720, Recall: 0.4328, F1-Score: 0.5265\n",
      "neutral - Precision: 0.7121, Recall: 0.5579, F1-Score: 0.6257\n",
      "\n",
      "Precision (Macro) 표준편차: 0.0667\n",
      "Recall (Macro) 표준편차: 0.1599\n",
      "F1-Score (Macro) 표준편차: 0.1337\n"
     ]
    }
   ],
   "source": [
    "accuracy, f1_micro, f1_macro = evaluation(preds_ekman, labels_ekman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d08b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goemotions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
