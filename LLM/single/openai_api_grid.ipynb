{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "710d8ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b6bc31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ems = \"\"\"\n",
    "        admiration\n",
    "        amusement\n",
    "        anger\n",
    "        annoyance\n",
    "        approval\n",
    "        caring\n",
    "        confusion\n",
    "        curiosity\n",
    "        desire\n",
    "        disappointment\n",
    "        disapproval\n",
    "        disgust\n",
    "        embarrassment\n",
    "        excitement\n",
    "        fear\n",
    "        gratitude\n",
    "        grief\n",
    "        joy\n",
    "        love\n",
    "        nervousness\n",
    "        optimism\n",
    "        pride\n",
    "        realization\n",
    "        relief\n",
    "        remorse\n",
    "        sadness\n",
    "        surprise\n",
    "        neutral\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4a196e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotions_to_categorical(df):\n",
    "    res = []\n",
    "\n",
    "    for i in df['emotions']:\n",
    "        tmp = [0 for _ in range(28)]\n",
    "        for j in i:\n",
    "            tmp[j] = 1\n",
    "        res.append(tmp)\n",
    "    tmp_df = pd.DataFrame(res, columns=ems.split())\n",
    "    \n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "975c4f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotions_to_ekman(df):\n",
    "    # anger disgust fear joy sadness surprise neutral\n",
    "    ekman = [3, 3, 0, 0, 3, 3, 5, 5, 3, 4, 0, 1, 4, 3, 2, 3, 4, 3, 3, 2, 3, 3, 5, 3, 4, 4, 5, 6]\n",
    "    res = []\n",
    "\n",
    "    for i in df:\n",
    "        tmp = [0, 0, 0, 0, 0, 0, 0]\n",
    "        for j in range(len(i)):\n",
    "            if i[j] == 1:\n",
    "                tmp[ekman[j]] = 1\n",
    "        res.append(tmp)\n",
    "    tmp_df = pd.DataFrame(res, columns=['angry', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'neutral'])\n",
    "    \n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "628b9fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_init(path = \"../data/dev.tsv\"):\n",
    "    df = pd.read_csv(path, sep=\"\\t\", encoding = \"utf-8\", header=None)\n",
    "    df.columns = ['text', 'emotions', 'id']\n",
    "    df['emotions'] = list(map(lambda s : list(map(int, s.split(','))), df['emotions']))\n",
    "    df = pd.concat([df, emotions_to_categorical(df)], axis=1)\n",
    "    df = df.drop(columns=['emotions', 'id'])\n",
    "    df['text'] = list(map(lambda s : s.replace('\\\\', '\\\\\\\\').replace('\"', '\\\\\"'), list(df['text']))) \n",
    "    return df.iloc[:2500, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "144fb321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(original_df, emotion_res):\n",
    "    emotions_list = ems.split()\n",
    "    df = original_df\n",
    "    predicted_df = pd.DataFrame(data = [[0 for _ in range(28)] for _ in range(len(df))], columns=emotions_list)\n",
    "    for i in range(len(emotion_res)):\n",
    "        for j in emotion_res[i]:\n",
    "            if j in emotions_list:\n",
    "                predicted_df.loc[i, j] = 1\n",
    "    predicted = predicted_df.to_numpy()\n",
    "    original = df.iloc[:,1:].to_numpy()\n",
    "    \n",
    "    accuracy = accuracy_score(original, predicted)\n",
    "    \n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
    "        original, predicted, average='micro'\n",
    "    )\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        original, predicted, average='macro'\n",
    "    )\n",
    "    \n",
    "    precision_per_label, recall_per_label, f1_per_label, _ = precision_recall_fscore_support(\n",
    "        original, predicted, average=None\n",
    "    )\n",
    "\n",
    "    precision_macro_std = np.std(precision_per_label)\n",
    "    recall_macro_std = np.std(recall_per_label)\n",
    "    f1_macro_std = np.std(f1_per_label)\n",
    "\n",
    "    print(\"--- 모델 평가 결과 ---\")\n",
    "    print(f\"전체 샘플에 대한 정확도 (Exact Match Accuracy): {accuracy:.4f}\")\n",
    "    print(\"\\n--- Micro 평균 지표 ---\")\n",
    "    print(f\"Precision (Micro): {precision_micro:.4f}\")\n",
    "    print(f\"Recall (Micro): {recall_micro:.4f}\")\n",
    "    print(f\"F1-Score (Micro): {f1_micro:.4f}\")\n",
    "    print(\"\\n--- Macro 평균 지표 ---\")\n",
    "    print(f\"Precision (Macro): {precision_macro:.4f}\")\n",
    "    print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
    "    print(f\"F1-Score (Macro): {f1_macro:.4f}\")\n",
    "    \n",
    "    print(\"\\n--- 라벨별 지표 ---\")\n",
    "    for i in range(len(emotions_list)):\n",
    "        print(f\"{emotions_list[i]} - Precision: {precision_per_label[i]:.4f}, Recall: {recall_per_label[i]:.4f}, F1-Score: {f1_per_label[i]:.4f}\")\n",
    "    \n",
    "    print(f\"\\nPrecision (Macro) 표준편차: {precision_macro_std:.4f}\")\n",
    "    print(f\"Recall (Macro) 표준편차: {recall_macro_std:.4f}\")\n",
    "    print(f\"F1-Score (Macro) 표준편차: {f1_macro_std:.4f}\")\n",
    "\n",
    "    return accuracy, f1_micro, f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "078a66fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_ekman(original_df, emotion_res):\n",
    "    emotions_list = 'anger disgust fear joy sadness surprise neutral'.split()\n",
    "    predicted_df = pd.DataFrame(data = [[0 for _ in range(28)] for _ in range(len(original_df))], columns=ems.split())\n",
    "    for i in range(len(emotion_res)):\n",
    "        for j in emotion_res[i]:\n",
    "            if j in ems.split():\n",
    "                predicted_df.loc[i, j] = 1\n",
    "    predicted = emotions_to_ekman(predicted_df.to_numpy()).to_numpy()\n",
    "    original = emotions_to_ekman(original_df.iloc[:,1:].to_numpy()).to_numpy()\n",
    "\n",
    "    accuracy = accuracy_score(original, predicted)\n",
    "    \n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
    "        original, predicted, average='micro'\n",
    "    )\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        original, predicted, average='macro'\n",
    "    )\n",
    "    \n",
    "    precision_per_label, recall_per_label, f1_per_label, _ = precision_recall_fscore_support(\n",
    "        original, predicted, average=None\n",
    "    )\n",
    "\n",
    "    precision_macro_std = np.std(precision_per_label)\n",
    "    recall_macro_std = np.std(recall_per_label)\n",
    "    f1_macro_std = np.std(f1_per_label)\n",
    "\n",
    "    print(\"--- 모델 평가 결과 ---\")\n",
    "    print(f\"전체 샘플에 대한 정확도 (Exact Match Accuracy): {accuracy:.4f}\")\n",
    "    print(\"\\n--- Micro 평균 지표 ---\")\n",
    "    print(f\"Precision (Micro): {precision_micro:.4f}\")\n",
    "    print(f\"Recall (Micro): {recall_micro:.4f}\")\n",
    "    print(f\"F1-Score (Micro): {f1_micro:.4f}\")\n",
    "    print(\"\\n--- Macro 평균 지표 ---\")\n",
    "    print(f\"Precision (Macro): {precision_macro:.4f}\")\n",
    "    print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
    "    print(f\"F1-Score (Macro): {f1_macro:.4f}\")\n",
    "    \n",
    "    print(\"\\n--- 라벨별 지표 ---\")\n",
    "    for i in range(len(emotions_list)):\n",
    "        print(f\"{emotions_list[i]} - Precision: {precision_per_label[i]:.4f}, Recall: {recall_per_label[i]:.4f}, F1-Score: {f1_per_label[i]:.4f}\")\n",
    "    \n",
    "    print(f\"\\nPrecision (Macro) 표준편차: {precision_macro_std:.4f}\")\n",
    "    print(f\"Recall (Macro) 표준편차: {recall_macro_std:.4f}\")\n",
    "    print(f\"F1-Score (Macro) 표준편차: {f1_macro_std:.4f}\")\n",
    "\n",
    "    return accuracy, f1_micro, f1_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ada1303",
   "metadata": {},
   "outputs": [],
   "source": [
    "persona_file = open('./prompt/persona.txt', 'r')\n",
    "persona = persona_file.read()\n",
    "persona_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60a144aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "guidelines_file = open('./prompt/guidelines.txt', 'r')\n",
    "guidelines = guidelines_file.read()\n",
    "guidelines_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "213cac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_structure_file = open('./prompt/output_structure.txt', 'r')\n",
    "output_structure = output_structure_file.read()\n",
    "output_structure_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "91001791",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_file = open('./prompt/few_shot.txt', 'r')\n",
    "# few_shot = few_shot_file.read().replace('  ', \"\").replace('   ', \"\").replace('    ', \"\").replace('     ', \"\").replace('      ', \"\").replace('\\n',\" \").replace('\\t', \" \").replace('\"', \"'\").replace('{ ', '{').replace('[ ', '[').replace(' }', '}').replace(' ]', ']')\n",
    "few_shot = few_shot_file.read()\n",
    "few_shot_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "559e18a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_of_thought_file = open('./prompt/chain_of_thought.txt', 'r')\n",
    "# chain_of_thought = chain_of_thought_file.read().replace('\\n', ' ').replace('\"', \"'\")\n",
    "chain_of_thought = chain_of_thought_file.read()\n",
    "chain_of_thought_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "defcfc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system = f\"We are trying to classify 28 emotions of goemotion, please read the prompt below carefully and proceed with the classification without errors. {persona}, {guidelines}, {chain_of_thought}, {output_structure}, {few_shot_example}\"\n",
    "system = f\"{persona}{guidelines}{output_structure}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a45ea0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(PERSONA ROLE) \n",
      "You are an expert system specializing in emotion classification, designed to analyze text with a highly analytical and empathetic approach. You excel at detecting and interpreting a wide range of emotions, considering nuanced language and complex emotional cues. \n",
      "Read the Reddit post, identify the emotions expressed, and choose the emotion label that best matches the overall sentiment.\n",
      "The following 28 emotion label: [admiration, amusement, anger, annoyance, approval, caring, confusion, curiosity, desire, disappointment, disapproval, disgust, embarrassment, excitement, fear, gratitude, grief, joy, love, nervousness, optimism, pride, realization, relief, remorse, sadness, surprise, neutral].\n",
      "(PERSONA ROLE END)\n",
      "(GUIDELINES) \n",
      "1. Think step by step carefully, First, identify key phrases and their emotional cues in the text. Second, consider which of the 28 labels best match these cues.\n",
      "2. Default to a single emotion. Your primary goal is to find the single most dominant emotion in the text. This will be the correct approach for the vast majority of sentences. \n",
      "3. Assign a second emotion only under strict conditions. Do this only if two emotions are clearly and equally present in the text, or if the sentence contains a clear transition from one emotion to another. When in doubt, prefer a single label. \n",
      "4. Assigning three or more labels is an exceptional case. This should be reserved only for longer, more complex texts where multiple, distinct emotions are explicitly described in sequence. Avoid this for short, simple sentences. \n",
      "5. Neutral Handling: \n",
      "- Choose `neutral` only when the text is purely factual, descriptive, or the emotional signals are too weak to be conclusive. - Do NOT assign `neutral` if any other clear emotion is present, even if it's mixed with factual statements.\n",
      "6. Repeat reasoning 3 times internally and output the most consistent emotion(s)\n",
      "(GUIDELINES END)\n",
      "(OUTPUT STRUCTURE)\n",
      "1. Strict JSON Output: Your final output must be a single JSON object. Do not include any text outside of this JSON object. \n",
      "2. JSON Structure: The JSON object must contain a key named analysis which is an array of objects. Each object in the array represents a single identified emotion and must contain the following two keys: \n",
      "-emotion: The specific emotion label from the list. \n",
      "-reason: A brief, objective explanation of why you chose this emotion, citing specific words or phrases from the text. \n",
      "(OUTPUT STRUCTURE END)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(system)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66b36c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beba6740",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = [0, 0.25, 0.5, 0.75, 1]\n",
    "top_p = [0, 0.125, 0.25, 0.5, 0.75, 1]\n",
    "temperature = [0, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8f3c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "for i in temperature:\n",
    "    for j in top_p:\n",
    "        if i in origin and j in origin:\n",
    "            continue\n",
    "        values.append((i, j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6b37fd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b90955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for j in values:\n",
    "    with open(f\"./inputs/few_shot_grid/grid_{i}.jsonl\", \"w\") as f:\n",
    "        k = 0\n",
    "        for record in data[\"text\"]:\n",
    "            baseQuery = {\n",
    "            \"custom_id\": f\"query{k}\",\n",
    "            \"method\": \"POST\",\n",
    "            \"url\": \"/v1/responses\",\n",
    "            \"body\": {\n",
    "                    \"model\": \"gpt-4o-mini\",\n",
    "                    \"temperature\": j[0],\n",
    "                    \"top_p\": j[1],\n",
    "                    \"input\": [{\n",
    "                        \"role\": \"developer\",\n",
    "                        \"content\": f\"{system}\"\n",
    "                    }, \n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": f\"{record}\"\n",
    "                    }], \n",
    "                    \"max_output_tokens\": 1000,\n",
    "                    \"text\": {\n",
    "                        \"format\": {\n",
    "                            \"type\": \"json_schema\",\n",
    "                            \"name\": \"result\",\n",
    "                            \"strict\": True,\n",
    "                            \"schema\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"analysis\": {\n",
    "                                        \"type\": \"array\",\n",
    "                                        \"items\": {\n",
    "                                            \"type\": \"object\",\n",
    "                                            \"properties\": {\n",
    "                                                \"emotion\": {\n",
    "                                                    \"type\": \"string\",\n",
    "                                                    \"enum\": [ \"admiration\", \"amusement\", \"anger\", \"annoyance\", \"approval\", \"caring\", \"confusion\", \"curiosity\", \"desire\", \"disappointment\", \"disapproval\", \"disgust\", \"embarrassment\", \"excitement\", \"fear\", \"gratitude\", \"grief\", \"joy\", \"love\", \"nervousness\", \"optimism\", \"pride\", \"realization\", \"relief\", \"remorse\", \"sadness\", \"surprise\", \"neutral\" ]\n",
    "                                                },\n",
    "                                                \"reason\": {\n",
    "                                                    \"type\": \"string\"\n",
    "                                                }\n",
    "                                            },\n",
    "                                            \"required\": [\"emotion\", \"reason\"],\n",
    "                                            \"additionalProperties\": False\n",
    "                                        }\n",
    "                                    }\n",
    "                                },\n",
    "                                \"required\": [\"analysis\"],\n",
    "                                \"additionalProperties\": False\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            k += 1\n",
    "            f.write(json.dumps(baseQuery) + \"\\n\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09d73f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_file = open('./key/openai_key.txt', 'r')\n",
    "api_key = key_file.readline()\n",
    "key_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bf06b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "d8f4bf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list = [\"\"] * 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "51cea49b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['batch_68f59a9be74c8190aa3bfd167ccd57c4', 'batch_68f59a9e7b9c81909e9db8203ce911a7', 'batch_68f59aa078f08190912209509e87993e', 'batch_68f59aa2d54c8190932de5696ab8de39', 'batch_68f59ade977c819087be4149bcaa4d77', 'batch_68f59ae0f4408190a2ecd9bf58faa43a', 'batch_68f59ae315748190be14ef08dbf50b50', 'batch_68f59ae5793881908df292dfbc95ddef', 'batch_68f59ae82fc08190b50c5075b3e4d583', 'batch_68f59ae9ec788190b08ee662f1007806', 'batch_68f59aed169481909bce6b0fd08e366f', 'batch_68f59aee912c8190a9e997f8c1bb7427', 'batch_68f59af069c48190a86a077d0d525029', 'batch_68f59af390cc819098a3380d3e910955', 'batch_68f59af5996881909fa06ae06dc3152d', 'batch_68f59af8059c819091a353272174adb5', 'batch_68f59afa0ce881909383f3e4843f2202', 'batch_68f59afbd7788190a8bc1fd1319612c9', 'batch_68f59afe5334819082d0caf50a3d4dbc', 'batch_68f59b00847c81908ab0041c5e0ca1b5', 'batch_68f59b0252c8819092bb8e12e9df20a1', 'batch_68f59b0488d0819094ea337117c55114', 'batch_68f59b07f1888190bc3512f620d08932', 'batch_68f59b09c0748190adfbf51c18e6e031', 'batch_68f59b0cdb5c81909d18ab63fcb16ab2']\n"
     ]
    }
   ],
   "source": [
    "print(batch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "ab2a8ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-AMpGNUUtuNjB9ZJQztQgoj', bytes=8817821, created_at=1760926430, filename='grid_4.jsonl', object='file', purpose='batch', status='processed', expires_at=1763518430, status_details=None)\n",
      "FileObject(id='file-13yJd1wq2Z36xDpWRiEf9W', bytes=8825321, created_at=1760926432, filename='grid_5.jsonl', object='file', purpose='batch', status='processed', expires_at=1763518432, status_details=None)\n",
      "FileObject(id='file-TjSj3Tf8ajXvg94wELZ1uh', bytes=8832821, created_at=1760926434, filename='grid_6.jsonl', object='file', purpose='batch', status='processed', expires_at=1763518434, status_details=None)\n",
      "FileObject(id='file-YHrNeBjEh2kh7dUngRg7C7', bytes=8830321, created_at=1760926436, filename='grid_7.jsonl', object='file', purpose='batch', status='processed', expires_at=1763518436, status_details=None)\n",
      "FileObject(id='file-AX4TWq3e88BG3XvDRzDnwz', bytes=8832821, created_at=1760926439, filename='grid_8.jsonl', object='file', purpose='batch', status='processed', expires_at=1763518439, status_details=None)\n",
      "FileObject(id='file-KuBUrLfvuNeYYJgDT5DV7p', bytes=8825321, created_at=1760926441, filename='grid_9.jsonl', object='file', purpose='batch', status='processed', expires_at=1763518441, status_details=None)\n",
      "FileObject(id='file-1n6ajQxgcfRWpXNaWhJNUV', bytes=8822821, created_at=1760926444, filename='grid_10.jsonl', object='file', purpose='batch', status='processed', expires_at=1763518444, status_details=None)\n",
      "FileObject(id='file-SqCThA9RHHaUydUPZiwzuv', bytes=8830321, created_at=1760926446, filename='grid_11.jsonl', object='file', purpose='batch', status='processed', expires_at=1763518446, status_details=None)\n",
      "FileObject(id='file-UAsUBbp5Grvzs9zYkkUt1p', bytes=8827821, created_at=1760926447, filename='grid_12.jsonl', object='file', purpose='batch', status='processed', expires_at=1763518447, status_details=None)\n",
      "FileObject(id='file-NLuFX7tqGJrwd3kVufiYWB', bytes=8830321, created_at=1760926450, filename='grid_13.jsonl', object='file', purpose='batch', status='processed', expires_at=1763518450, status_details=None)\n",
      "FileObject(id='file-LWv6WGHVBa4czoTBubHSnt', bytes=8822821, created_at=1760926452, filename='grid_14.jsonl', object='file', purpose='batch', status='processed', expires_at=1763518452, status_details=None)\n",
      "FileObject(id='file-43AEm9CRfr8QsQpJ8wkEKy', bytes=8825321, created_at=1760926455, filename='grid_15.jsonl', object='file', purpose='batch', status='processed', expires_at=1763518455, status_details=None)\n",
      "FileObject(id='file-TL6vKRBamzPtbnDuXpjW5x', bytes=8832821, created_at=1760926457, filename='grid_16.jsonl', object='file', purpose='batch', status='processed', expires_at=1763518457, status_details=None)\n",
      "FileObject(id='file-5EtKzS6twpipAj2LX1EMsv', bytes=8830321, created_at=1760926459, filename='grid_17.jsonl', object='file', purpose='batch', status='processed', expires_at=1763518459, status_details=None)\n",
      "FileObject(id='file-EqyTPUp1f4at6r3pMedTpP', bytes=8832821, created_at=1760926461, filename='grid_18.jsonl', object='file', purpose='batch', status='processed', expires_at=1763518461, status_details=None)\n",
      "FileObject(id='file-MwqxkVfJmgFfovWPKxdzg4', bytes=8825321, created_at=1760926463, filename='grid_19.jsonl', object='file', purpose='batch', status='processed', expires_at=1763518463, status_details=None)\n",
      "FileObject(id='file-AwCdX1FpFSQDFpQuSZPq93', bytes=8817821, created_at=1760926465, filename='grid_20.jsonl', object='file', purpose='batch', status='processed', expires_at=1763518465, status_details=None)\n",
      "FileObject(id='file-2sFV53C9zBAvrFPqKpvWBv', bytes=8825321, created_at=1760926467, filename='grid_21.jsonl', object='file', purpose='batch', status='processed', expires_at=1763518467, status_details=None)\n",
      "FileObject(id='file-1B4A1eRtTf5xS1iRcBPKGn', bytes=8822821, created_at=1760926471, filename='grid_22.jsonl', object='file', purpose='batch', status='processed', expires_at=1763518471, status_details=None)\n",
      "FileObject(id='file-N1n4ndLVqAjBNbHN82Pc7v', bytes=8825321, created_at=1760926473, filename='grid_23.jsonl', object='file', purpose='batch', status='processed', expires_at=1763518473, status_details=None)\n",
      "FileObject(id='file-9r9GoHY7mYaGzGTwo8FqxM', bytes=8817821, created_at=1760926475, filename='grid_24.jsonl', object='file', purpose='batch', status='processed', expires_at=1763518475, status_details=None)\n"
     ]
    }
   ],
   "source": [
    "for i in range(4, 25):\n",
    "    batch_input_file = client.files.create(\n",
    "        file=open(f\"./inputs/grid/grid_{i}.jsonl\", \"rb\"),\n",
    "        purpose='batch'\n",
    "    )\n",
    "    print(batch_input_file)\n",
    "    \n",
    "    batch_input_file_id = batch_input_file.id\n",
    "    create_batch=client.batches.create(\n",
    "        input_file_id=batch_input_file_id,\n",
    "        endpoint=\"/v1/responses\",\n",
    "        completion_window=\"24h\",\n",
    "    )\n",
    "    batch_list[i] = create_batch.id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "b1c79b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_res = [0] * 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "aa50243b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 done\n",
      "1 done\n",
      "2 done\n",
      "3 done\n",
      "4 done\n",
      "5 done\n",
      "6 done\n",
      "7 done\n",
      "8 done\n",
      "9 done\n",
      "10 done\n",
      "11 done\n",
      "12 done\n",
      "13 done\n",
      "14 done\n",
      "15 done\n",
      "16 done\n",
      "17 done\n",
      "18 done\n",
      "19 done\n",
      "20 done\n",
      "21 done\n",
      "22 done!\n",
      "23 done\n",
      "24 done\n",
      "25 / 25\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in range(len(batch_list)):\n",
    "    print(i, end=\" \")\n",
    "    if batch_res[i] != 0:\n",
    "        print(\"done\")\n",
    "        cnt += 1\n",
    "        continue\n",
    "    batch = client.batches.retrieve(batch_list[i])\n",
    "    result = None\n",
    "    if batch.status == 'completed':\n",
    "        out = batch.output_file_id\n",
    "        if out != None:\n",
    "            cnt += 1\n",
    "            print('done!')\n",
    "            result = client.files.content(out)\n",
    "            batch_res[i] = result\n",
    "        else:\n",
    "            print('error')\n",
    "            result = client.files.content(batch.error_file_id).text\n",
    "            batch_res[i] = result\n",
    "    elif batch.status == 'failed':\n",
    "        print('failed')\n",
    "        print(batch.errors)\n",
    "    else:\n",
    "        print('it does not finish yet')\n",
    "        print(batch.status)\n",
    "        print(batch.request_counts)\n",
    "print(cnt, \"/ 25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "a709a5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = []\n",
    "for i in temperature:\n",
    "    for j in top_p:\n",
    "        t.append((float(i), float(j)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "dac2d0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 0.0), (0.0, 0.25), (0.0, 0.5), (0.0, 0.75), (0.0, 1.0), (0.25, 0.0), (0.25, 0.25), (0.25, 0.5), (0.25, 0.75), (0.25, 1.0), (0.5, 0.0), (0.5, 0.25), (0.5, 0.5), (0.5, 0.75), (0.5, 1.0), (0.75, 0.0), (0.75, 0.25), (0.75, 0.5), (0.75, 0.75), (0.75, 1.0), (1.0, 0.0), (1.0, 0.25), (1.0, 0.5), (1.0, 0.75), (1.0, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "8f9d37ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------- 0--------------------------\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2244\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3125\n",
      "Recall (Micro): 0.2701\n",
      "F1-Score (Micro): 0.2897\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3727\n",
      "Recall (Macro): 0.3120\n",
      "F1-Score (Macro): 0.2902\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.6500, Recall: 0.1711, F1-Score: 0.2708\n",
      "amusement - Precision: 0.3021, Recall: 0.6959, F1-Score: 0.4213\n",
      "anger - Precision: 0.2421, Recall: 0.6778, F1-Score: 0.3567\n",
      "annoyance - Precision: 0.1806, Recall: 0.0929, F1-Score: 0.1226\n",
      "approval - Precision: 0.2410, Recall: 0.1156, F1-Score: 0.1562\n",
      "caring - Precision: 0.2951, Recall: 0.2769, F1-Score: 0.2857\n",
      "confusion - Precision: 0.1498, Recall: 0.5000, F1-Score: 0.2305\n",
      "curiosity - Precision: 0.2182, Recall: 0.3130, F1-Score: 0.2571\n",
      "desire - Precision: 0.3889, Recall: 0.2059, F1-Score: 0.2692\n",
      "disappointment - Precision: 0.1527, Recall: 0.2532, F1-Score: 0.1905\n",
      "disapproval - Precision: 0.2113, Recall: 0.2950, F1-Score: 0.2462\n",
      "disgust - Precision: 0.4146, Recall: 0.3333, F1-Score: 0.3696\n",
      "embarrassment - Precision: 0.5000, Recall: 0.4000, F1-Score: 0.4444\n",
      "excitement - Precision: 0.2727, Recall: 0.2195, F1-Score: 0.2432\n",
      "fear - Precision: 0.2958, Recall: 0.4884, F1-Score: 0.3684\n",
      "gratitude - Precision: 0.9077, Recall: 0.3554, F1-Score: 0.5108\n",
      "grief - Precision: 0.4000, Recall: 0.4444, F1-Score: 0.4211\n",
      "joy - Precision: 0.1982, Recall: 0.4839, F1-Score: 0.2812\n",
      "love - Precision: 0.7500, Recall: 0.2778, F1-Score: 0.4054\n",
      "nervousness - Precision: 0.4000, Recall: 0.1818, F1-Score: 0.2500\n",
      "optimism - Precision: 0.4028, Recall: 0.2762, F1-Score: 0.3277\n",
      "pride - Precision: 0.4167, Recall: 0.5000, F1-Score: 0.4545\n",
      "realization - Precision: 0.3333, Recall: 0.0469, F1-Score: 0.0822\n",
      "relief - Precision: 0.0526, Recall: 0.1429, F1-Score: 0.0769\n",
      "remorse - Precision: 0.6667, Recall: 0.0526, F1-Score: 0.0976\n",
      "sadness - Precision: 0.3367, Recall: 0.5000, F1-Score: 0.4024\n",
      "surprise - Precision: 0.4146, Recall: 0.2787, F1-Score: 0.3333\n",
      "neutral - Precision: 0.6406, Recall: 0.1561, F1-Score: 0.2510\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1955\n",
      "Recall (Macro) 표준편차: 0.1709\n",
      "F1-Score (Macro) 표준편차: 0.1156\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4548\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5294\n",
      "Recall (Micro): 0.4875\n",
      "F1-Score (Micro): 0.5076\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4677\n",
      "Recall (Macro): 0.4806\n",
      "F1-Score (Macro): 0.4436\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3996, Recall: 0.6035, F1-Score: 0.4808\n",
      "disgust - Precision: 0.4146, Recall: 0.3333, F1-Score: 0.3696\n",
      "fear - Precision: 0.3684, Recall: 0.5283, F1-Score: 0.4341\n",
      "joy - Precision: 0.7015, Recall: 0.6879, F1-Score: 0.6946\n",
      "sadness - Precision: 0.3976, Recall: 0.5260, F1-Score: 0.4529\n",
      "surprise - Precision: 0.3515, Recall: 0.5290, F1-Score: 0.4223\n",
      "neutral - Precision: 0.6406, Recall: 0.1561, F1-Score: 0.2510\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1311\n",
      "Recall (Macro) 표준편차: 0.1655\n",
      "F1-Score (Macro) 표준편차: 0.1240\n",
      "-------------------------- 1--------------------------\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2236\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3121\n",
      "Recall (Micro): 0.2697\n",
      "F1-Score (Micro): 0.2893\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3641\n",
      "Recall (Macro): 0.3107\n",
      "F1-Score (Macro): 0.2856\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.6724, Recall: 0.1711, F1-Score: 0.2727\n",
      "amusement - Precision: 0.2953, Recall: 0.6824, F1-Score: 0.4122\n",
      "anger - Precision: 0.2411, Recall: 0.6778, F1-Score: 0.3557\n",
      "annoyance - Precision: 0.1944, Recall: 0.1000, F1-Score: 0.1321\n",
      "approval - Precision: 0.2442, Recall: 0.1214, F1-Score: 0.1622\n",
      "caring - Precision: 0.3276, Recall: 0.2923, F1-Score: 0.3089\n",
      "confusion - Precision: 0.1466, Recall: 0.5000, F1-Score: 0.2267\n",
      "curiosity - Precision: 0.2130, Recall: 0.3130, F1-Score: 0.2535\n",
      "desire - Precision: 0.3529, Recall: 0.1765, F1-Score: 0.2353\n",
      "disappointment - Precision: 0.1667, Recall: 0.2785, F1-Score: 0.2085\n",
      "disapproval - Precision: 0.2165, Recall: 0.3022, F1-Score: 0.2523\n",
      "disgust - Precision: 0.4359, Recall: 0.3333, F1-Score: 0.3778\n",
      "embarrassment - Precision: 0.4286, Recall: 0.4000, F1-Score: 0.4138\n",
      "excitement - Precision: 0.2727, Recall: 0.2195, F1-Score: 0.2432\n",
      "fear - Precision: 0.3000, Recall: 0.4884, F1-Score: 0.3717\n",
      "gratitude - Precision: 0.8939, Recall: 0.3554, F1-Score: 0.5086\n",
      "grief - Precision: 0.3077, Recall: 0.4444, F1-Score: 0.3636\n",
      "joy - Precision: 0.2074, Recall: 0.4839, F1-Score: 0.2903\n",
      "love - Precision: 0.7500, Recall: 0.3056, F1-Score: 0.4342\n",
      "nervousness - Precision: 0.4000, Recall: 0.1818, F1-Score: 0.2500\n",
      "optimism - Precision: 0.3867, Recall: 0.2762, F1-Score: 0.3222\n",
      "pride - Precision: 0.3846, Recall: 0.5000, F1-Score: 0.4348\n",
      "realization - Precision: 0.2857, Recall: 0.0312, F1-Score: 0.0563\n",
      "relief - Precision: 0.0556, Recall: 0.1429, F1-Score: 0.0800\n",
      "remorse - Precision: 0.6667, Recall: 0.0526, F1-Score: 0.0976\n",
      "sadness - Precision: 0.3125, Recall: 0.4545, F1-Score: 0.3704\n",
      "surprise - Precision: 0.3902, Recall: 0.2623, F1-Score: 0.3137\n",
      "neutral - Precision: 0.6471, Recall: 0.1536, F1-Score: 0.2482\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1935\n",
      "Recall (Macro) 표준편차: 0.1691\n",
      "F1-Score (Macro) 표준편차: 0.1120\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4548\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5296\n",
      "Recall (Micro): 0.4875\n",
      "F1-Score (Micro): 0.5077\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4728\n",
      "Recall (Macro): 0.4828\n",
      "F1-Score (Macro): 0.4460\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3969, Recall: 0.6006, F1-Score: 0.4780\n",
      "disgust - Precision: 0.4359, Recall: 0.3333, F1-Score: 0.3778\n",
      "fear - Precision: 0.3733, Recall: 0.5283, F1-Score: 0.4375\n",
      "joy - Precision: 0.7030, Recall: 0.6860, F1-Score: 0.6944\n",
      "sadness - Precision: 0.4031, Recall: 0.5417, F1-Score: 0.4622\n",
      "surprise - Precision: 0.3504, Recall: 0.5358, F1-Score: 0.4238\n",
      "neutral - Precision: 0.6471, Recall: 0.1536, F1-Score: 0.2482\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1310\n",
      "Recall (Macro) 표준편차: 0.1666\n",
      "F1-Score (Macro) 표준편차: 0.1238\n",
      "-------------------------- 2--------------------------\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2240\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3120\n",
      "Recall (Micro): 0.2701\n",
      "F1-Score (Micro): 0.2895\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3730\n",
      "Recall (Macro): 0.3143\n",
      "F1-Score (Macro): 0.2896\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.6897, Recall: 0.1754, F1-Score: 0.2797\n",
      "amusement - Precision: 0.3003, Recall: 0.6959, F1-Score: 0.4196\n",
      "anger - Precision: 0.2381, Recall: 0.6667, F1-Score: 0.3509\n",
      "annoyance - Precision: 0.2027, Recall: 0.1071, F1-Score: 0.1402\n",
      "approval - Precision: 0.2683, Recall: 0.1272, F1-Score: 0.1725\n",
      "caring - Precision: 0.3333, Recall: 0.3077, F1-Score: 0.3200\n",
      "confusion - Precision: 0.1515, Recall: 0.5147, F1-Score: 0.2341\n",
      "curiosity - Precision: 0.2275, Recall: 0.3304, F1-Score: 0.2695\n",
      "desire - Precision: 0.3750, Recall: 0.1765, F1-Score: 0.2400\n",
      "disappointment - Precision: 0.1484, Recall: 0.2405, F1-Score: 0.1836\n",
      "disapproval - Precision: 0.2000, Recall: 0.2878, F1-Score: 0.2360\n",
      "disgust - Precision: 0.4000, Recall: 0.3529, F1-Score: 0.3750\n",
      "embarrassment - Precision: 0.3846, Recall: 0.3333, F1-Score: 0.3571\n",
      "excitement - Precision: 0.2571, Recall: 0.2195, F1-Score: 0.2368\n",
      "fear - Precision: 0.2917, Recall: 0.4884, F1-Score: 0.3652\n",
      "gratitude - Precision: 0.9062, Recall: 0.3494, F1-Score: 0.5043\n",
      "grief - Precision: 0.3333, Recall: 0.4444, F1-Score: 0.3810\n",
      "joy - Precision: 0.1938, Recall: 0.4731, F1-Score: 0.2750\n",
      "love - Precision: 0.7561, Recall: 0.2870, F1-Score: 0.4161\n",
      "nervousness - Precision: 0.4000, Recall: 0.1818, F1-Score: 0.2500\n",
      "optimism - Precision: 0.4110, Recall: 0.2857, F1-Score: 0.3371\n",
      "pride - Precision: 0.4615, Recall: 0.6000, F1-Score: 0.5217\n",
      "realization - Precision: 0.3750, Recall: 0.0469, F1-Score: 0.0833\n",
      "relief - Precision: 0.0588, Recall: 0.1429, F1-Score: 0.0833\n",
      "remorse - Precision: 0.6667, Recall: 0.0526, F1-Score: 0.0976\n",
      "sadness - Precision: 0.3196, Recall: 0.4697, F1-Score: 0.3804\n",
      "surprise - Precision: 0.4500, Recall: 0.2951, F1-Score: 0.3564\n",
      "neutral - Precision: 0.6429, Recall: 0.1485, F1-Score: 0.2412\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1962\n",
      "Recall (Macro) 표준편차: 0.1731\n",
      "F1-Score (Macro) 표준편차: 0.1139\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4536\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5283\n",
      "Recall (Micro): 0.4871\n",
      "F1-Score (Micro): 0.5069\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4654\n",
      "Recall (Macro): 0.4836\n",
      "F1-Score (Macro): 0.4430\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3931, Recall: 0.6006, F1-Score: 0.4752\n",
      "disgust - Precision: 0.4000, Recall: 0.3529, F1-Score: 0.3750\n",
      "fear - Precision: 0.3636, Recall: 0.5283, F1-Score: 0.4308\n",
      "joy - Precision: 0.7041, Recall: 0.6899, F1-Score: 0.6969\n",
      "sadness - Precision: 0.3992, Recall: 0.5260, F1-Score: 0.4539\n",
      "surprise - Precision: 0.3551, Recall: 0.5392, F1-Score: 0.4282\n",
      "neutral - Precision: 0.6429, Recall: 0.1485, F1-Score: 0.2412\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1336\n",
      "Recall (Macro) 표준편차: 0.1658\n",
      "F1-Score (Macro) 표준편차: 0.1261\n",
      "-------------------------- 3--------------------------\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2264\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3152\n",
      "Recall (Micro): 0.2728\n",
      "F1-Score (Micro): 0.2925\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3704\n",
      "Recall (Macro): 0.3170\n",
      "F1-Score (Macro): 0.2932\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.7193, Recall: 0.1798, F1-Score: 0.2877\n",
      "amusement - Precision: 0.3063, Recall: 0.6892, F1-Score: 0.4241\n",
      "anger - Precision: 0.2353, Recall: 0.6667, F1-Score: 0.3478\n",
      "annoyance - Precision: 0.1690, Recall: 0.0857, F1-Score: 0.1137\n",
      "approval - Precision: 0.2439, Recall: 0.1156, F1-Score: 0.1569\n",
      "caring - Precision: 0.3167, Recall: 0.2923, F1-Score: 0.3040\n",
      "confusion - Precision: 0.1485, Recall: 0.5000, F1-Score: 0.2290\n",
      "curiosity - Precision: 0.2262, Recall: 0.3304, F1-Score: 0.2686\n",
      "desire - Precision: 0.3500, Recall: 0.2059, F1-Score: 0.2593\n",
      "disappointment - Precision: 0.1642, Recall: 0.2785, F1-Score: 0.2066\n",
      "disapproval - Precision: 0.2092, Recall: 0.2950, F1-Score: 0.2448\n",
      "disgust - Precision: 0.3953, Recall: 0.3333, F1-Score: 0.3617\n",
      "embarrassment - Precision: 0.4615, Recall: 0.4000, F1-Score: 0.4286\n",
      "excitement - Precision: 0.2500, Recall: 0.2195, F1-Score: 0.2338\n",
      "fear - Precision: 0.3000, Recall: 0.4884, F1-Score: 0.3717\n",
      "gratitude - Precision: 0.9014, Recall: 0.3855, F1-Score: 0.5401\n",
      "grief - Precision: 0.3636, Recall: 0.4444, F1-Score: 0.4000\n",
      "joy - Precision: 0.2000, Recall: 0.4839, F1-Score: 0.2830\n",
      "love - Precision: 0.7674, Recall: 0.3056, F1-Score: 0.4371\n",
      "nervousness - Precision: 0.4000, Recall: 0.1818, F1-Score: 0.2500\n",
      "optimism - Precision: 0.3836, Recall: 0.2667, F1-Score: 0.3146\n",
      "pride - Precision: 0.5000, Recall: 0.6000, F1-Score: 0.5455\n",
      "realization - Precision: 0.2500, Recall: 0.0312, F1-Score: 0.0556\n",
      "relief - Precision: 0.0588, Recall: 0.1429, F1-Score: 0.0833\n",
      "remorse - Precision: 0.6667, Recall: 0.0526, F1-Score: 0.0976\n",
      "sadness - Precision: 0.3404, Recall: 0.4848, F1-Score: 0.4000\n",
      "surprise - Precision: 0.3902, Recall: 0.2623, F1-Score: 0.3137\n",
      "neutral - Precision: 0.6524, Recall: 0.1548, F1-Score: 0.2503\n",
      "\n",
      "Precision (Macro) 표준편차: 0.2016\n",
      "Recall (Macro) 표준편차: 0.1750\n",
      "F1-Score (Macro) 표준편차: 0.1241\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4572\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5327\n",
      "Recall (Micro): 0.4904\n",
      "F1-Score (Micro): 0.5107\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4696\n",
      "Recall (Macro): 0.4842\n",
      "F1-Score (Macro): 0.4456\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3985, Recall: 0.6064, F1-Score: 0.4809\n",
      "disgust - Precision: 0.3953, Recall: 0.3333, F1-Score: 0.3617\n",
      "fear - Precision: 0.3733, Recall: 0.5283, F1-Score: 0.4375\n",
      "joy - Precision: 0.7086, Recall: 0.6908, F1-Score: 0.6996\n",
      "sadness - Precision: 0.4039, Recall: 0.5365, F1-Score: 0.4609\n",
      "surprise - Precision: 0.3551, Recall: 0.5392, F1-Score: 0.4282\n",
      "neutral - Precision: 0.6524, Recall: 0.1548, F1-Score: 0.2503\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1351\n",
      "Recall (Macro) 표준편차: 0.1676\n",
      "F1-Score (Macro) 표준편차: 0.1262\n",
      "-------------------------- 4--------------------------\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2256\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3122\n",
      "Recall (Micro): 0.2694\n",
      "F1-Score (Micro): 0.2892\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3669\n",
      "Recall (Macro): 0.3092\n",
      "F1-Score (Macro): 0.2867\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.6984, Recall: 0.1930, F1-Score: 0.3024\n",
      "amusement - Precision: 0.3033, Recall: 0.6824, F1-Score: 0.4200\n",
      "anger - Precision: 0.2369, Recall: 0.6556, F1-Score: 0.3481\n",
      "annoyance - Precision: 0.1867, Recall: 0.1000, F1-Score: 0.1302\n",
      "approval - Precision: 0.2468, Recall: 0.1098, F1-Score: 0.1520\n",
      "caring - Precision: 0.3065, Recall: 0.2923, F1-Score: 0.2992\n",
      "confusion - Precision: 0.1515, Recall: 0.5147, F1-Score: 0.2341\n",
      "curiosity - Precision: 0.2202, Recall: 0.3217, F1-Score: 0.2615\n",
      "desire - Precision: 0.4118, Recall: 0.2059, F1-Score: 0.2745\n",
      "disappointment - Precision: 0.1567, Recall: 0.2658, F1-Score: 0.1972\n",
      "disapproval - Precision: 0.2132, Recall: 0.3022, F1-Score: 0.2500\n",
      "disgust - Precision: 0.4250, Recall: 0.3333, F1-Score: 0.3736\n",
      "embarrassment - Precision: 0.4167, Recall: 0.3333, F1-Score: 0.3704\n",
      "excitement - Precision: 0.2432, Recall: 0.2195, F1-Score: 0.2308\n",
      "fear - Precision: 0.2958, Recall: 0.4884, F1-Score: 0.3684\n",
      "gratitude - Precision: 0.8923, Recall: 0.3494, F1-Score: 0.5022\n",
      "grief - Precision: 0.3636, Recall: 0.4444, F1-Score: 0.4000\n",
      "joy - Precision: 0.2009, Recall: 0.4839, F1-Score: 0.2839\n",
      "love - Precision: 0.7561, Recall: 0.2870, F1-Score: 0.4161\n",
      "nervousness - Precision: 0.3333, Recall: 0.1818, F1-Score: 0.2353\n",
      "optimism - Precision: 0.3889, Recall: 0.2667, F1-Score: 0.3164\n",
      "pride - Precision: 0.4167, Recall: 0.5000, F1-Score: 0.4545\n",
      "realization - Precision: 0.3333, Recall: 0.0469, F1-Score: 0.0822\n",
      "relief - Precision: 0.0556, Recall: 0.1429, F1-Score: 0.0800\n",
      "remorse - Precision: 0.6667, Recall: 0.0526, F1-Score: 0.0976\n",
      "sadness - Precision: 0.3333, Recall: 0.4697, F1-Score: 0.3899\n",
      "surprise - Precision: 0.3810, Recall: 0.2623, F1-Score: 0.3107\n",
      "neutral - Precision: 0.6383, Recall: 0.1523, F1-Score: 0.2459\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1952\n",
      "Recall (Macro) 표준편차: 0.1662\n",
      "F1-Score (Macro) 표준편차: 0.1106\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4528\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5270\n",
      "Recall (Micro): 0.4849\n",
      "F1-Score (Micro): 0.5051\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4672\n",
      "Recall (Macro): 0.4793\n",
      "F1-Score (Macro): 0.4419\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3954, Recall: 0.6006, F1-Score: 0.4769\n",
      "disgust - Precision: 0.4250, Recall: 0.3333, F1-Score: 0.3736\n",
      "fear - Precision: 0.3636, Recall: 0.5283, F1-Score: 0.4308\n",
      "joy - Precision: 0.7031, Recall: 0.6841, F1-Score: 0.6934\n",
      "sadness - Precision: 0.3953, Recall: 0.5208, F1-Score: 0.4494\n",
      "surprise - Precision: 0.3497, Recall: 0.5358, F1-Score: 0.4232\n",
      "neutral - Precision: 0.6383, Recall: 0.1523, F1-Score: 0.2459\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1318\n",
      "Recall (Macro) 표준편차: 0.1657\n",
      "F1-Score (Macro) 표준편차: 0.1243\n",
      "-------------------------- 5--------------------------\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2240\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3119\n",
      "Recall (Micro): 0.2697\n",
      "F1-Score (Micro): 0.2893\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3739\n",
      "Recall (Macro): 0.3139\n",
      "F1-Score (Macro): 0.2910\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.6949, Recall: 0.1798, F1-Score: 0.2857\n",
      "amusement - Precision: 0.3018, Recall: 0.6892, F1-Score: 0.4198\n",
      "anger - Precision: 0.2381, Recall: 0.6667, F1-Score: 0.3509\n",
      "annoyance - Precision: 0.1757, Recall: 0.0929, F1-Score: 0.1215\n",
      "approval - Precision: 0.2405, Recall: 0.1098, F1-Score: 0.1508\n",
      "caring - Precision: 0.3115, Recall: 0.2923, F1-Score: 0.3016\n",
      "confusion - Precision: 0.1447, Recall: 0.4853, F1-Score: 0.2230\n",
      "curiosity - Precision: 0.2275, Recall: 0.3304, F1-Score: 0.2695\n",
      "desire - Precision: 0.4118, Recall: 0.2059, F1-Score: 0.2745\n",
      "disappointment - Precision: 0.1462, Recall: 0.2405, F1-Score: 0.1818\n",
      "disapproval - Precision: 0.2060, Recall: 0.2950, F1-Score: 0.2426\n",
      "disgust - Precision: 0.4048, Recall: 0.3333, F1-Score: 0.3656\n",
      "embarrassment - Precision: 0.5000, Recall: 0.4000, F1-Score: 0.4444\n",
      "excitement - Precision: 0.2812, Recall: 0.2195, F1-Score: 0.2466\n",
      "fear - Precision: 0.3000, Recall: 0.4884, F1-Score: 0.3717\n",
      "gratitude - Precision: 0.8923, Recall: 0.3494, F1-Score: 0.5022\n",
      "grief - Precision: 0.3333, Recall: 0.4444, F1-Score: 0.3810\n",
      "joy - Precision: 0.1948, Recall: 0.4839, F1-Score: 0.2778\n",
      "love - Precision: 0.7500, Recall: 0.2778, F1-Score: 0.4054\n",
      "nervousness - Precision: 0.4000, Recall: 0.1818, F1-Score: 0.2500\n",
      "optimism - Precision: 0.4143, Recall: 0.2762, F1-Score: 0.3314\n",
      "pride - Precision: 0.4615, Recall: 0.6000, F1-Score: 0.5217\n",
      "realization - Precision: 0.3333, Recall: 0.0469, F1-Score: 0.0822\n",
      "relief - Precision: 0.0526, Recall: 0.1429, F1-Score: 0.0769\n",
      "remorse - Precision: 0.6667, Recall: 0.0526, F1-Score: 0.0976\n",
      "sadness - Precision: 0.3263, Recall: 0.4697, F1-Score: 0.3851\n",
      "surprise - Precision: 0.4146, Recall: 0.2787, F1-Score: 0.3333\n",
      "neutral - Precision: 0.6458, Recall: 0.1574, F1-Score: 0.2531\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1979\n",
      "Recall (Macro) 표준편차: 0.1728\n",
      "F1-Score (Macro) 표준편차: 0.1176\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4548\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5294\n",
      "Recall (Micro): 0.4868\n",
      "F1-Score (Micro): 0.5072\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4676\n",
      "Recall (Macro): 0.4801\n",
      "F1-Score (Macro): 0.4432\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3943, Recall: 0.6035, F1-Score: 0.4770\n",
      "disgust - Precision: 0.4048, Recall: 0.3333, F1-Score: 0.3656\n",
      "fear - Precision: 0.3733, Recall: 0.5283, F1-Score: 0.4375\n",
      "joy - Precision: 0.7069, Recall: 0.6850, F1-Score: 0.6958\n",
      "sadness - Precision: 0.3968, Recall: 0.5208, F1-Score: 0.4505\n",
      "surprise - Precision: 0.3514, Recall: 0.5324, F1-Score: 0.4233\n",
      "neutral - Precision: 0.6458, Recall: 0.1574, F1-Score: 0.2531\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1340\n",
      "Recall (Macro) 표준편차: 0.1646\n",
      "F1-Score (Macro) 표준편차: 0.1240\n",
      "-------------------------- 6--------------------------\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2236\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3140\n",
      "Recall (Micro): 0.2714\n",
      "F1-Score (Micro): 0.2912\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3792\n",
      "Recall (Macro): 0.3124\n",
      "F1-Score (Macro): 0.2915\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.6897, Recall: 0.1754, F1-Score: 0.2797\n",
      "amusement - Precision: 0.3012, Recall: 0.6959, F1-Score: 0.4204\n",
      "anger - Precision: 0.2419, Recall: 0.6667, F1-Score: 0.3550\n",
      "annoyance - Precision: 0.1781, Recall: 0.0929, F1-Score: 0.1221\n",
      "approval - Precision: 0.2706, Recall: 0.1329, F1-Score: 0.1783\n",
      "caring - Precision: 0.3226, Recall: 0.3077, F1-Score: 0.3150\n",
      "confusion - Precision: 0.1460, Recall: 0.4853, F1-Score: 0.2245\n",
      "curiosity - Precision: 0.2176, Recall: 0.3217, F1-Score: 0.2596\n",
      "desire - Precision: 0.4118, Recall: 0.2059, F1-Score: 0.2745\n",
      "disappointment - Precision: 0.1550, Recall: 0.2532, F1-Score: 0.1923\n",
      "disapproval - Precision: 0.2172, Recall: 0.3094, F1-Score: 0.2552\n",
      "disgust - Precision: 0.3953, Recall: 0.3333, F1-Score: 0.3617\n",
      "embarrassment - Precision: 0.4615, Recall: 0.4000, F1-Score: 0.4286\n",
      "excitement - Precision: 0.2571, Recall: 0.2195, F1-Score: 0.2368\n",
      "fear - Precision: 0.2958, Recall: 0.4884, F1-Score: 0.3684\n",
      "gratitude - Precision: 0.9062, Recall: 0.3494, F1-Score: 0.5043\n",
      "grief - Precision: 0.4000, Recall: 0.4444, F1-Score: 0.4211\n",
      "joy - Precision: 0.1947, Recall: 0.4731, F1-Score: 0.2759\n",
      "love - Precision: 0.7561, Recall: 0.2870, F1-Score: 0.4161\n",
      "nervousness - Precision: 0.5000, Recall: 0.1818, F1-Score: 0.2667\n",
      "optimism - Precision: 0.4028, Recall: 0.2762, F1-Score: 0.3277\n",
      "pride - Precision: 0.4167, Recall: 0.5000, F1-Score: 0.4545\n",
      "realization - Precision: 0.3750, Recall: 0.0469, F1-Score: 0.0833\n",
      "relief - Precision: 0.0526, Recall: 0.1429, F1-Score: 0.0769\n",
      "remorse - Precision: 0.6667, Recall: 0.0526, F1-Score: 0.0976\n",
      "sadness - Precision: 0.3368, Recall: 0.4848, F1-Score: 0.3975\n",
      "surprise - Precision: 0.4000, Recall: 0.2623, F1-Score: 0.3168\n",
      "neutral - Precision: 0.6474, Recall: 0.1561, F1-Score: 0.2515\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1980\n",
      "Recall (Macro) 표준편차: 0.1676\n",
      "F1-Score (Macro) 표준편차: 0.1133\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4572\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5320\n",
      "Recall (Micro): 0.4893\n",
      "F1-Score (Micro): 0.5097\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4681\n",
      "Recall (Macro): 0.4814\n",
      "F1-Score (Macro): 0.4443\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3958, Recall: 0.5977, F1-Score: 0.4762\n",
      "disgust - Precision: 0.3953, Recall: 0.3333, F1-Score: 0.3617\n",
      "fear - Precision: 0.3733, Recall: 0.5283, F1-Score: 0.4375\n",
      "joy - Precision: 0.7064, Recall: 0.6928, F1-Score: 0.6995\n",
      "sadness - Precision: 0.4040, Recall: 0.5260, F1-Score: 0.4570\n",
      "surprise - Precision: 0.3544, Recall: 0.5358, F1-Score: 0.4266\n",
      "neutral - Precision: 0.6474, Recall: 0.1561, F1-Score: 0.2515\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1339\n",
      "Recall (Macro) 표준편차: 0.1661\n",
      "F1-Score (Macro) 표준편차: 0.1257\n",
      "-------------------------- 7--------------------------\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2280\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3161\n",
      "Recall (Micro): 0.2738\n",
      "F1-Score (Micro): 0.2934\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3727\n",
      "Recall (Macro): 0.3186\n",
      "F1-Score (Macro): 0.2952\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.6984, Recall: 0.1930, F1-Score: 0.3024\n",
      "amusement - Precision: 0.3045, Recall: 0.6892, F1-Score: 0.4224\n",
      "anger - Precision: 0.2362, Recall: 0.6667, F1-Score: 0.3488\n",
      "annoyance - Precision: 0.1757, Recall: 0.0929, F1-Score: 0.1215\n",
      "approval - Precision: 0.2500, Recall: 0.1272, F1-Score: 0.1686\n",
      "caring - Precision: 0.3167, Recall: 0.2923, F1-Score: 0.3040\n",
      "confusion - Precision: 0.1483, Recall: 0.5147, F1-Score: 0.2303\n",
      "curiosity - Precision: 0.2303, Recall: 0.3304, F1-Score: 0.2714\n",
      "desire - Precision: 0.3500, Recall: 0.2059, F1-Score: 0.2593\n",
      "disappointment - Precision: 0.1719, Recall: 0.2785, F1-Score: 0.2126\n",
      "disapproval - Precision: 0.2051, Recall: 0.2878, F1-Score: 0.2395\n",
      "disgust - Precision: 0.4103, Recall: 0.3137, F1-Score: 0.3556\n",
      "embarrassment - Precision: 0.5455, Recall: 0.4000, F1-Score: 0.4615\n",
      "excitement - Precision: 0.2571, Recall: 0.2195, F1-Score: 0.2368\n",
      "fear - Precision: 0.3000, Recall: 0.4884, F1-Score: 0.3717\n",
      "gratitude - Precision: 0.8955, Recall: 0.3614, F1-Score: 0.5150\n",
      "grief - Precision: 0.3636, Recall: 0.4444, F1-Score: 0.4000\n",
      "joy - Precision: 0.2074, Recall: 0.4839, F1-Score: 0.2903\n",
      "love - Precision: 0.7500, Recall: 0.3056, F1-Score: 0.4342\n",
      "nervousness - Precision: 0.4000, Recall: 0.1818, F1-Score: 0.2500\n",
      "optimism - Precision: 0.4167, Recall: 0.2857, F1-Score: 0.3390\n",
      "pride - Precision: 0.4615, Recall: 0.6000, F1-Score: 0.5217\n",
      "realization - Precision: 0.2500, Recall: 0.0312, F1-Score: 0.0556\n",
      "relief - Precision: 0.0588, Recall: 0.1429, F1-Score: 0.0833\n",
      "remorse - Precision: 0.6667, Recall: 0.0526, F1-Score: 0.0976\n",
      "sadness - Precision: 0.3367, Recall: 0.5000, F1-Score: 0.4024\n",
      "surprise - Precision: 0.3864, Recall: 0.2787, F1-Score: 0.3238\n",
      "neutral - Precision: 0.6417, Recall: 0.1523, F1-Score: 0.2462\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1985\n",
      "Recall (Macro) 표준편차: 0.1745\n",
      "F1-Score (Macro) 표준편차: 0.1213\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4560\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5309\n",
      "Recall (Micro): 0.4889\n",
      "F1-Score (Micro): 0.5091\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4702\n",
      "Recall (Macro): 0.4812\n",
      "F1-Score (Macro): 0.4442\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3985, Recall: 0.6064, F1-Score: 0.4809\n",
      "disgust - Precision: 0.4103, Recall: 0.3137, F1-Score: 0.3556\n",
      "fear - Precision: 0.3733, Recall: 0.5283, F1-Score: 0.4375\n",
      "joy - Precision: 0.7045, Recall: 0.6889, F1-Score: 0.6966\n",
      "sadness - Precision: 0.4104, Recall: 0.5365, F1-Score: 0.4650\n",
      "surprise - Precision: 0.3525, Recall: 0.5427, F1-Score: 0.4274\n",
      "neutral - Precision: 0.6417, Recall: 0.1523, F1-Score: 0.2462\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1309\n",
      "Recall (Macro) 표준편차: 0.1708\n",
      "F1-Score (Macro) 표준편차: 0.1270\n",
      "-------------------------- 8--------------------------\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2288\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3178\n",
      "Recall (Micro): 0.2751\n",
      "F1-Score (Micro): 0.2949\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3676\n",
      "Recall (Macro): 0.3138\n",
      "F1-Score (Macro): 0.2915\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.7119, Recall: 0.1842, F1-Score: 0.2927\n",
      "amusement - Precision: 0.3152, Recall: 0.7027, F1-Score: 0.4351\n",
      "anger - Precision: 0.2402, Recall: 0.6778, F1-Score: 0.3547\n",
      "annoyance - Precision: 0.1892, Recall: 0.1000, F1-Score: 0.1308\n",
      "approval - Precision: 0.2410, Recall: 0.1156, F1-Score: 0.1562\n",
      "caring - Precision: 0.3333, Recall: 0.3077, F1-Score: 0.3200\n",
      "confusion - Precision: 0.1422, Recall: 0.4853, F1-Score: 0.2200\n",
      "curiosity - Precision: 0.2321, Recall: 0.3391, F1-Score: 0.2756\n",
      "desire - Precision: 0.3684, Recall: 0.2059, F1-Score: 0.2642\n",
      "disappointment - Precision: 0.1653, Recall: 0.2532, F1-Score: 0.2000\n",
      "disapproval - Precision: 0.2020, Recall: 0.2878, F1-Score: 0.2374\n",
      "disgust - Precision: 0.3864, Recall: 0.3333, F1-Score: 0.3579\n",
      "embarrassment - Precision: 0.3846, Recall: 0.3333, F1-Score: 0.3571\n",
      "excitement - Precision: 0.2571, Recall: 0.2195, F1-Score: 0.2368\n",
      "fear - Precision: 0.2838, Recall: 0.4884, F1-Score: 0.3590\n",
      "gratitude - Precision: 0.9077, Recall: 0.3554, F1-Score: 0.5108\n",
      "grief - Precision: 0.4000, Recall: 0.4444, F1-Score: 0.4211\n",
      "joy - Precision: 0.2018, Recall: 0.4731, F1-Score: 0.2830\n",
      "love - Precision: 0.7619, Recall: 0.2963, F1-Score: 0.4267\n",
      "nervousness - Precision: 0.5000, Recall: 0.1818, F1-Score: 0.2667\n",
      "optimism - Precision: 0.4000, Recall: 0.2667, F1-Score: 0.3200\n",
      "pride - Precision: 0.5455, Recall: 0.6000, F1-Score: 0.5714\n",
      "realization - Precision: 0.1667, Recall: 0.0156, F1-Score: 0.0286\n",
      "relief - Precision: 0.0526, Recall: 0.1429, F1-Score: 0.0769\n",
      "remorse - Precision: 0.5000, Recall: 0.0263, F1-Score: 0.0500\n",
      "sadness - Precision: 0.3232, Recall: 0.4848, F1-Score: 0.3879\n",
      "surprise - Precision: 0.4390, Recall: 0.2951, F1-Score: 0.3529\n",
      "neutral - Precision: 0.6425, Recall: 0.1688, F1-Score: 0.2673\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1991\n",
      "Recall (Macro) 표준편차: 0.1762\n",
      "F1-Score (Macro) 표준편차: 0.1272\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4580\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5329\n",
      "Recall (Micro): 0.4911\n",
      "F1-Score (Micro): 0.5111\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4666\n",
      "Recall (Macro): 0.4846\n",
      "F1-Score (Macro): 0.4463\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3992, Recall: 0.6122, F1-Score: 0.4833\n",
      "disgust - Precision: 0.3864, Recall: 0.3333, F1-Score: 0.3579\n",
      "fear - Precision: 0.3590, Recall: 0.5283, F1-Score: 0.4275\n",
      "joy - Precision: 0.7103, Recall: 0.6821, F1-Score: 0.6959\n",
      "sadness - Precision: 0.4163, Recall: 0.5312, F1-Score: 0.4668\n",
      "surprise - Precision: 0.3528, Recall: 0.5358, F1-Score: 0.4255\n",
      "neutral - Precision: 0.6425, Recall: 0.1688, F1-Score: 0.2673\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1354\n",
      "Recall (Macro) 표준편차: 0.1624\n",
      "F1-Score (Macro) 표준편차: 0.1223\n",
      "-------------------------- 9--------------------------\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2256\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3125\n",
      "Recall (Micro): 0.2701\n",
      "F1-Score (Micro): 0.2897\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3652\n",
      "Recall (Macro): 0.3082\n",
      "F1-Score (Macro): 0.2851\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.6290, Recall: 0.1711, F1-Score: 0.2690\n",
      "amusement - Precision: 0.3077, Recall: 0.7027, F1-Score: 0.4280\n",
      "anger - Precision: 0.2326, Recall: 0.6667, F1-Score: 0.3448\n",
      "annoyance - Precision: 0.1918, Recall: 0.1000, F1-Score: 0.1315\n",
      "approval - Precision: 0.2250, Recall: 0.1040, F1-Score: 0.1423\n",
      "caring - Precision: 0.3276, Recall: 0.2923, F1-Score: 0.3089\n",
      "confusion - Precision: 0.1392, Recall: 0.4853, F1-Score: 0.2164\n",
      "curiosity - Precision: 0.2256, Recall: 0.3217, F1-Score: 0.2652\n",
      "desire - Precision: 0.3684, Recall: 0.2059, F1-Score: 0.2642\n",
      "disappointment - Precision: 0.1550, Recall: 0.2532, F1-Score: 0.1923\n",
      "disapproval - Precision: 0.2151, Recall: 0.2878, F1-Score: 0.2462\n",
      "disgust - Precision: 0.3953, Recall: 0.3333, F1-Score: 0.3617\n",
      "embarrassment - Precision: 0.4167, Recall: 0.3333, F1-Score: 0.3704\n",
      "excitement - Precision: 0.2286, Recall: 0.1951, F1-Score: 0.2105\n",
      "fear - Precision: 0.3088, Recall: 0.4884, F1-Score: 0.3784\n",
      "gratitude - Precision: 0.9048, Recall: 0.3434, F1-Score: 0.4978\n",
      "grief - Precision: 0.3333, Recall: 0.4444, F1-Score: 0.3810\n",
      "joy - Precision: 0.2055, Recall: 0.4839, F1-Score: 0.2885\n",
      "love - Precision: 0.7556, Recall: 0.3148, F1-Score: 0.4444\n",
      "nervousness - Precision: 0.3333, Recall: 0.1818, F1-Score: 0.2353\n",
      "optimism - Precision: 0.4030, Recall: 0.2571, F1-Score: 0.3140\n",
      "pride - Precision: 0.3846, Recall: 0.5000, F1-Score: 0.4348\n",
      "realization - Precision: 0.3750, Recall: 0.0469, F1-Score: 0.0833\n",
      "relief - Precision: 0.0556, Recall: 0.1429, F1-Score: 0.0800\n",
      "remorse - Precision: 0.7500, Recall: 0.0789, F1-Score: 0.1429\n",
      "sadness - Precision: 0.3131, Recall: 0.4697, F1-Score: 0.3758\n",
      "surprise - Precision: 0.4000, Recall: 0.2623, F1-Score: 0.3168\n",
      "neutral - Precision: 0.6465, Recall: 0.1624, F1-Score: 0.2596\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1986\n",
      "Recall (Macro) 표준편차: 0.1673\n",
      "F1-Score (Macro) 표준편차: 0.1086\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4548\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5289\n",
      "Recall (Micro): 0.4878\n",
      "F1-Score (Micro): 0.5076\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4673\n",
      "Recall (Macro): 0.4820\n",
      "F1-Score (Macro): 0.4447\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3965, Recall: 0.5977, F1-Score: 0.4767\n",
      "disgust - Precision: 0.3953, Recall: 0.3333, F1-Score: 0.3617\n",
      "fear - Precision: 0.3784, Recall: 0.5283, F1-Score: 0.4409\n",
      "joy - Precision: 0.7035, Recall: 0.6831, F1-Score: 0.6931\n",
      "sadness - Precision: 0.4023, Recall: 0.5365, F1-Score: 0.4598\n",
      "surprise - Precision: 0.3482, Recall: 0.5324, F1-Score: 0.4211\n",
      "neutral - Precision: 0.6465, Recall: 0.1624, F1-Score: 0.2596\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1333\n",
      "Recall (Macro) 표준편차: 0.1629\n",
      "F1-Score (Macro) 표준편차: 0.1223\n",
      "-------------------------- 10--------------------------\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2220\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3096\n",
      "Recall (Micro): 0.2677\n",
      "F1-Score (Micro): 0.2871\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3669\n",
      "Recall (Macro): 0.3096\n",
      "F1-Score (Macro): 0.2866\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.6667, Recall: 0.1667, F1-Score: 0.2667\n",
      "amusement - Precision: 0.3068, Recall: 0.7027, F1-Score: 0.4271\n",
      "anger - Precision: 0.2419, Recall: 0.6667, F1-Score: 0.3550\n",
      "annoyance - Precision: 0.1842, Recall: 0.1000, F1-Score: 0.1296\n",
      "approval - Precision: 0.2471, Recall: 0.1214, F1-Score: 0.1628\n",
      "caring - Precision: 0.3115, Recall: 0.2923, F1-Score: 0.3016\n",
      "confusion - Precision: 0.1518, Recall: 0.5000, F1-Score: 0.2329\n",
      "curiosity - Precision: 0.2151, Recall: 0.3217, F1-Score: 0.2578\n",
      "desire - Precision: 0.4118, Recall: 0.2059, F1-Score: 0.2745\n",
      "disappointment - Precision: 0.1603, Recall: 0.2658, F1-Score: 0.2000\n",
      "disapproval - Precision: 0.2050, Recall: 0.2950, F1-Score: 0.2419\n",
      "disgust - Precision: 0.3810, Recall: 0.3137, F1-Score: 0.3441\n",
      "embarrassment - Precision: 0.4615, Recall: 0.4000, F1-Score: 0.4286\n",
      "excitement - Precision: 0.2500, Recall: 0.2195, F1-Score: 0.2338\n",
      "fear - Precision: 0.2958, Recall: 0.4884, F1-Score: 0.3684\n",
      "gratitude - Precision: 0.8889, Recall: 0.3373, F1-Score: 0.4891\n",
      "grief - Precision: 0.4000, Recall: 0.4444, F1-Score: 0.4211\n",
      "joy - Precision: 0.1964, Recall: 0.4731, F1-Score: 0.2776\n",
      "love - Precision: 0.7317, Recall: 0.2778, F1-Score: 0.4027\n",
      "nervousness - Precision: 0.4000, Recall: 0.1818, F1-Score: 0.2500\n",
      "optimism - Precision: 0.3836, Recall: 0.2667, F1-Score: 0.3146\n",
      "pride - Precision: 0.4167, Recall: 0.5000, F1-Score: 0.4545\n",
      "realization - Precision: 0.2857, Recall: 0.0312, F1-Score: 0.0563\n",
      "relief - Precision: 0.0526, Recall: 0.1429, F1-Score: 0.0769\n",
      "remorse - Precision: 0.6667, Recall: 0.0526, F1-Score: 0.0976\n",
      "sadness - Precision: 0.3298, Recall: 0.4697, F1-Score: 0.3875\n",
      "surprise - Precision: 0.3864, Recall: 0.2787, F1-Score: 0.3238\n",
      "neutral - Precision: 0.6436, Recall: 0.1536, F1-Score: 0.2480\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1928\n",
      "Recall (Macro) 표준편차: 0.1694\n",
      "F1-Score (Macro) 표준편차: 0.1134\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4532\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5280\n",
      "Recall (Micro): 0.4860\n",
      "F1-Score (Micro): 0.5061\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4634\n",
      "Recall (Macro): 0.4776\n",
      "F1-Score (Macro): 0.4395\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3950, Recall: 0.6035, F1-Score: 0.4775\n",
      "disgust - Precision: 0.3810, Recall: 0.3137, F1-Score: 0.3441\n",
      "fear - Precision: 0.3684, Recall: 0.5283, F1-Score: 0.4341\n",
      "joy - Precision: 0.7037, Recall: 0.6860, F1-Score: 0.6947\n",
      "sadness - Precision: 0.4024, Recall: 0.5260, F1-Score: 0.4560\n",
      "surprise - Precision: 0.3498, Recall: 0.5324, F1-Score: 0.4222\n",
      "neutral - Precision: 0.6436, Recall: 0.1536, F1-Score: 0.2480\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1349\n",
      "Recall (Macro) 표준편차: 0.1686\n",
      "F1-Score (Macro) 표준편차: 0.1270\n",
      "-------------------------- 11--------------------------\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2260\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3141\n",
      "Recall (Micro): 0.2714\n",
      "F1-Score (Micro): 0.2912\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3687\n",
      "Recall (Macro): 0.3112\n",
      "F1-Score (Macro): 0.2873\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.7091, Recall: 0.1711, F1-Score: 0.2756\n",
      "amusement - Precision: 0.3045, Recall: 0.6892, F1-Score: 0.4224\n",
      "anger - Precision: 0.2470, Recall: 0.6889, F1-Score: 0.3636\n",
      "annoyance - Precision: 0.1867, Recall: 0.1000, F1-Score: 0.1302\n",
      "approval - Precision: 0.2346, Recall: 0.1098, F1-Score: 0.1496\n",
      "caring - Precision: 0.3279, Recall: 0.3077, F1-Score: 0.3175\n",
      "confusion - Precision: 0.1478, Recall: 0.5000, F1-Score: 0.2282\n",
      "curiosity - Precision: 0.2321, Recall: 0.3391, F1-Score: 0.2756\n",
      "desire - Precision: 0.3889, Recall: 0.2059, F1-Score: 0.2692\n",
      "disappointment - Precision: 0.1550, Recall: 0.2532, F1-Score: 0.1923\n",
      "disapproval - Precision: 0.2020, Recall: 0.2878, F1-Score: 0.2374\n",
      "disgust - Precision: 0.4048, Recall: 0.3333, F1-Score: 0.3656\n",
      "embarrassment - Precision: 0.4545, Recall: 0.3333, F1-Score: 0.3846\n",
      "excitement - Precision: 0.2647, Recall: 0.2195, F1-Score: 0.2400\n",
      "fear - Precision: 0.3000, Recall: 0.4884, F1-Score: 0.3717\n",
      "gratitude - Precision: 0.8986, Recall: 0.3735, F1-Score: 0.5277\n",
      "grief - Precision: 0.3333, Recall: 0.4444, F1-Score: 0.3810\n",
      "joy - Precision: 0.2000, Recall: 0.4839, F1-Score: 0.2830\n",
      "love - Precision: 0.7442, Recall: 0.2963, F1-Score: 0.4238\n",
      "nervousness - Precision: 0.3333, Recall: 0.1818, F1-Score: 0.2353\n",
      "optimism - Precision: 0.4085, Recall: 0.2762, F1-Score: 0.3295\n",
      "pride - Precision: 0.3846, Recall: 0.5000, F1-Score: 0.4348\n",
      "realization - Precision: 0.3750, Recall: 0.0469, F1-Score: 0.0833\n",
      "relief - Precision: 0.0556, Recall: 0.1429, F1-Score: 0.0800\n",
      "remorse - Precision: 0.6667, Recall: 0.0526, F1-Score: 0.0976\n",
      "sadness - Precision: 0.3061, Recall: 0.4545, F1-Score: 0.3659\n",
      "surprise - Precision: 0.4048, Recall: 0.2787, F1-Score: 0.3301\n",
      "neutral - Precision: 0.6524, Recall: 0.1548, F1-Score: 0.2503\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1964\n",
      "Recall (Macro) 표준편차: 0.1689\n",
      "F1-Score (Macro) 표준편차: 0.1119\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4552\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5296\n",
      "Recall (Micro): 0.4875\n",
      "F1-Score (Micro): 0.5077\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4686\n",
      "Recall (Macro): 0.4822\n",
      "F1-Score (Macro): 0.4438\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3969, Recall: 0.6064, F1-Score: 0.4798\n",
      "disgust - Precision: 0.4048, Recall: 0.3333, F1-Score: 0.3656\n",
      "fear - Precision: 0.3684, Recall: 0.5283, F1-Score: 0.4341\n",
      "joy - Precision: 0.7031, Recall: 0.6841, F1-Score: 0.6934\n",
      "sadness - Precision: 0.3992, Recall: 0.5260, F1-Score: 0.4539\n",
      "surprise - Precision: 0.3557, Recall: 0.5427, F1-Score: 0.4297\n",
      "neutral - Precision: 0.6524, Recall: 0.1548, F1-Score: 0.2503\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1339\n",
      "Recall (Macro) 표준편차: 0.1661\n",
      "F1-Score (Macro) 표준편차: 0.1240\n",
      "-------------------------- 12--------------------------\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2236\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3124\n",
      "Recall (Micro): 0.2704\n",
      "F1-Score (Micro): 0.2899\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3624\n",
      "Recall (Macro): 0.3108\n",
      "F1-Score (Macro): 0.2870\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.6508, Recall: 0.1798, F1-Score: 0.2818\n",
      "amusement - Precision: 0.3063, Recall: 0.6892, F1-Score: 0.4241\n",
      "anger - Precision: 0.2394, Recall: 0.6889, F1-Score: 0.3553\n",
      "annoyance - Precision: 0.1918, Recall: 0.1000, F1-Score: 0.1315\n",
      "approval - Precision: 0.2593, Recall: 0.1214, F1-Score: 0.1654\n",
      "caring - Precision: 0.3333, Recall: 0.3077, F1-Score: 0.3200\n",
      "confusion - Precision: 0.1447, Recall: 0.5000, F1-Score: 0.2244\n",
      "curiosity - Precision: 0.2093, Recall: 0.3130, F1-Score: 0.2509\n",
      "desire - Precision: 0.4118, Recall: 0.2059, F1-Score: 0.2745\n",
      "disappointment - Precision: 0.1600, Recall: 0.2532, F1-Score: 0.1961\n",
      "disapproval - Precision: 0.2132, Recall: 0.3022, F1-Score: 0.2500\n",
      "disgust - Precision: 0.4091, Recall: 0.3529, F1-Score: 0.3789\n",
      "embarrassment - Precision: 0.3846, Recall: 0.3333, F1-Score: 0.3571\n",
      "excitement - Precision: 0.2903, Recall: 0.2195, F1-Score: 0.2500\n",
      "fear - Precision: 0.3000, Recall: 0.4884, F1-Score: 0.3717\n",
      "gratitude - Precision: 0.9077, Recall: 0.3554, F1-Score: 0.5108\n",
      "grief - Precision: 0.3333, Recall: 0.4444, F1-Score: 0.3810\n",
      "joy - Precision: 0.1964, Recall: 0.4731, F1-Score: 0.2776\n",
      "love - Precision: 0.7619, Recall: 0.2963, F1-Score: 0.4267\n",
      "nervousness - Precision: 0.4000, Recall: 0.1818, F1-Score: 0.2500\n",
      "optimism - Precision: 0.4058, Recall: 0.2667, F1-Score: 0.3218\n",
      "pride - Precision: 0.4545, Recall: 0.5000, F1-Score: 0.4762\n",
      "realization - Precision: 0.2500, Recall: 0.0312, F1-Score: 0.0556\n",
      "relief - Precision: 0.0526, Recall: 0.1429, F1-Score: 0.0769\n",
      "remorse - Precision: 0.5000, Recall: 0.0263, F1-Score: 0.0500\n",
      "sadness - Precision: 0.3333, Recall: 0.5000, F1-Score: 0.4000\n",
      "surprise - Precision: 0.4146, Recall: 0.2787, F1-Score: 0.3333\n",
      "neutral - Precision: 0.6330, Recall: 0.1510, F1-Score: 0.2439\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1882\n",
      "Recall (Macro) 표준편차: 0.1718\n",
      "F1-Score (Macro) 표준편차: 0.1177\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4516\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5268\n",
      "Recall (Micro): 0.4860\n",
      "F1-Score (Micro): 0.5056\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4667\n",
      "Recall (Macro): 0.4841\n",
      "F1-Score (Macro): 0.4446\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3932, Recall: 0.6064, F1-Score: 0.4771\n",
      "disgust - Precision: 0.4091, Recall: 0.3529, F1-Score: 0.3789\n",
      "fear - Precision: 0.3733, Recall: 0.5283, F1-Score: 0.4375\n",
      "joy - Precision: 0.7070, Recall: 0.6831, F1-Score: 0.6948\n",
      "sadness - Precision: 0.4064, Recall: 0.5312, F1-Score: 0.4605\n",
      "surprise - Precision: 0.3451, Recall: 0.5358, F1-Score: 0.4198\n",
      "neutral - Precision: 0.6330, Recall: 0.1510, F1-Score: 0.2439\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1316\n",
      "Recall (Macro) 표준편차: 0.1646\n",
      "F1-Score (Macro) 표준편차: 0.1249\n",
      "-------------------------- 13--------------------------\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2224\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3100\n",
      "Recall (Micro): 0.2684\n",
      "F1-Score (Micro): 0.2877\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3578\n",
      "Recall (Macro): 0.3097\n",
      "F1-Score (Macro): 0.2842\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.6349, Recall: 0.1754, F1-Score: 0.2749\n",
      "amusement - Precision: 0.3038, Recall: 0.6959, F1-Score: 0.4230\n",
      "anger - Precision: 0.2290, Recall: 0.6667, F1-Score: 0.3409\n",
      "annoyance - Precision: 0.1884, Recall: 0.0929, F1-Score: 0.1244\n",
      "approval - Precision: 0.2273, Recall: 0.1156, F1-Score: 0.1533\n",
      "caring - Precision: 0.3158, Recall: 0.2769, F1-Score: 0.2951\n",
      "confusion - Precision: 0.1509, Recall: 0.5147, F1-Score: 0.2333\n",
      "curiosity - Precision: 0.2229, Recall: 0.3217, F1-Score: 0.2633\n",
      "desire - Precision: 0.3500, Recall: 0.2059, F1-Score: 0.2593\n",
      "disappointment - Precision: 0.1504, Recall: 0.2532, F1-Score: 0.1887\n",
      "disapproval - Precision: 0.2108, Recall: 0.3094, F1-Score: 0.2507\n",
      "disgust - Precision: 0.4000, Recall: 0.3137, F1-Score: 0.3516\n",
      "embarrassment - Precision: 0.3571, Recall: 0.3333, F1-Score: 0.3448\n",
      "excitement - Precision: 0.2500, Recall: 0.1951, F1-Score: 0.2192\n",
      "fear - Precision: 0.3134, Recall: 0.4884, F1-Score: 0.3818\n",
      "gratitude - Precision: 0.9062, Recall: 0.3494, F1-Score: 0.5043\n",
      "grief - Precision: 0.4000, Recall: 0.4444, F1-Score: 0.4211\n",
      "joy - Precision: 0.2028, Recall: 0.4731, F1-Score: 0.2839\n",
      "love - Precision: 0.7561, Recall: 0.2870, F1-Score: 0.4161\n",
      "nervousness - Precision: 0.4000, Recall: 0.1818, F1-Score: 0.2500\n",
      "optimism - Precision: 0.3803, Recall: 0.2571, F1-Score: 0.3068\n",
      "pride - Precision: 0.4286, Recall: 0.6000, F1-Score: 0.5000\n",
      "realization - Precision: 0.2857, Recall: 0.0312, F1-Score: 0.0563\n",
      "relief - Precision: 0.0588, Recall: 0.1429, F1-Score: 0.0833\n",
      "remorse - Precision: 0.5000, Recall: 0.0263, F1-Score: 0.0500\n",
      "sadness - Precision: 0.3298, Recall: 0.4697, F1-Score: 0.3875\n",
      "surprise - Precision: 0.4091, Recall: 0.2951, F1-Score: 0.3429\n",
      "neutral - Precision: 0.6559, Recall: 0.1548, F1-Score: 0.2505\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1875\n",
      "Recall (Macro) 표준편차: 0.1761\n",
      "F1-Score (Macro) 표준편차: 0.1190\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4544\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5301\n",
      "Recall (Micro): 0.4893\n",
      "F1-Score (Micro): 0.5089\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4709\n",
      "Recall (Macro): 0.4807\n",
      "F1-Score (Macro): 0.4440\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3888, Recall: 0.6064, F1-Score: 0.4738\n",
      "disgust - Precision: 0.4000, Recall: 0.3137, F1-Score: 0.3516\n",
      "fear - Precision: 0.3889, Recall: 0.5283, F1-Score: 0.4480\n",
      "joy - Precision: 0.7043, Recall: 0.6879, F1-Score: 0.6960\n",
      "sadness - Precision: 0.3953, Recall: 0.5208, F1-Score: 0.4494\n",
      "surprise - Precision: 0.3632, Recall: 0.5529, F1-Score: 0.4384\n",
      "neutral - Precision: 0.6559, Recall: 0.1548, F1-Score: 0.2505\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1334\n",
      "Recall (Macro) 표준편차: 0.1698\n",
      "F1-Score (Macro) 표준편차: 0.1256\n",
      "-------------------------- 14--------------------------\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2220\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3108\n",
      "Recall (Micro): 0.2687\n",
      "F1-Score (Micro): 0.2882\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3558\n",
      "Recall (Macro): 0.3049\n",
      "F1-Score (Macro): 0.2792\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.6508, Recall: 0.1798, F1-Score: 0.2818\n",
      "amusement - Precision: 0.3091, Recall: 0.6892, F1-Score: 0.4268\n",
      "anger - Precision: 0.2335, Recall: 0.6667, F1-Score: 0.3458\n",
      "annoyance - Precision: 0.1972, Recall: 0.1000, F1-Score: 0.1327\n",
      "approval - Precision: 0.2805, Recall: 0.1329, F1-Score: 0.1804\n",
      "caring - Precision: 0.3333, Recall: 0.2923, F1-Score: 0.3115\n",
      "confusion - Precision: 0.1500, Recall: 0.5294, F1-Score: 0.2338\n",
      "curiosity - Precision: 0.2236, Recall: 0.3130, F1-Score: 0.2609\n",
      "desire - Precision: 0.3684, Recall: 0.2059, F1-Score: 0.2642\n",
      "disappointment - Precision: 0.1587, Recall: 0.2532, F1-Score: 0.1951\n",
      "disapproval - Precision: 0.2020, Recall: 0.2878, F1-Score: 0.2374\n",
      "disgust - Precision: 0.3864, Recall: 0.3333, F1-Score: 0.3579\n",
      "embarrassment - Precision: 0.2857, Recall: 0.2667, F1-Score: 0.2759\n",
      "excitement - Precision: 0.2812, Recall: 0.2195, F1-Score: 0.2466\n",
      "fear - Precision: 0.3088, Recall: 0.4884, F1-Score: 0.3784\n",
      "gratitude - Precision: 0.9206, Recall: 0.3494, F1-Score: 0.5066\n",
      "grief - Precision: 0.3077, Recall: 0.4444, F1-Score: 0.3636\n",
      "joy - Precision: 0.1956, Recall: 0.4731, F1-Score: 0.2767\n",
      "love - Precision: 0.7632, Recall: 0.2685, F1-Score: 0.3973\n",
      "nervousness - Precision: 0.3333, Recall: 0.1818, F1-Score: 0.2353\n",
      "optimism - Precision: 0.4030, Recall: 0.2571, F1-Score: 0.3140\n",
      "pride - Precision: 0.3846, Recall: 0.5000, F1-Score: 0.4348\n",
      "realization - Precision: 0.2500, Recall: 0.0312, F1-Score: 0.0556\n",
      "relief - Precision: 0.0500, Recall: 0.1429, F1-Score: 0.0741\n",
      "remorse - Precision: 0.6667, Recall: 0.0526, F1-Score: 0.0976\n",
      "sadness - Precision: 0.3021, Recall: 0.4394, F1-Score: 0.3580\n",
      "surprise - Precision: 0.3778, Recall: 0.2787, F1-Score: 0.3208\n",
      "neutral - Precision: 0.6378, Recall: 0.1586, F1-Score: 0.2541\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1957\n",
      "Recall (Macro) 표준편차: 0.1673\n",
      "F1-Score (Macro) 표준편차: 0.1070\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4560\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5305\n",
      "Recall (Micro): 0.4886\n",
      "F1-Score (Micro): 0.5087\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4672\n",
      "Recall (Macro): 0.4849\n",
      "F1-Score (Macro): 0.4459\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3954, Recall: 0.6064, F1-Score: 0.4787\n",
      "disgust - Precision: 0.3864, Recall: 0.3333, F1-Score: 0.3579\n",
      "fear - Precision: 0.3784, Recall: 0.5283, F1-Score: 0.4409\n",
      "joy - Precision: 0.7077, Recall: 0.6783, F1-Score: 0.6926\n",
      "sadness - Precision: 0.4008, Recall: 0.5260, F1-Score: 0.4550\n",
      "surprise - Precision: 0.3642, Recall: 0.5631, F1-Score: 0.4424\n",
      "neutral - Precision: 0.6378, Recall: 0.1586, F1-Score: 0.2541\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1317\n",
      "Recall (Macro) 표준편차: 0.1653\n",
      "F1-Score (Macro) 표준편차: 0.1234\n",
      "-------------------------- 15--------------------------\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2224\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3122\n",
      "Recall (Micro): 0.2704\n",
      "F1-Score (Micro): 0.2898\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3664\n",
      "Recall (Macro): 0.3153\n",
      "F1-Score (Macro): 0.2898\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.6842, Recall: 0.1711, F1-Score: 0.2737\n",
      "amusement - Precision: 0.3056, Recall: 0.6959, F1-Score: 0.4247\n",
      "anger - Precision: 0.2372, Recall: 0.6667, F1-Score: 0.3499\n",
      "annoyance - Precision: 0.1806, Recall: 0.0929, F1-Score: 0.1226\n",
      "approval - Precision: 0.2738, Recall: 0.1329, F1-Score: 0.1790\n",
      "caring - Precision: 0.3175, Recall: 0.3077, F1-Score: 0.3125\n",
      "confusion - Precision: 0.1504, Recall: 0.5000, F1-Score: 0.2313\n",
      "curiosity - Precision: 0.2189, Recall: 0.3217, F1-Score: 0.2606\n",
      "desire - Precision: 0.3889, Recall: 0.2059, F1-Score: 0.2692\n",
      "disappointment - Precision: 0.1562, Recall: 0.2532, F1-Score: 0.1932\n",
      "disapproval - Precision: 0.2172, Recall: 0.3094, F1-Score: 0.2552\n",
      "disgust - Precision: 0.4286, Recall: 0.3529, F1-Score: 0.3871\n",
      "embarrassment - Precision: 0.4615, Recall: 0.4000, F1-Score: 0.4286\n",
      "excitement - Precision: 0.2647, Recall: 0.2195, F1-Score: 0.2400\n",
      "fear - Precision: 0.2958, Recall: 0.4884, F1-Score: 0.3684\n",
      "gratitude - Precision: 0.8939, Recall: 0.3554, F1-Score: 0.5086\n",
      "grief - Precision: 0.3333, Recall: 0.4444, F1-Score: 0.3810\n",
      "joy - Precision: 0.1886, Recall: 0.4624, F1-Score: 0.2679\n",
      "love - Precision: 0.7500, Recall: 0.2778, F1-Score: 0.4054\n",
      "nervousness - Precision: 0.3333, Recall: 0.1818, F1-Score: 0.2353\n",
      "optimism - Precision: 0.3867, Recall: 0.2762, F1-Score: 0.3222\n",
      "pride - Precision: 0.4615, Recall: 0.6000, F1-Score: 0.5217\n",
      "realization - Precision: 0.2500, Recall: 0.0312, F1-Score: 0.0556\n",
      "relief - Precision: 0.0500, Recall: 0.1429, F1-Score: 0.0741\n",
      "remorse - Precision: 0.6667, Recall: 0.0526, F1-Score: 0.0976\n",
      "sadness - Precision: 0.3298, Recall: 0.4697, F1-Score: 0.3875\n",
      "surprise - Precision: 0.3902, Recall: 0.2623, F1-Score: 0.3137\n",
      "neutral - Precision: 0.6436, Recall: 0.1536, F1-Score: 0.2480\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1966\n",
      "Recall (Macro) 표준편차: 0.1736\n",
      "F1-Score (Macro) 표준편차: 0.1185\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4544\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5296\n",
      "Recall (Micro): 0.4875\n",
      "F1-Score (Micro): 0.5077\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4695\n",
      "Recall (Macro): 0.4826\n",
      "F1-Score (Macro): 0.4450\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3958, Recall: 0.6035, F1-Score: 0.4781\n",
      "disgust - Precision: 0.4286, Recall: 0.3529, F1-Score: 0.3871\n",
      "fear - Precision: 0.3636, Recall: 0.5283, F1-Score: 0.4308\n",
      "joy - Precision: 0.7048, Recall: 0.6899, F1-Score: 0.6973\n",
      "sadness - Precision: 0.4000, Recall: 0.5208, F1-Score: 0.4525\n",
      "surprise - Precision: 0.3499, Recall: 0.5290, F1-Score: 0.4212\n",
      "neutral - Precision: 0.6436, Recall: 0.1536, F1-Score: 0.2480\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1326\n",
      "Recall (Macro) 표준편차: 0.1640\n",
      "F1-Score (Macro) 표준편차: 0.1241\n",
      "-------------------------- 16--------------------------\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2256\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3142\n",
      "Recall (Micro): 0.2717\n",
      "F1-Score (Micro): 0.2914\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3740\n",
      "Recall (Macro): 0.3152\n",
      "F1-Score (Macro): 0.2909\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.6667, Recall: 0.1754, F1-Score: 0.2778\n",
      "amusement - Precision: 0.3038, Recall: 0.6959, F1-Score: 0.4230\n",
      "anger - Precision: 0.2379, Recall: 0.6556, F1-Score: 0.3491\n",
      "annoyance - Precision: 0.1918, Recall: 0.1000, F1-Score: 0.1315\n",
      "approval - Precision: 0.2805, Recall: 0.1329, F1-Score: 0.1804\n",
      "caring - Precision: 0.3455, Recall: 0.2923, F1-Score: 0.3167\n",
      "confusion - Precision: 0.1478, Recall: 0.5000, F1-Score: 0.2282\n",
      "curiosity - Precision: 0.2156, Recall: 0.3130, F1-Score: 0.2553\n",
      "desire - Precision: 0.4118, Recall: 0.2059, F1-Score: 0.2745\n",
      "disappointment - Precision: 0.1473, Recall: 0.2405, F1-Score: 0.1827\n",
      "disapproval - Precision: 0.2136, Recall: 0.3165, F1-Score: 0.2551\n",
      "disgust - Precision: 0.3810, Recall: 0.3137, F1-Score: 0.3441\n",
      "embarrassment - Precision: 0.4615, Recall: 0.4000, F1-Score: 0.4286\n",
      "excitement - Precision: 0.2647, Recall: 0.2195, F1-Score: 0.2400\n",
      "fear - Precision: 0.3000, Recall: 0.4884, F1-Score: 0.3717\n",
      "gratitude - Precision: 0.8955, Recall: 0.3614, F1-Score: 0.5150\n",
      "grief - Precision: 0.3077, Recall: 0.4444, F1-Score: 0.3636\n",
      "joy - Precision: 0.2044, Recall: 0.4946, F1-Score: 0.2893\n",
      "love - Precision: 0.7442, Recall: 0.2963, F1-Score: 0.4238\n",
      "nervousness - Precision: 0.5000, Recall: 0.1818, F1-Score: 0.2667\n",
      "optimism - Precision: 0.3944, Recall: 0.2667, F1-Score: 0.3182\n",
      "pride - Precision: 0.4286, Recall: 0.6000, F1-Score: 0.5000\n",
      "realization - Precision: 0.3333, Recall: 0.0469, F1-Score: 0.0822\n",
      "relief - Precision: 0.0556, Recall: 0.1429, F1-Score: 0.0800\n",
      "remorse - Precision: 0.6667, Recall: 0.0526, F1-Score: 0.0976\n",
      "sadness - Precision: 0.3093, Recall: 0.4545, F1-Score: 0.3681\n",
      "surprise - Precision: 0.4048, Recall: 0.2787, F1-Score: 0.3301\n",
      "neutral - Precision: 0.6595, Recall: 0.1548, F1-Score: 0.2508\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1954\n",
      "Recall (Macro) 표준편차: 0.1720\n",
      "F1-Score (Macro) 표준편차: 0.1136\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4532\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5276\n",
      "Recall (Micro): 0.4857\n",
      "F1-Score (Micro): 0.5058\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4657\n",
      "Recall (Macro): 0.4775\n",
      "F1-Score (Macro): 0.4398\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3947, Recall: 0.6064, F1-Score: 0.4782\n",
      "disgust - Precision: 0.3810, Recall: 0.3137, F1-Score: 0.3441\n",
      "fear - Precision: 0.3784, Recall: 0.5283, F1-Score: 0.4409\n",
      "joy - Precision: 0.7038, Recall: 0.6841, F1-Score: 0.6938\n",
      "sadness - Precision: 0.3961, Recall: 0.5260, F1-Score: 0.4519\n",
      "surprise - Precision: 0.3468, Recall: 0.5290, F1-Score: 0.4189\n",
      "neutral - Precision: 0.6595, Recall: 0.1548, F1-Score: 0.2508\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1379\n",
      "Recall (Macro) 표준편차: 0.1681\n",
      "F1-Score (Macro) 표준편차: 0.1262\n",
      "-------------------------- 17--------------------------\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2236\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3113\n",
      "Recall (Micro): 0.2694\n",
      "F1-Score (Micro): 0.2888\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3605\n",
      "Recall (Macro): 0.3136\n",
      "F1-Score (Macro): 0.2869\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.6667, Recall: 0.1754, F1-Score: 0.2778\n",
      "amusement - Precision: 0.3036, Recall: 0.6892, F1-Score: 0.4215\n",
      "anger - Precision: 0.2392, Recall: 0.6778, F1-Score: 0.3536\n",
      "annoyance - Precision: 0.1765, Recall: 0.0857, F1-Score: 0.1154\n",
      "approval - Precision: 0.2651, Recall: 0.1272, F1-Score: 0.1719\n",
      "caring - Precision: 0.3115, Recall: 0.2923, F1-Score: 0.3016\n",
      "confusion - Precision: 0.1459, Recall: 0.5000, F1-Score: 0.2259\n",
      "curiosity - Precision: 0.2209, Recall: 0.3130, F1-Score: 0.2590\n",
      "desire - Precision: 0.3500, Recall: 0.2059, F1-Score: 0.2593\n",
      "disappointment - Precision: 0.1603, Recall: 0.2658, F1-Score: 0.2000\n",
      "disapproval - Precision: 0.2132, Recall: 0.3022, F1-Score: 0.2500\n",
      "disgust - Precision: 0.3947, Recall: 0.2941, F1-Score: 0.3371\n",
      "embarrassment - Precision: 0.4615, Recall: 0.4000, F1-Score: 0.4286\n",
      "excitement - Precision: 0.2647, Recall: 0.2195, F1-Score: 0.2400\n",
      "fear - Precision: 0.2877, Recall: 0.4884, F1-Score: 0.3621\n",
      "gratitude - Precision: 0.8824, Recall: 0.3614, F1-Score: 0.5128\n",
      "grief - Precision: 0.3333, Recall: 0.4444, F1-Score: 0.3810\n",
      "joy - Precision: 0.1964, Recall: 0.4731, F1-Score: 0.2776\n",
      "love - Precision: 0.7500, Recall: 0.3056, F1-Score: 0.4342\n",
      "nervousness - Precision: 0.2857, Recall: 0.1818, F1-Score: 0.2222\n",
      "optimism - Precision: 0.4000, Recall: 0.2667, F1-Score: 0.3200\n",
      "pride - Precision: 0.4286, Recall: 0.6000, F1-Score: 0.5000\n",
      "realization - Precision: 0.2857, Recall: 0.0312, F1-Score: 0.0563\n",
      "relief - Precision: 0.0588, Recall: 0.1429, F1-Score: 0.0833\n",
      "remorse - Precision: 0.6667, Recall: 0.0526, F1-Score: 0.0976\n",
      "sadness - Precision: 0.3191, Recall: 0.4545, F1-Score: 0.3750\n",
      "surprise - Precision: 0.3864, Recall: 0.2787, F1-Score: 0.3238\n",
      "neutral - Precision: 0.6383, Recall: 0.1523, F1-Score: 0.2459\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1931\n",
      "Recall (Macro) 표준편차: 0.1739\n",
      "F1-Score (Macro) 표준편차: 0.1171\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4536\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5283\n",
      "Recall (Micro): 0.4871\n",
      "F1-Score (Micro): 0.5069\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4627\n",
      "Recall (Macro): 0.4763\n",
      "F1-Score (Macro): 0.4375\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3981, Recall: 0.6035, F1-Score: 0.4797\n",
      "disgust - Precision: 0.3947, Recall: 0.2941, F1-Score: 0.3371\n",
      "fear - Precision: 0.3500, Recall: 0.5283, F1-Score: 0.4211\n",
      "joy - Precision: 0.7025, Recall: 0.6889, F1-Score: 0.6956\n",
      "sadness - Precision: 0.4032, Recall: 0.5312, F1-Score: 0.4584\n",
      "surprise - Precision: 0.3520, Recall: 0.5358, F1-Score: 0.4249\n",
      "neutral - Precision: 0.6383, Recall: 0.1523, F1-Score: 0.2459\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1340\n",
      "Recall (Macro) 표준편차: 0.1727\n",
      "F1-Score (Macro) 표준편차: 0.1288\n",
      "-------------------------- 18--------------------------\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2240\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3108\n",
      "Recall (Micro): 0.2697\n",
      "F1-Score (Micro): 0.2888\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3802\n",
      "Recall (Macro): 0.3142\n",
      "F1-Score (Macro): 0.2914\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.6970, Recall: 0.2018, F1-Score: 0.3129\n",
      "amusement - Precision: 0.3003, Recall: 0.6757, F1-Score: 0.4158\n",
      "anger - Precision: 0.2346, Recall: 0.6778, F1-Score: 0.3486\n",
      "annoyance - Precision: 0.1912, Recall: 0.0929, F1-Score: 0.1250\n",
      "approval - Precision: 0.2333, Recall: 0.1214, F1-Score: 0.1597\n",
      "caring - Precision: 0.3115, Recall: 0.2923, F1-Score: 0.3016\n",
      "confusion - Precision: 0.1496, Recall: 0.5147, F1-Score: 0.2318\n",
      "curiosity - Precision: 0.2294, Recall: 0.3391, F1-Score: 0.2737\n",
      "desire - Precision: 0.4375, Recall: 0.2059, F1-Score: 0.2800\n",
      "disappointment - Precision: 0.1615, Recall: 0.2658, F1-Score: 0.2010\n",
      "disapproval - Precision: 0.1951, Recall: 0.2878, F1-Score: 0.2326\n",
      "disgust - Precision: 0.4324, Recall: 0.3137, F1-Score: 0.3636\n",
      "embarrassment - Precision: 0.4615, Recall: 0.4000, F1-Score: 0.4286\n",
      "excitement - Precision: 0.2727, Recall: 0.2195, F1-Score: 0.2432\n",
      "fear - Precision: 0.3000, Recall: 0.4884, F1-Score: 0.3717\n",
      "gratitude - Precision: 0.8939, Recall: 0.3554, F1-Score: 0.5086\n",
      "grief - Precision: 0.3077, Recall: 0.4444, F1-Score: 0.3636\n",
      "joy - Precision: 0.2027, Recall: 0.4839, F1-Score: 0.2857\n",
      "love - Precision: 0.7250, Recall: 0.2685, F1-Score: 0.3919\n",
      "nervousness - Precision: 0.6667, Recall: 0.1818, F1-Score: 0.2857\n",
      "optimism - Precision: 0.4030, Recall: 0.2571, F1-Score: 0.3140\n",
      "pride - Precision: 0.5000, Recall: 0.6000, F1-Score: 0.5455\n",
      "realization - Precision: 0.2500, Recall: 0.0312, F1-Score: 0.0556\n",
      "relief - Precision: 0.0476, Recall: 0.1429, F1-Score: 0.0714\n",
      "remorse - Precision: 0.6667, Recall: 0.0526, F1-Score: 0.0976\n",
      "sadness - Precision: 0.3229, Recall: 0.4697, F1-Score: 0.3827\n",
      "surprise - Precision: 0.4211, Recall: 0.2623, F1-Score: 0.3232\n",
      "neutral - Precision: 0.6296, Recall: 0.1510, F1-Score: 0.2436\n",
      "\n",
      "Precision (Macro) 표준편차: 0.2046\n",
      "Recall (Macro) 표준편차: 0.1740\n",
      "F1-Score (Macro) 표준편차: 0.1186\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4528\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5270\n",
      "Recall (Micro): 0.4860\n",
      "F1-Score (Micro): 0.5057\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4713\n",
      "Recall (Macro): 0.4806\n",
      "F1-Score (Macro): 0.4445\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3846, Recall: 0.5977, F1-Score: 0.4680\n",
      "disgust - Precision: 0.4324, Recall: 0.3137, F1-Score: 0.3636\n",
      "fear - Precision: 0.3836, Recall: 0.5283, F1-Score: 0.4444\n",
      "joy - Precision: 0.7025, Recall: 0.6821, F1-Score: 0.6922\n",
      "sadness - Precision: 0.4078, Recall: 0.5417, F1-Score: 0.4653\n",
      "surprise - Precision: 0.3586, Recall: 0.5495, F1-Score: 0.4340\n",
      "neutral - Precision: 0.6296, Recall: 0.1510, F1-Score: 0.2436\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1265\n",
      "Recall (Macro) 표준편차: 0.1697\n",
      "F1-Score (Macro) 표준편차: 0.1250\n",
      "-------------------------- 19--------------------------\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2208\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3074\n",
      "Recall (Micro): 0.2673\n",
      "F1-Score (Micro): 0.2860\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3690\n",
      "Recall (Macro): 0.3113\n",
      "F1-Score (Macro): 0.2888\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.6567, Recall: 0.1930, F1-Score: 0.2983\n",
      "amusement - Precision: 0.3093, Recall: 0.6959, F1-Score: 0.4283\n",
      "anger - Precision: 0.2290, Recall: 0.6667, F1-Score: 0.3409\n",
      "annoyance - Precision: 0.1842, Recall: 0.1000, F1-Score: 0.1296\n",
      "approval - Precision: 0.2317, Recall: 0.1098, F1-Score: 0.1490\n",
      "caring - Precision: 0.3036, Recall: 0.2615, F1-Score: 0.2810\n",
      "confusion - Precision: 0.1466, Recall: 0.5000, F1-Score: 0.2267\n",
      "curiosity - Precision: 0.2130, Recall: 0.3130, F1-Score: 0.2535\n",
      "desire - Precision: 0.3684, Recall: 0.2059, F1-Score: 0.2642\n",
      "disappointment - Precision: 0.1379, Recall: 0.2025, F1-Score: 0.1641\n",
      "disapproval - Precision: 0.1902, Recall: 0.2806, F1-Score: 0.2267\n",
      "disgust - Precision: 0.3810, Recall: 0.3137, F1-Score: 0.3441\n",
      "embarrassment - Precision: 0.3846, Recall: 0.3333, F1-Score: 0.3571\n",
      "excitement - Precision: 0.2903, Recall: 0.2195, F1-Score: 0.2500\n",
      "fear - Precision: 0.2838, Recall: 0.4884, F1-Score: 0.3590\n",
      "gratitude - Precision: 0.9062, Recall: 0.3494, F1-Score: 0.5043\n",
      "grief - Precision: 0.4000, Recall: 0.4444, F1-Score: 0.4211\n",
      "joy - Precision: 0.2080, Recall: 0.5054, F1-Score: 0.2947\n",
      "love - Precision: 0.7143, Recall: 0.2778, F1-Score: 0.4000\n",
      "nervousness - Precision: 0.5000, Recall: 0.2727, F1-Score: 0.3529\n",
      "optimism - Precision: 0.3906, Recall: 0.2381, F1-Score: 0.2959\n",
      "pride - Precision: 0.5000, Recall: 0.6000, F1-Score: 0.5455\n",
      "realization - Precision: 0.3333, Recall: 0.0469, F1-Score: 0.0822\n",
      "relief - Precision: 0.0500, Recall: 0.1429, F1-Score: 0.0741\n",
      "remorse - Precision: 0.6667, Recall: 0.0526, F1-Score: 0.0976\n",
      "sadness - Precision: 0.3048, Recall: 0.4848, F1-Score: 0.3743\n",
      "surprise - Precision: 0.4103, Recall: 0.2623, F1-Score: 0.3200\n",
      "neutral - Precision: 0.6373, Recall: 0.1561, F1-Score: 0.2508\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1960\n",
      "Recall (Macro) 표준편차: 0.1738\n",
      "F1-Score (Macro) 표준편차: 0.1177\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4500\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5232\n",
      "Recall (Micro): 0.4831\n",
      "F1-Score (Micro): 0.5024\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4585\n",
      "Recall (Macro): 0.4761\n",
      "F1-Score (Macro): 0.4360\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3812, Recall: 0.6035, F1-Score: 0.4673\n",
      "disgust - Precision: 0.3810, Recall: 0.3137, F1-Score: 0.3441\n",
      "fear - Precision: 0.3500, Recall: 0.5283, F1-Score: 0.4211\n",
      "joy - Precision: 0.7064, Recall: 0.6763, F1-Score: 0.6910\n",
      "sadness - Precision: 0.4008, Recall: 0.5156, F1-Score: 0.4510\n",
      "surprise - Precision: 0.3527, Recall: 0.5392, F1-Score: 0.4265\n",
      "neutral - Precision: 0.6373, Recall: 0.1561, F1-Score: 0.2508\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1372\n",
      "Recall (Macro) 표준편차: 0.1662\n",
      "F1-Score (Macro) 표준편차: 0.1250\n",
      "-------------------------- 20--------------------------\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2268\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3150\n",
      "Recall (Micro): 0.2728\n",
      "F1-Score (Micro): 0.2923\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3729\n",
      "Recall (Macro): 0.3172\n",
      "F1-Score (Macro): 0.2932\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.6667, Recall: 0.1754, F1-Score: 0.2778\n",
      "amusement - Precision: 0.3047, Recall: 0.6959, F1-Score: 0.4239\n",
      "anger - Precision: 0.2430, Recall: 0.6778, F1-Score: 0.3578\n",
      "annoyance - Precision: 0.1818, Recall: 0.1000, F1-Score: 0.1290\n",
      "approval - Precision: 0.2637, Recall: 0.1387, F1-Score: 0.1818\n",
      "caring - Precision: 0.3167, Recall: 0.2923, F1-Score: 0.3040\n",
      "confusion - Precision: 0.1528, Recall: 0.5147, F1-Score: 0.2357\n",
      "curiosity - Precision: 0.2262, Recall: 0.3304, F1-Score: 0.2686\n",
      "desire - Precision: 0.4118, Recall: 0.2059, F1-Score: 0.2745\n",
      "disappointment - Precision: 0.1603, Recall: 0.2658, F1-Score: 0.2000\n",
      "disapproval - Precision: 0.2073, Recall: 0.2878, F1-Score: 0.2410\n",
      "disgust - Precision: 0.4048, Recall: 0.3333, F1-Score: 0.3656\n",
      "embarrassment - Precision: 0.4286, Recall: 0.4000, F1-Score: 0.4138\n",
      "excitement - Precision: 0.2727, Recall: 0.2195, F1-Score: 0.2432\n",
      "fear - Precision: 0.3056, Recall: 0.5116, F1-Score: 0.3826\n",
      "gratitude - Precision: 0.9219, Recall: 0.3554, F1-Score: 0.5130\n",
      "grief - Precision: 0.3636, Recall: 0.4444, F1-Score: 0.4000\n",
      "joy - Precision: 0.1920, Recall: 0.4624, F1-Score: 0.2713\n",
      "love - Precision: 0.7619, Recall: 0.2963, F1-Score: 0.4267\n",
      "nervousness - Precision: 0.2857, Recall: 0.1818, F1-Score: 0.2222\n",
      "optimism - Precision: 0.4085, Recall: 0.2762, F1-Score: 0.3295\n",
      "pride - Precision: 0.5000, Recall: 0.6000, F1-Score: 0.5455\n",
      "realization - Precision: 0.3750, Recall: 0.0469, F1-Score: 0.0833\n",
      "relief - Precision: 0.0556, Recall: 0.1429, F1-Score: 0.0800\n",
      "remorse - Precision: 0.6667, Recall: 0.0526, F1-Score: 0.0976\n",
      "sadness - Precision: 0.3191, Recall: 0.4545, F1-Score: 0.3750\n",
      "surprise - Precision: 0.3902, Recall: 0.2623, F1-Score: 0.3137\n",
      "neutral - Precision: 0.6543, Recall: 0.1561, F1-Score: 0.2520\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1984\n",
      "Recall (Macro) 표준편차: 0.1735\n",
      "F1-Score (Macro) 표준편차: 0.1182\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4560\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5311\n",
      "Recall (Micro): 0.4893\n",
      "F1-Score (Micro): 0.5094\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4690\n",
      "Recall (Macro): 0.4845\n",
      "F1-Score (Macro): 0.4448\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3973, Recall: 0.6035, F1-Score: 0.4792\n",
      "disgust - Precision: 0.4048, Recall: 0.3333, F1-Score: 0.3656\n",
      "fear - Precision: 0.3671, Recall: 0.5472, F1-Score: 0.4394\n",
      "joy - Precision: 0.7079, Recall: 0.6908, F1-Score: 0.6993\n",
      "sadness - Precision: 0.4032, Recall: 0.5312, F1-Score: 0.4584\n",
      "surprise - Precision: 0.3483, Recall: 0.5290, F1-Score: 0.4201\n",
      "neutral - Precision: 0.6543, Recall: 0.1561, F1-Score: 0.2520\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1363\n",
      "Recall (Macro) 표준편차: 0.1671\n",
      "F1-Score (Macro) 표준편차: 0.1255\n",
      "-------------------------- 21--------------------------\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2268\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3158\n",
      "Recall (Micro): 0.2738\n",
      "F1-Score (Micro): 0.2933\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3763\n",
      "Recall (Macro): 0.3167\n",
      "F1-Score (Macro): 0.2940\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.7091, Recall: 0.1711, F1-Score: 0.2756\n",
      "amusement - Precision: 0.3018, Recall: 0.6892, F1-Score: 0.4198\n",
      "anger - Precision: 0.2410, Recall: 0.6667, F1-Score: 0.3540\n",
      "annoyance - Precision: 0.1892, Recall: 0.1000, F1-Score: 0.1308\n",
      "approval - Precision: 0.2500, Recall: 0.1214, F1-Score: 0.1634\n",
      "caring - Precision: 0.3333, Recall: 0.3077, F1-Score: 0.3200\n",
      "confusion - Precision: 0.1511, Recall: 0.5000, F1-Score: 0.2321\n",
      "curiosity - Precision: 0.2299, Recall: 0.3478, F1-Score: 0.2768\n",
      "desire - Precision: 0.4375, Recall: 0.2059, F1-Score: 0.2800\n",
      "disappointment - Precision: 0.1603, Recall: 0.2658, F1-Score: 0.2000\n",
      "disapproval - Precision: 0.2092, Recall: 0.2950, F1-Score: 0.2448\n",
      "disgust - Precision: 0.4000, Recall: 0.3137, F1-Score: 0.3516\n",
      "embarrassment - Precision: 0.4615, Recall: 0.4000, F1-Score: 0.4286\n",
      "excitement - Precision: 0.2571, Recall: 0.2195, F1-Score: 0.2368\n",
      "fear - Precision: 0.3000, Recall: 0.4884, F1-Score: 0.3717\n",
      "gratitude - Precision: 0.8955, Recall: 0.3614, F1-Score: 0.5150\n",
      "grief - Precision: 0.3636, Recall: 0.4444, F1-Score: 0.4000\n",
      "joy - Precision: 0.1928, Recall: 0.4624, F1-Score: 0.2722\n",
      "love - Precision: 0.7500, Recall: 0.3056, F1-Score: 0.4342\n",
      "nervousness - Precision: 0.4000, Recall: 0.1818, F1-Score: 0.2500\n",
      "optimism - Precision: 0.3733, Recall: 0.2667, F1-Score: 0.3111\n",
      "pride - Precision: 0.5000, Recall: 0.6000, F1-Score: 0.5455\n",
      "realization - Precision: 0.3333, Recall: 0.0469, F1-Score: 0.0822\n",
      "relief - Precision: 0.0476, Recall: 0.1429, F1-Score: 0.0714\n",
      "remorse - Precision: 0.6667, Recall: 0.0526, F1-Score: 0.0976\n",
      "sadness - Precision: 0.3163, Recall: 0.4697, F1-Score: 0.3780\n",
      "surprise - Precision: 0.3953, Recall: 0.2787, F1-Score: 0.3269\n",
      "neutral - Precision: 0.6702, Recall: 0.1624, F1-Score: 0.2615\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1990\n",
      "Recall (Macro) 표준편차: 0.1717\n",
      "F1-Score (Macro) 표준편차: 0.1193\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4580\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5327\n",
      "Recall (Micro): 0.4911\n",
      "F1-Score (Micro): 0.5110\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4720\n",
      "Recall (Macro): 0.4822\n",
      "F1-Score (Macro): 0.4451\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3969, Recall: 0.6006, F1-Score: 0.4780\n",
      "disgust - Precision: 0.4000, Recall: 0.3137, F1-Score: 0.3516\n",
      "fear - Precision: 0.3733, Recall: 0.5283, F1-Score: 0.4375\n",
      "joy - Precision: 0.7056, Recall: 0.6879, F1-Score: 0.6967\n",
      "sadness - Precision: 0.4023, Recall: 0.5365, F1-Score: 0.4598\n",
      "surprise - Precision: 0.3556, Recall: 0.5461, F1-Score: 0.4307\n",
      "neutral - Precision: 0.6702, Recall: 0.1624, F1-Score: 0.2615\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1378\n",
      "Recall (Macro) 표준편차: 0.1674\n",
      "F1-Score (Macro) 표준편차: 0.1238\n",
      "-------------------------- 22--------------------------\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2216\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3092\n",
      "Recall (Micro): 0.2677\n",
      "F1-Score (Micro): 0.2870\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3559\n",
      "Recall (Macro): 0.3089\n",
      "F1-Score (Macro): 0.2817\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.6780, Recall: 0.1754, F1-Score: 0.2787\n",
      "amusement - Precision: 0.3118, Recall: 0.7162, F1-Score: 0.4344\n",
      "anger - Precision: 0.2374, Recall: 0.6778, F1-Score: 0.3516\n",
      "annoyance - Precision: 0.1857, Recall: 0.0929, F1-Score: 0.1238\n",
      "approval - Precision: 0.2530, Recall: 0.1214, F1-Score: 0.1641\n",
      "caring - Precision: 0.3226, Recall: 0.3077, F1-Score: 0.3150\n",
      "confusion - Precision: 0.1447, Recall: 0.4853, F1-Score: 0.2230\n",
      "curiosity - Precision: 0.2176, Recall: 0.3217, F1-Score: 0.2596\n",
      "desire - Precision: 0.3333, Recall: 0.1765, F1-Score: 0.2308\n",
      "disappointment - Precision: 0.1504, Recall: 0.2532, F1-Score: 0.1887\n",
      "disapproval - Precision: 0.2000, Recall: 0.2734, F1-Score: 0.2310\n",
      "disgust - Precision: 0.4000, Recall: 0.3137, F1-Score: 0.3516\n",
      "embarrassment - Precision: 0.3571, Recall: 0.3333, F1-Score: 0.3448\n",
      "excitement - Precision: 0.2571, Recall: 0.2195, F1-Score: 0.2368\n",
      "fear - Precision: 0.3056, Recall: 0.5116, F1-Score: 0.3826\n",
      "gratitude - Precision: 0.9032, Recall: 0.3373, F1-Score: 0.4912\n",
      "grief - Precision: 0.4000, Recall: 0.4444, F1-Score: 0.4211\n",
      "joy - Precision: 0.1964, Recall: 0.4731, F1-Score: 0.2776\n",
      "love - Precision: 0.7381, Recall: 0.2870, F1-Score: 0.4133\n",
      "nervousness - Precision: 0.4000, Recall: 0.1818, F1-Score: 0.2500\n",
      "optimism - Precision: 0.4030, Recall: 0.2571, F1-Score: 0.3140\n",
      "pride - Precision: 0.4000, Recall: 0.6000, F1-Score: 0.4800\n",
      "realization - Precision: 0.2857, Recall: 0.0312, F1-Score: 0.0563\n",
      "relief - Precision: 0.0526, Recall: 0.1429, F1-Score: 0.0769\n",
      "remorse - Precision: 0.5000, Recall: 0.0263, F1-Score: 0.0500\n",
      "sadness - Precision: 0.3196, Recall: 0.4697, F1-Score: 0.3804\n",
      "surprise - Precision: 0.3810, Recall: 0.2623, F1-Score: 0.3107\n",
      "neutral - Precision: 0.6308, Recall: 0.1561, F1-Score: 0.2503\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1871\n",
      "Recall (Macro) 표준편차: 0.1783\n",
      "F1-Score (Macro) 표준편차: 0.1176\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4528\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5272\n",
      "Recall (Micro): 0.4860\n",
      "F1-Score (Micro): 0.5058\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4641\n",
      "Recall (Macro): 0.4791\n",
      "F1-Score (Macro): 0.4413\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3946, Recall: 0.5948, F1-Score: 0.4744\n",
      "disgust - Precision: 0.4000, Recall: 0.3137, F1-Score: 0.3516\n",
      "fear - Precision: 0.3766, Recall: 0.5472, F1-Score: 0.4462\n",
      "joy - Precision: 0.7040, Recall: 0.6870, F1-Score: 0.6954\n",
      "sadness - Precision: 0.3945, Recall: 0.5260, F1-Score: 0.4509\n",
      "surprise - Precision: 0.3483, Recall: 0.5290, F1-Score: 0.4201\n",
      "neutral - Precision: 0.6308, Recall: 0.1561, F1-Score: 0.2503\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1310\n",
      "Recall (Macro) 표준편차: 0.1680\n",
      "F1-Score (Macro) 표준편차: 0.1258\n",
      "-------------------------- 23--------------------------\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2204\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3067\n",
      "Recall (Micro): 0.2653\n",
      "F1-Score (Micro): 0.2845\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3555\n",
      "Recall (Macro): 0.3048\n",
      "F1-Score (Macro): 0.2806\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.7115, Recall: 0.1623, F1-Score: 0.2643\n",
      "amusement - Precision: 0.3021, Recall: 0.6959, F1-Score: 0.4213\n",
      "anger - Precision: 0.2332, Recall: 0.6556, F1-Score: 0.3440\n",
      "annoyance - Precision: 0.1711, Recall: 0.0929, F1-Score: 0.1204\n",
      "approval - Precision: 0.2391, Recall: 0.1272, F1-Score: 0.1660\n",
      "caring - Precision: 0.3390, Recall: 0.3077, F1-Score: 0.3226\n",
      "confusion - Precision: 0.1391, Recall: 0.4706, F1-Score: 0.2148\n",
      "curiosity - Precision: 0.2105, Recall: 0.3130, F1-Score: 0.2517\n",
      "desire - Precision: 0.3529, Recall: 0.1765, F1-Score: 0.2353\n",
      "disappointment - Precision: 0.1691, Recall: 0.2911, F1-Score: 0.2140\n",
      "disapproval - Precision: 0.2147, Recall: 0.2950, F1-Score: 0.2485\n",
      "disgust - Precision: 0.4186, Recall: 0.3529, F1-Score: 0.3830\n",
      "embarrassment - Precision: 0.3333, Recall: 0.2667, F1-Score: 0.2963\n",
      "excitement - Precision: 0.2308, Recall: 0.2195, F1-Score: 0.2250\n",
      "fear - Precision: 0.2958, Recall: 0.4884, F1-Score: 0.3684\n",
      "gratitude - Precision: 0.9206, Recall: 0.3494, F1-Score: 0.5066\n",
      "grief - Precision: 0.4000, Recall: 0.4444, F1-Score: 0.4211\n",
      "joy - Precision: 0.2018, Recall: 0.4731, F1-Score: 0.2830\n",
      "love - Precision: 0.7442, Recall: 0.2963, F1-Score: 0.4238\n",
      "nervousness - Precision: 0.4000, Recall: 0.1818, F1-Score: 0.2500\n",
      "optimism - Precision: 0.4242, Recall: 0.2667, F1-Score: 0.3275\n",
      "pride - Precision: 0.3846, Recall: 0.5000, F1-Score: 0.4348\n",
      "realization - Precision: 0.2222, Recall: 0.0312, F1-Score: 0.0548\n",
      "relief - Precision: 0.0526, Recall: 0.1429, F1-Score: 0.0769\n",
      "remorse - Precision: 0.5000, Recall: 0.0263, F1-Score: 0.0500\n",
      "sadness - Precision: 0.3299, Recall: 0.4848, F1-Score: 0.3926\n",
      "surprise - Precision: 0.3953, Recall: 0.2787, F1-Score: 0.3269\n",
      "neutral - Precision: 0.6162, Recall: 0.1447, F1-Score: 0.2343\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1930\n",
      "Recall (Macro) 표준편차: 0.1694\n",
      "F1-Score (Macro) 표준편차: 0.1164\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4488\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5217\n",
      "Recall (Micro): 0.4802\n",
      "F1-Score (Micro): 0.5001\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4617\n",
      "Recall (Macro): 0.4788\n",
      "F1-Score (Macro): 0.4398\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3931, Recall: 0.5948, F1-Score: 0.4733\n",
      "disgust - Precision: 0.4186, Recall: 0.3529, F1-Score: 0.3830\n",
      "fear - Precision: 0.3684, Recall: 0.5283, F1-Score: 0.4341\n",
      "joy - Precision: 0.7015, Recall: 0.6812, F1-Score: 0.6912\n",
      "sadness - Precision: 0.3969, Recall: 0.5312, F1-Score: 0.4543\n",
      "surprise - Precision: 0.3370, Recall: 0.5188, F1-Score: 0.4086\n",
      "neutral - Precision: 0.6162, Recall: 0.1447, F1-Score: 0.2343\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1289\n",
      "Recall (Macro) 표준편차: 0.1642\n",
      "F1-Score (Macro) 표준편차: 0.1259\n",
      "-------------------------- 24--------------------------\n",
      "{'id': 'batch_req_68f59f7132308190b8b85db7a335680d', 'custom_id': 'query660', 'response': {'status_code': 200, 'request_id': 'c775f5e0aff3d8b7c2af38f5b5093140', 'body': {'id': 'resp_09a241848fd66e940068f59b48e50481a3a66199a5f4b3d462', 'object': 'response', 'created_at': 1760926536, 'status': 'incomplete', 'background': False, 'billing': {'payer': 'developer'}, 'error': None, 'incomplete_details': {'reason': 'max_output_tokens'}, 'instructions': None, 'max_output_tokens': 1000, 'max_tool_calls': None, 'model': 'gpt-4o-mini-2024-07-18', 'output': [{'id': 'msg_09a241848fd66e940068f59b491d2881a39a6cf765341b1f5d', 'type': 'message', 'status': 'incomplete', 'content': [{'type': 'output_text', 'annotations': [], 'logprobs': [], 'text': '{\"analysis\":[{\"emotion\":\"disappointment\",\"reason\":\"The phrase \\'realize that this whole \" \\n    \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r    \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r    \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r   \\r  '}], 'role': 'assistant'}], 'parallel_tool_calls': True, 'previous_response_id': None, 'prompt_cache_key': None, 'reasoning': {'effort': None, 'summary': None}, 'safety_identifier': None, 'service_tier': 'default', 'store': True, 'temperature': 1.0, 'text': {'format': {'type': 'json_schema', 'description': None, 'name': 'result', 'schema': {'type': 'object', 'properties': {'analysis': {'type': 'array', 'items': {'type': 'object', 'properties': {'emotion': {'type': 'string', 'enum': ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']}, 'reason': {'type': 'string'}}, 'required': ['emotion', 'reason'], 'additionalProperties': False}}}, 'required': ['analysis'], 'additionalProperties': False}, 'strict': True}, 'verbosity': 'medium'}, 'tool_choice': 'auto', 'tools': [], 'top_logprobs': 0, 'top_p': 1.0, 'truncation': 'disabled', 'usage': {'input_tokens': 676, 'input_tokens_details': {'cached_tokens': 0}, 'output_tokens': 1000, 'output_tokens_details': {'reasoning_tokens': 0}, 'total_tokens': 1676}, 'user': None, 'metadata': {}}}, 'error': None}\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2212\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3050\n",
      "Recall (Micro): 0.2633\n",
      "F1-Score (Micro): 0.2826\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3707\n",
      "Recall (Macro): 0.3033\n",
      "F1-Score (Macro): 0.2853\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.6964, Recall: 0.1711, F1-Score: 0.2746\n",
      "amusement - Precision: 0.3061, Recall: 0.6824, F1-Score: 0.4226\n",
      "anger - Precision: 0.2278, Recall: 0.6556, F1-Score: 0.3381\n",
      "annoyance - Precision: 0.1449, Recall: 0.0714, F1-Score: 0.0957\n",
      "approval - Precision: 0.2308, Recall: 0.1214, F1-Score: 0.1591\n",
      "caring - Precision: 0.3667, Recall: 0.3385, F1-Score: 0.3520\n",
      "confusion - Precision: 0.1372, Recall: 0.4559, F1-Score: 0.2109\n",
      "curiosity - Precision: 0.2047, Recall: 0.3043, F1-Score: 0.2448\n",
      "desire - Precision: 0.4444, Recall: 0.2353, F1-Score: 0.3077\n",
      "disappointment - Precision: 0.1641, Recall: 0.2658, F1-Score: 0.2029\n",
      "disapproval - Precision: 0.1796, Recall: 0.2662, F1-Score: 0.2145\n",
      "disgust - Precision: 0.3333, Recall: 0.2745, F1-Score: 0.3011\n",
      "embarrassment - Precision: 0.5000, Recall: 0.4000, F1-Score: 0.4444\n",
      "excitement - Precision: 0.2250, Recall: 0.2195, F1-Score: 0.2222\n",
      "fear - Precision: 0.2941, Recall: 0.4651, F1-Score: 0.3604\n",
      "gratitude - Precision: 0.9219, Recall: 0.3554, F1-Score: 0.5130\n",
      "grief - Precision: 0.3750, Recall: 0.3333, F1-Score: 0.3529\n",
      "joy - Precision: 0.2000, Recall: 0.4839, F1-Score: 0.2830\n",
      "love - Precision: 0.7073, Recall: 0.2685, F1-Score: 0.3893\n",
      "nervousness - Precision: 0.4000, Recall: 0.1818, F1-Score: 0.2500\n",
      "optimism - Precision: 0.4032, Recall: 0.2381, F1-Score: 0.2994\n",
      "pride - Precision: 0.4545, Recall: 0.5000, F1-Score: 0.4762\n",
      "realization - Precision: 0.3333, Recall: 0.0469, F1-Score: 0.0822\n",
      "relief - Precision: 0.0667, Recall: 0.1429, F1-Score: 0.0909\n",
      "remorse - Precision: 0.6667, Recall: 0.0526, F1-Score: 0.0976\n",
      "sadness - Precision: 0.3400, Recall: 0.5152, F1-Score: 0.4096\n",
      "surprise - Precision: 0.4286, Recall: 0.2951, F1-Score: 0.3495\n",
      "neutral - Precision: 0.6263, Recall: 0.1510, F1-Score: 0.2434\n",
      "\n",
      "Precision (Macro) 표준편차: 0.2000\n",
      "Recall (Macro) 표준편차: 0.1653\n",
      "F1-Score (Macro) 표준편차: 0.1155\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4496\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5213\n",
      "Recall (Micro): 0.4795\n",
      "F1-Score (Micro): 0.4995\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4524\n",
      "Recall (Macro): 0.4663\n",
      "F1-Score (Macro): 0.4295\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3790, Recall: 0.5889, F1-Score: 0.4612\n",
      "disgust - Precision: 0.3333, Recall: 0.2745, F1-Score: 0.3011\n",
      "fear - Precision: 0.3699, Recall: 0.5094, F1-Score: 0.4286\n",
      "joy - Precision: 0.7027, Recall: 0.6783, F1-Score: 0.6903\n",
      "sadness - Precision: 0.4104, Recall: 0.5365, F1-Score: 0.4650\n",
      "surprise - Precision: 0.3453, Recall: 0.5256, F1-Score: 0.4168\n",
      "neutral - Precision: 0.6263, Recall: 0.1510, F1-Score: 0.2434\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1376\n",
      "Recall (Macro) 표준편차: 0.1717\n",
      "F1-Score (Macro) 표준편차: 0.1318\n"
     ]
    }
   ],
   "source": [
    "evaluate = {}\n",
    "for k in range(len(batch_res)):\n",
    "    print(\"--------------------------\", k, end='--------------------------\\n')\n",
    "    json_res = []\n",
    "    for i in batch_res[k].text.split('\\n')[:-1]:\n",
    "        json_res.append(json.loads(i))\n",
    "    emotion_res = []\n",
    "\n",
    "    for i in json_res:\n",
    "        tmp = []\n",
    "        try:\n",
    "            l = json.loads(i['response']['body']['output'][0]['content'][0]['text'])\n",
    "            \n",
    "            for j in l['analysis']:\n",
    "                tmp.append(j['emotion'])\n",
    "        except:\n",
    "            print(i)\n",
    "        \n",
    "        emotion_res.append(tmp)\n",
    "    e = evaluation(data, emotion_res)\n",
    "    ek = evaluation_ekman(data, emotion_res)\n",
    "    evaluate[t[k]] = list(e) + list(ek)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "91aa91b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0.0, 0.0): [0.2244, 0.289707750952986, 0.29024781718346315, 0.4548, 0.5075585789871504, 0.4436318083455104], (0.0, 0.25): [0.2236, 0.2893447086585587, 0.2855926256537827, 0.4548, 0.5076545076545077, 0.44597022569871464], (0.0, 0.5): [0.224, 0.2894975512425177, 0.28956292514781323, 0.4536, 0.5068932955618508, 0.44303576930811767], (0.0, 0.75): [0.2264, 0.29245283018867924, 0.29317099468918545, 0.4572, 0.5106785106785107, 0.44557519966778153], (0.0, 1.0): [0.2256, 0.2891916439600363, 0.286680279852414, 0.4528, 0.5051039697542533, 0.441886528129043], (0.25, 0.0): [0.224, 0.28929219600725953, 0.290984029551434, 0.4548, 0.5071860816944024, 0.443239947278968], (0.25, 0.25): [0.2236, 0.29115992013069525, 0.2915046054641585, 0.4572, 0.5097371903951597, 0.4442975072495047], (0.25, 0.5): [0.228, 0.29343489299963726, 0.2951949834415063, 0.456, 0.5090702947845805, 0.44417058745775756], (0.25, 0.75): [0.2288, 0.29493923453654997, 0.2914582198079928, 0.458, 0.5111446921042689, 0.4463184688762758], (0.25, 1.0): [0.2256, 0.289707750952986, 0.2851358395984454, 0.4548, 0.5075528700906344, 0.4447196284409029], (0.5, 0.0): [0.222, 0.2871143375680581, 0.28658659973087197, 0.4532, 0.5061425061425061, 0.4395063363364545], (0.5, 0.25): [0.226, 0.29121278140885987, 0.2873475488712275, 0.4552, 0.5076545076545077, 0.44383884441478977], (0.5, 0.5): [0.2236, 0.2898603301287865, 0.2869787649220009, 0.4516, 0.505569190107608, 0.4446410075304853], (0.5, 0.75): [0.2224, 0.2876836568111736, 0.2841828090192925, 0.4544, 0.5088712721781804, 0.44397521317720884], (0.5, 1.0): [0.222, 0.2882032667876588, 0.27918589740482996, 0.456, 0.5086923658352229, 0.4459398944636561], (0.75, 0.0): [0.2224, 0.28980776206021036, 0.28980463183911576, 0.4544, 0.5076545076545077, 0.4449752622544293], (0.75, 0.25): [0.2256, 0.29141716566866266, 0.29085347290928193, 0.4532, 0.5057645057645057, 0.43979438282732913], (0.75, 0.5): [0.2236, 0.2888243831640058, 0.2869061387410198, 0.4536, 0.5068932955618508, 0.437527150978279], (0.75, 0.75): [0.224, 0.2888204384852328, 0.2913850658497135, 0.4528, 0.5056646525679759, 0.44445195933725096], (0.75, 1.0): [0.2208, 0.285972850678733, 0.2887751313583447, 0.45, 0.5023589356482355, 0.4359520547324275], (1.0, 0.0): [0.2268, 0.2923467537178092, 0.2931826459072009, 0.456, 0.5093519743056868, 0.44484983639136566], (1.0, 0.25): [0.2268, 0.2932753307957223, 0.2939868211689905, 0.458, 0.5110481586402267, 0.44511127583342525], (1.0, 0.5): [0.2216, 0.28695809903863595, 0.2817258242101678, 0.4528, 0.5057601510859301, 0.4412538152664426], (1.0, 0.75): [0.2204, 0.2845218653601887, 0.2806351141195777, 0.4488, 0.5000945000945001, 0.4398362208222606], (1.0, 1.0): [0.2212, 0.2826007991282238, 0.2852852427426563, 0.4496, 0.4995273208546039, 0.4294634143290542]}\n"
     ]
    }
   ],
   "source": [
    "print(evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "c6b8e9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(evaluate).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "d260b89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>ekman accuracy</th>\n",
       "      <th>ekman f1 micro</th>\n",
       "      <th>ekman f1 macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.00</th>\n",
       "      <th>0.00</th>\n",
       "      <td>0.2244</td>\n",
       "      <td>0.289708</td>\n",
       "      <td>0.290248</td>\n",
       "      <td>0.4548</td>\n",
       "      <td>0.507559</td>\n",
       "      <td>0.443632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>0.2236</td>\n",
       "      <td>0.289345</td>\n",
       "      <td>0.285593</td>\n",
       "      <td>0.4548</td>\n",
       "      <td>0.507655</td>\n",
       "      <td>0.445970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.2240</td>\n",
       "      <td>0.289498</td>\n",
       "      <td>0.289563</td>\n",
       "      <td>0.4536</td>\n",
       "      <td>0.506893</td>\n",
       "      <td>0.443036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>0.2264</td>\n",
       "      <td>0.292453</td>\n",
       "      <td>0.293171</td>\n",
       "      <td>0.4572</td>\n",
       "      <td>0.510679</td>\n",
       "      <td>0.445575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.2256</td>\n",
       "      <td>0.289192</td>\n",
       "      <td>0.286680</td>\n",
       "      <td>0.4528</td>\n",
       "      <td>0.505104</td>\n",
       "      <td>0.441887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.25</th>\n",
       "      <th>0.00</th>\n",
       "      <td>0.2240</td>\n",
       "      <td>0.289292</td>\n",
       "      <td>0.290984</td>\n",
       "      <td>0.4548</td>\n",
       "      <td>0.507186</td>\n",
       "      <td>0.443240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>0.2236</td>\n",
       "      <td>0.291160</td>\n",
       "      <td>0.291505</td>\n",
       "      <td>0.4572</td>\n",
       "      <td>0.509737</td>\n",
       "      <td>0.444298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.293435</td>\n",
       "      <td>0.295195</td>\n",
       "      <td>0.4560</td>\n",
       "      <td>0.509070</td>\n",
       "      <td>0.444171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>0.2288</td>\n",
       "      <td>0.294939</td>\n",
       "      <td>0.291458</td>\n",
       "      <td>0.4580</td>\n",
       "      <td>0.511145</td>\n",
       "      <td>0.446318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.2256</td>\n",
       "      <td>0.289708</td>\n",
       "      <td>0.285136</td>\n",
       "      <td>0.4548</td>\n",
       "      <td>0.507553</td>\n",
       "      <td>0.444720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.50</th>\n",
       "      <th>0.00</th>\n",
       "      <td>0.2220</td>\n",
       "      <td>0.287114</td>\n",
       "      <td>0.286587</td>\n",
       "      <td>0.4532</td>\n",
       "      <td>0.506143</td>\n",
       "      <td>0.439506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>0.2260</td>\n",
       "      <td>0.291213</td>\n",
       "      <td>0.287348</td>\n",
       "      <td>0.4552</td>\n",
       "      <td>0.507655</td>\n",
       "      <td>0.443839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.2236</td>\n",
       "      <td>0.289860</td>\n",
       "      <td>0.286979</td>\n",
       "      <td>0.4516</td>\n",
       "      <td>0.505569</td>\n",
       "      <td>0.444641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>0.2224</td>\n",
       "      <td>0.287684</td>\n",
       "      <td>0.284183</td>\n",
       "      <td>0.4544</td>\n",
       "      <td>0.508871</td>\n",
       "      <td>0.443975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.2220</td>\n",
       "      <td>0.288203</td>\n",
       "      <td>0.279186</td>\n",
       "      <td>0.4560</td>\n",
       "      <td>0.508692</td>\n",
       "      <td>0.445940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0.75</th>\n",
       "      <th>0.00</th>\n",
       "      <td>0.2224</td>\n",
       "      <td>0.289808</td>\n",
       "      <td>0.289805</td>\n",
       "      <td>0.4544</td>\n",
       "      <td>0.507655</td>\n",
       "      <td>0.444975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>0.2256</td>\n",
       "      <td>0.291417</td>\n",
       "      <td>0.290853</td>\n",
       "      <td>0.4532</td>\n",
       "      <td>0.505765</td>\n",
       "      <td>0.439794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.2236</td>\n",
       "      <td>0.288824</td>\n",
       "      <td>0.286906</td>\n",
       "      <td>0.4536</td>\n",
       "      <td>0.506893</td>\n",
       "      <td>0.437527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>0.2240</td>\n",
       "      <td>0.288820</td>\n",
       "      <td>0.291385</td>\n",
       "      <td>0.4528</td>\n",
       "      <td>0.505665</td>\n",
       "      <td>0.444452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.2208</td>\n",
       "      <td>0.285973</td>\n",
       "      <td>0.288775</td>\n",
       "      <td>0.4500</td>\n",
       "      <td>0.502359</td>\n",
       "      <td>0.435952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1.00</th>\n",
       "      <th>0.00</th>\n",
       "      <td>0.2268</td>\n",
       "      <td>0.292347</td>\n",
       "      <td>0.293183</td>\n",
       "      <td>0.4560</td>\n",
       "      <td>0.509352</td>\n",
       "      <td>0.444850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <td>0.2268</td>\n",
       "      <td>0.293275</td>\n",
       "      <td>0.293987</td>\n",
       "      <td>0.4580</td>\n",
       "      <td>0.511048</td>\n",
       "      <td>0.445111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.286958</td>\n",
       "      <td>0.281726</td>\n",
       "      <td>0.4528</td>\n",
       "      <td>0.505760</td>\n",
       "      <td>0.441254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.75</th>\n",
       "      <td>0.2204</td>\n",
       "      <td>0.284522</td>\n",
       "      <td>0.280635</td>\n",
       "      <td>0.4488</td>\n",
       "      <td>0.500095</td>\n",
       "      <td>0.439836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <td>0.2212</td>\n",
       "      <td>0.282601</td>\n",
       "      <td>0.285285</td>\n",
       "      <td>0.4496</td>\n",
       "      <td>0.499527</td>\n",
       "      <td>0.429463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy  f1 micro  f1 macro  ekman accuracy  ekman f1 micro  \\\n",
       "0.00 0.00    0.2244  0.289708  0.290248          0.4548        0.507559   \n",
       "     0.25    0.2236  0.289345  0.285593          0.4548        0.507655   \n",
       "     0.50    0.2240  0.289498  0.289563          0.4536        0.506893   \n",
       "     0.75    0.2264  0.292453  0.293171          0.4572        0.510679   \n",
       "     1.00    0.2256  0.289192  0.286680          0.4528        0.505104   \n",
       "0.25 0.00    0.2240  0.289292  0.290984          0.4548        0.507186   \n",
       "     0.25    0.2236  0.291160  0.291505          0.4572        0.509737   \n",
       "     0.50    0.2280  0.293435  0.295195          0.4560        0.509070   \n",
       "     0.75    0.2288  0.294939  0.291458          0.4580        0.511145   \n",
       "     1.00    0.2256  0.289708  0.285136          0.4548        0.507553   \n",
       "0.50 0.00    0.2220  0.287114  0.286587          0.4532        0.506143   \n",
       "     0.25    0.2260  0.291213  0.287348          0.4552        0.507655   \n",
       "     0.50    0.2236  0.289860  0.286979          0.4516        0.505569   \n",
       "     0.75    0.2224  0.287684  0.284183          0.4544        0.508871   \n",
       "     1.00    0.2220  0.288203  0.279186          0.4560        0.508692   \n",
       "0.75 0.00    0.2224  0.289808  0.289805          0.4544        0.507655   \n",
       "     0.25    0.2256  0.291417  0.290853          0.4532        0.505765   \n",
       "     0.50    0.2236  0.288824  0.286906          0.4536        0.506893   \n",
       "     0.75    0.2240  0.288820  0.291385          0.4528        0.505665   \n",
       "     1.00    0.2208  0.285973  0.288775          0.4500        0.502359   \n",
       "1.00 0.00    0.2268  0.292347  0.293183          0.4560        0.509352   \n",
       "     0.25    0.2268  0.293275  0.293987          0.4580        0.511048   \n",
       "     0.50    0.2216  0.286958  0.281726          0.4528        0.505760   \n",
       "     0.75    0.2204  0.284522  0.280635          0.4488        0.500095   \n",
       "     1.00    0.2212  0.282601  0.285285          0.4496        0.499527   \n",
       "\n",
       "           ekman f1 macro  \n",
       "0.00 0.00        0.443632  \n",
       "     0.25        0.445970  \n",
       "     0.50        0.443036  \n",
       "     0.75        0.445575  \n",
       "     1.00        0.441887  \n",
       "0.25 0.00        0.443240  \n",
       "     0.25        0.444298  \n",
       "     0.50        0.444171  \n",
       "     0.75        0.446318  \n",
       "     1.00        0.444720  \n",
       "0.50 0.00        0.439506  \n",
       "     0.25        0.443839  \n",
       "     0.50        0.444641  \n",
       "     0.75        0.443975  \n",
       "     1.00        0.445940  \n",
       "0.75 0.00        0.444975  \n",
       "     0.25        0.439794  \n",
       "     0.50        0.437527  \n",
       "     0.75        0.444452  \n",
       "     1.00        0.435952  \n",
       "1.00 0.00        0.444850  \n",
       "     0.25        0.445111  \n",
       "     0.50        0.441254  \n",
       "     0.75        0.439836  \n",
       "     1.00        0.429463  "
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "a3738983",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.columns = ['accuracy', 'f1 micro', 'f1 macro', 'ekman accuracy', 'ekman f1 micro', 'ekman f1 macro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "d9d4290b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>ekman accuracy</th>\n",
       "      <th>ekman f1 micro</th>\n",
       "      <th>ekman f1 macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0.25</th>\n",
       "      <th>0.75</th>\n",
       "      <td>0.2288</td>\n",
       "      <td>0.294939</td>\n",
       "      <td>0.291458</td>\n",
       "      <td>0.4580</td>\n",
       "      <td>0.511145</td>\n",
       "      <td>0.446318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.293435</td>\n",
       "      <td>0.295195</td>\n",
       "      <td>0.4560</td>\n",
       "      <td>0.509070</td>\n",
       "      <td>0.444171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.00</th>\n",
       "      <th>0.25</th>\n",
       "      <td>0.2268</td>\n",
       "      <td>0.293275</td>\n",
       "      <td>0.293987</td>\n",
       "      <td>0.4580</td>\n",
       "      <td>0.511048</td>\n",
       "      <td>0.445111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>0.2268</td>\n",
       "      <td>0.292347</td>\n",
       "      <td>0.293183</td>\n",
       "      <td>0.4560</td>\n",
       "      <td>0.509352</td>\n",
       "      <td>0.444850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <th>0.75</th>\n",
       "      <td>0.2264</td>\n",
       "      <td>0.292453</td>\n",
       "      <td>0.293171</td>\n",
       "      <td>0.4572</td>\n",
       "      <td>0.510679</td>\n",
       "      <td>0.445575</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy  f1 micro  f1 macro  ekman accuracy  ekman f1 micro  \\\n",
       "0.25 0.75    0.2288  0.294939  0.291458          0.4580        0.511145   \n",
       "     0.50    0.2280  0.293435  0.295195          0.4560        0.509070   \n",
       "1.00 0.25    0.2268  0.293275  0.293987          0.4580        0.511048   \n",
       "     0.00    0.2268  0.292347  0.293183          0.4560        0.509352   \n",
       "0.00 0.75    0.2264  0.292453  0.293171          0.4572        0.510679   \n",
       "\n",
       "           ekman f1 macro  \n",
       "0.25 0.75        0.446318  \n",
       "     0.50        0.444171  \n",
       "1.00 0.25        0.445111  \n",
       "     0.00        0.444850  \n",
       "0.00 0.75        0.445575  "
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.sort_values('accuracy', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "7f260c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>ekman accuracy</th>\n",
       "      <th>ekman f1 micro</th>\n",
       "      <th>ekman f1 macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <th>0.50</th>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.293435</td>\n",
       "      <td>0.295195</td>\n",
       "      <td>0.4560</td>\n",
       "      <td>0.509070</td>\n",
       "      <td>0.444171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1.00</th>\n",
       "      <th>0.25</th>\n",
       "      <td>0.2268</td>\n",
       "      <td>0.293275</td>\n",
       "      <td>0.293987</td>\n",
       "      <td>0.4580</td>\n",
       "      <td>0.511048</td>\n",
       "      <td>0.445111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <td>0.2268</td>\n",
       "      <td>0.292347</td>\n",
       "      <td>0.293183</td>\n",
       "      <td>0.4560</td>\n",
       "      <td>0.509352</td>\n",
       "      <td>0.444850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <th>0.75</th>\n",
       "      <td>0.2264</td>\n",
       "      <td>0.292453</td>\n",
       "      <td>0.293171</td>\n",
       "      <td>0.4572</td>\n",
       "      <td>0.510679</td>\n",
       "      <td>0.445575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <th>0.25</th>\n",
       "      <td>0.2236</td>\n",
       "      <td>0.291160</td>\n",
       "      <td>0.291505</td>\n",
       "      <td>0.4572</td>\n",
       "      <td>0.509737</td>\n",
       "      <td>0.444298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy  f1 micro  f1 macro  ekman accuracy  ekman f1 micro  \\\n",
       "0.25 0.50    0.2280  0.293435  0.295195          0.4560        0.509070   \n",
       "1.00 0.25    0.2268  0.293275  0.293987          0.4580        0.511048   \n",
       "     0.00    0.2268  0.292347  0.293183          0.4560        0.509352   \n",
       "0.00 0.75    0.2264  0.292453  0.293171          0.4572        0.510679   \n",
       "0.25 0.25    0.2236  0.291160  0.291505          0.4572        0.509737   \n",
       "\n",
       "           ekman f1 macro  \n",
       "0.25 0.50        0.444171  \n",
       "1.00 0.25        0.445111  \n",
       "     0.00        0.444850  \n",
       "0.00 0.75        0.445575  \n",
       "0.25 0.25        0.444298  "
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.sort_values('f1 macro', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "6d58b0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>ekman accuracy</th>\n",
       "      <th>ekman f1 micro</th>\n",
       "      <th>ekman f1 macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <th>0.75</th>\n",
       "      <td>0.2288</td>\n",
       "      <td>0.294939</td>\n",
       "      <td>0.291458</td>\n",
       "      <td>0.4580</td>\n",
       "      <td>0.511145</td>\n",
       "      <td>0.446318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <th>0.25</th>\n",
       "      <td>0.2268</td>\n",
       "      <td>0.293275</td>\n",
       "      <td>0.293987</td>\n",
       "      <td>0.4580</td>\n",
       "      <td>0.511048</td>\n",
       "      <td>0.445111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <th>0.25</th>\n",
       "      <td>0.2236</td>\n",
       "      <td>0.291160</td>\n",
       "      <td>0.291505</td>\n",
       "      <td>0.4572</td>\n",
       "      <td>0.509737</td>\n",
       "      <td>0.444298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <th>0.75</th>\n",
       "      <td>0.2264</td>\n",
       "      <td>0.292453</td>\n",
       "      <td>0.293171</td>\n",
       "      <td>0.4572</td>\n",
       "      <td>0.510679</td>\n",
       "      <td>0.445575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <th>0.50</th>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.293435</td>\n",
       "      <td>0.295195</td>\n",
       "      <td>0.4560</td>\n",
       "      <td>0.509070</td>\n",
       "      <td>0.444171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy  f1 micro  f1 macro  ekman accuracy  ekman f1 micro  \\\n",
       "0.25 0.75    0.2288  0.294939  0.291458          0.4580        0.511145   \n",
       "1.00 0.25    0.2268  0.293275  0.293987          0.4580        0.511048   \n",
       "0.25 0.25    0.2236  0.291160  0.291505          0.4572        0.509737   \n",
       "0.00 0.75    0.2264  0.292453  0.293171          0.4572        0.510679   \n",
       "0.25 0.50    0.2280  0.293435  0.295195          0.4560        0.509070   \n",
       "\n",
       "           ekman f1 macro  \n",
       "0.25 0.75        0.446318  \n",
       "1.00 0.25        0.445111  \n",
       "0.25 0.25        0.444298  \n",
       "0.00 0.75        0.445575  \n",
       "0.25 0.50        0.444171  "
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.sort_values('ekman accuracy', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "61cb67bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>f1 micro</th>\n",
       "      <th>f1 macro</th>\n",
       "      <th>ekman accuracy</th>\n",
       "      <th>ekman f1 micro</th>\n",
       "      <th>ekman f1 macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.25</th>\n",
       "      <th>0.75</th>\n",
       "      <td>0.2288</td>\n",
       "      <td>0.294939</td>\n",
       "      <td>0.291458</td>\n",
       "      <td>0.4580</td>\n",
       "      <td>0.511145</td>\n",
       "      <td>0.446318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <th>0.25</th>\n",
       "      <td>0.2236</td>\n",
       "      <td>0.289345</td>\n",
       "      <td>0.285593</td>\n",
       "      <td>0.4548</td>\n",
       "      <td>0.507655</td>\n",
       "      <td>0.445970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <th>1.00</th>\n",
       "      <td>0.2220</td>\n",
       "      <td>0.288203</td>\n",
       "      <td>0.279186</td>\n",
       "      <td>0.4560</td>\n",
       "      <td>0.508692</td>\n",
       "      <td>0.445940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.00</th>\n",
       "      <th>0.75</th>\n",
       "      <td>0.2264</td>\n",
       "      <td>0.292453</td>\n",
       "      <td>0.293171</td>\n",
       "      <td>0.4572</td>\n",
       "      <td>0.510679</td>\n",
       "      <td>0.445575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.00</th>\n",
       "      <th>0.25</th>\n",
       "      <td>0.2268</td>\n",
       "      <td>0.293275</td>\n",
       "      <td>0.293987</td>\n",
       "      <td>0.4580</td>\n",
       "      <td>0.511048</td>\n",
       "      <td>0.445111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           accuracy  f1 micro  f1 macro  ekman accuracy  ekman f1 micro  \\\n",
       "0.25 0.75    0.2288  0.294939  0.291458          0.4580        0.511145   \n",
       "0.00 0.25    0.2236  0.289345  0.285593          0.4548        0.507655   \n",
       "0.50 1.00    0.2220  0.288203  0.279186          0.4560        0.508692   \n",
       "0.00 0.75    0.2264  0.292453  0.293171          0.4572        0.510679   \n",
       "1.00 0.25    0.2268  0.293275  0.293987          0.4580        0.511048   \n",
       "\n",
       "           ekman f1 macro  \n",
       "0.25 0.75        0.446318  \n",
       "0.00 0.25        0.445970  \n",
       "0.50 1.00        0.445940  \n",
       "0.00 0.75        0.445575  \n",
       "1.00 0.25        0.445111  "
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.sort_values('ekman f1 macro', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "c31cd899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "091e6a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key, value in evaluate.items():\n",
    "    plt.plot(key[0], value[5], 'k.')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "a8c1558d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj0AAAGdCAYAAAD5ZcJyAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAL+9JREFUeJzt3QtsVNedx/G/H9gOBDAP2bwcQ7CBBhqgGBwIZsNDOMoKitSAs1BDiYuJCkQbQhpoUgxkKQkkPJp4wzuhElrT7AKKSOXwcgRueFQQKyYNFEgJTxvY8nDpLgZ7Vv8jzeyMPTYe45nxzPl+pJvJ3Ll35s41nvn5nP85N8LhcDgEAAAgzEUG+wAAAAACgdADAACsQOgBAABWIPQAAAArEHoAAIAVCD0AAMAKhB4AAGAFQg8AALBCdLAPoDmprq6Wy5cvS+vWrSUiIiLYhwMAABpA51muqKiQLl26SGRk3e05hB43GniSkpKCfRgAAKARLly4IN26davzcUKPG23hcZ60Nm3aBPtwAABAA9y+fds0Wji/x+tC6HHj7NLSwEPoAQAgtDyoNIVCZgAAYAVCDwAAsAKhBwAAWIHQAwAArEDoAQAAViD0AAAAKxB6AACAFQg9AADACoQeAABgBUIPAACwAqEHABASLl68KEVFReYWaAxCDwCg2du0aZMkJyfLqFGjzK3eB3wV4XA4HD7vFcZXaW3btq3cunWLC44CQDOhLTsadKqrq13roqKi5Ny5c9KtW7egHhtC6/ublh4AQLN2+vRpj8Cjqqqq5MyZM0E7JoQmQg8AoFlLTU2VyEjPrytt6UlJSQnaMSE0EXoAAM2admGtX7/eBB2lt+vWraNrCz6jpscNNT0A0Lxre7RLS1t4CDxozPd3dJ2PAPD4sNW6Am1m58MWCA793eP3Dw+D7i3gARgqCwDhMc8SoQeoh/5y5ubmukaO6O3MmTOZHA0AQvCPR0IPUA+GygJA+PzxSOgB6sFQWQAInz8eCT1APRgqCwDh88cjoQd4gJycHDPdvRbg6a3eBwCE3h+PzNPjhnl6AAAIvXmWmKcHABBWmC8rtHVrBvMs0b0FAGj2msuQZ4Q2urfc0L0FAM2zhUeDjvsIIK0L0Rq7YLccILS+v2npAQA0a81pyDNCG6EHANCsNachzwhthB4AQLPWnIY8I7RR0+OGmh4AsHPIM0IbQ9YBAGGlOQx5RmijewsAAFiB0AMAAKxA6AEaWEug197SWwCARaEnPz9funfvLnFxcZKeni5Hjx5t0H4FBQUSEREhEyZMqHObl156yWyzevVqj/X6errefXn77bc9tvn6668lIyPDHFdSUpIsX768MW8P8MBMsABgaejZtm2bzJ07V/Ly8uT48ePSv39/yczMlKtXr9a7n86cOW/ePBNK6rJjxw45fPiwdOnSxevjS5YskStXrriWOXPmeFRujx071nwpHTt2TFasWCGLFi0ywxyDjVaC0KU/s9zcXNfEaHo7c+ZMfpYAYEPoWblypcyYMUOmT58uTzzxhKxdu1ZatmwpmzdvrnMfnTlzypQpsnjxYnn88ce9bnPp0iUTYrZu3SotWrTwuk3r1q2lU6dOrqVVq1aux3S/yspKcxx9+/aVF154QV5++WVzvMFEK0FoYyZYALA09Gio0FaUMWPG/P8TREaa+4cOHapzP22hSUhIkJycHK+P65dKdna2vPbaayaw1EW7szp06CADBw40LTn37993PaavP2LECImJiXGt0xaoU6dOyY0bN7w+3927d00LkfvSlGglCH3MBAsAloae69evm79yExMTPdbr/bKyMq/7FBcXm9aNDRs21Pm877zzjkRHR5uWmbroY1oTpN1EGhx+85vfyC9/+UvX4/r63o7L+Zg3y5YtM5MZORetA2pKtBKEPmaCBYDw4dfJCSsqKkwLjgaejh07et1GW47WrFlj6oO0OLkuWkfk9OSTT5oWHQ0/GlxiY2MbdXwLFizweF5t6WnK4KOtBPqe3Ce91vu0EoQWbaHUVkNmggUAi0KPBhf9S7e8vNxjvd7XGpuazp49awqYx40b51rnbPnQlh3tejp48KApgn7sscc8WkNeffVVM4JL9/dGR41p95Y+3rt3b/P63o5LeTs2pWGpsYGpseoLdmi+mAkWAB6OlnZoD4g2CATr89Sn7i1tXRk0aJDs27fPI8To/aFDh9bavk+fPlJaWiolJSWuZfz48TJy5Ejz/9qqoi1BOtTcfRsdvaX1PZ9//nmdx6Lbaa2F1gopff0DBw7IvXv3XNvs2bPHBKJ27dpJMOgPt+alzfR80b0FALDJpmYyqMfn7i3tDpo2bZqkpaXJkCFDTGvMnTt3zGguNXXqVOnatavpdtL5cvr16+exf3x8vLl1rtfCZF3c6egtbZ3RwOIsUj5y5IgJSzqCS++/8sor8tOf/tQVaCZPnmxGh2lXxOuvvy4nTpww3WarVq2SYBfButf1UAQL2PtXJmCji3UM6tGygUD/LvocerKysuTatWuycOFCUyA8YMAAKSwsdBUNnz9/vtZol4elXVBaxKzz7uiIqx49epjQ416Po4XIu3fvllmzZpnWKO2K02PUEx3sIlj94WqXHUWwQHDoX5XOD139fNLfy7pGkwKQgA3qCfT3YYSjZv+LxRp6afrGpFyKYIHg0N8/bU6v2eKq9YD8PgLh8TvY0O9vrr0VAPpDfeaZZ/iABYKAqSOA4OrWjKb+8OuQdQAINmrrwgd1WaErp5lM/UFLD4Cw1pz+ykToj/5BaPd6UNMTgJoeAMFHbV3ooi4LTfX9TfcW0AA0q4c+JpgMXc1p9A9CG91bwAPQrA4EFxf+RVMh9ACNmFRL1yO06M9ML1jMzy70UJeFpkLoAerBcOfwQGtdeIz+0RoeDa56y+SSaAwKmd1QyIyaKKAMffwMgfB3m8kJgYdHs3roo7UOgBOjt4AQmVQLjcPkhOGDUZR4WLT0AA3QHCbVQuPQWhceqMtCU6Cmxw01PUD4YnLC0EVdFh6EyQmBJkSzeuhjcsLQxeSEaCp0bwEPQLM6EFxMToimQugB6sHkhEDwUZeFpkL3FlAPmtWB5oFRlGgKhJ4AoB4kdDHcGWg+qMvCw6J7y8+oBwltNKsDQPhgyLofh6wzzDJ8MNwZAJovhqw3A9SDhA+a1QEg9NG95UcMswQAoPkg9PgR9SAAADQf1PQE4DIU1IMAAOA/1PQ0I9SDAAAQfHRvBYC29BQVFTGLLwAAQUTo8TPm6QEAoHmgpscN8/QAABC+39+09ARpnh4AABBYhB4/Yp4eoPmgtg4AocePmKcHaB6orQOgqOlxwzw9QPihtg4If7eZp6f5YJ4eIHi4Bh4AJ7q3AIQ1ausAOBF6AIQ1ausAOFHTE4CaHgDBR20dEL6o6QEAN9TWAaB7CwAAWKFRoSc/P1+6d+8ucXFxkp6eLkePHm3QfgUFBRIRESETJkyoc5uXXnrJbLN69WrXOh1ampOTIz169JBHHnlEevbsKXl5eVJZWemxje5Xczl8+HBj3iIAAAgzPndvbdu2TebOnStr1641gUfDSWZmppw6dUoSEhLq3E9Dybx58yQjI6PObXbs2GFCSpcuXTzWnzx50gw51eJD7Y8/ceKEzJgxQ+7cuSPvvvuux7Z79+6Vvn37uu536NDB17cIAADCkM8tPStXrjSBY/r06fLEE0+Y8NOyZUvZvHlznfvonBhTpkyRxYsXy+OPP+51m0uXLsmcOXNk69at0qJFC4/Hnn32Wfnoo49k7NixZv/x48ebALV9+/Zaz6Mhp1OnTq6l5nMBAAA7+RR6tDvp2LFjMmbMmP9/gshIc//QoUN17rdkyRLTCqRdVN5oK052dra89tprHq009dEK7fbt29dar4FIX2v48OHy6aefNui5AABA+POpe+v69eum1SYxMdFjvd7XLihviouLzXVuSkpK6nzed955R6Kjo+Xll19u0HHosNP333/fo2vr0Ucflffee0+efvppE8T+67/+y9QO7dy50wQhb+7evWsW9yFvAAAgPPl1yHpFRYVpwdmwYYN07NjR6zbacrRmzRo5fvy4KTx+EO0G0+6uiRMnmm42J31+rTVyGjx4sFy+fFlWrFhRZ+hZtmyZ6XIDAADhz6fuLQ0WOptpeXm5x3q9r/UzNZ09e9YUMI8bN8605Ojyu9/9znQ76f/r4wcPHpSrV6/KY4895trm+++/l1dffdWMEHOnIWbkyJEybNgwM8Pqg2ihtbYK1WXBggWmm8y5XLhwwZfTAQAAwrWlJyYmRgYNGiT79u1zDTvXehy9P3v27Frb9+nTR0pLSz3Wvfnmm6YFSFt3kpKSTEuQe42Q0tFgul6Lpd1beDTw6OtrUXPNa+l4o11qnTt3rvPx2NhYswAAgPDnc/eWdiFNmzZN0tLSZMiQIWbIug4ddwaUqVOnSteuXU3Xkc7j069fP4/94+Pjza1zvY62qjmsXEdcactR7969XYHnmWeekeTkZFPHc+3aNde2zhamLVu2mFA2cOBAc19HdumIso0bN/r6FgEAQBjyOfRkZWWZ0LFw4UIpKyuTAQMGSGFhoau4+fz58w1qhfHFnj17TDeVLjWnkXe/dNhbb71lusa0i0xbmXROoeeff75JjwUAAIQmLjjqhguOAgAQvt/fXHsLAABYgdADAACsQOgBAABWIPQAAAC/u3jxohQVFZnbYCH0AAAAv9LLUem0M6NGjTK3ej8YGL3lhtFbAAA0LW3Z0aCjkxk76dUd9IoNNaehaSxGbwEAgKA7ffq0R+BRevHy+i4T5S+EHgAA4Depqam1Ji3Wlp6UlBQJNEIPAADwG+3C0ouEa9BRertu3bom69ryBTU9bqjpAQDAf7U92qWlLTxNHXga+v3t87W3AAAAfKVBJxitO+7o3gIAAFYg9AAAACsQegAAgBUIPQAAwAqEHgBWaA7X/QEQXIQeAGGvuVz3B0BwMU+PG+bpAcJPIK77AyC4uPYWADSz6/4ACC5CD4Cw1pyu+wMguAg9AMJac7ruD4DgoqbHDTU9QPjy53V/AAQX194CgGZ23R8AwUX3FgAAsAKhBwAAWIHQAwAArEDoAQAAViD0AAAAKxB6AACAFQg9AADACoQeAABgBUIPAACwAqEHAABYgdADAACsQOgBAABWIPQAAAArEHoAAIAVCD0AAMAKhB4AAGCFRoWe/Px86d69u8TFxUl6erocPXq0QfsVFBRIRESETJgwoc5tXnrpJbPN6tWrPdb/7W9/kylTpkibNm0kPj5ecnJy5O9//7vHNl9//bVkZGSY40pKSpLly5c35u0BAIAw5HPo2bZtm8ydO1fy8vLk+PHj0r9/f8nMzJSrV6/Wu9+5c+dk3rx5JpTUZceOHXL48GHp0qVLrcc08HzzzTeyZ88e2bVrlxw4cEByc3Ndj9++fVvGjh0rycnJcuzYMVmxYoUsWrRI1q9f7+tbBAAAYcjn0LNy5UqZMWOGTJ8+XZ544glZu3attGzZUjZv3lznPlVVVSa0LF68WB5//HGv21y6dEnmzJkjW7dulRYtWng89u2330phYaFs3LjRtCwNHz5c3n//fdNydPnyZbON7ldZWWmOo2/fvvLCCy/Iyy+/bI4XAADAp9CjoUJbUcaMGfP/TxAZae4fOnSozv2WLFkiCQkJpkvKm+rqasnOzpbXXnvNBJaa9Lm1SystLc21Tl9TX/vIkSOubUaMGCExMTGubbQF6tSpU3Ljxg2vr3v37l3TQuS+AACA8ORT6Ll+/bpptUlMTPRYr/fLysq87lNcXCybNm2SDRs21Pm877zzjkRHR5uWGW/0uTU0udPt27dv73pdvfV2XM7HvFm2bJm0bdvWtWgdEAAACE9+Hb1VUVFhWnA08HTs2NHrNtpytGbNGvn4449NAXMgLViwQG7duuVaLly4ENDXBwA03MWLF6WoqMjcAo0R7cvGGlyioqKkvLzcY73e79SpU63tz549awqYx40b59GVZV44Otp0PR08eNAUQT/22GOubbQ16dVXXzUjuHR/fe6ahdL37983I7qcr6u33o7L+Zg3sbGxZgEeRD9kT58+LampqdKtW7dgHw5gHe0x0MEr+h2ipQ06SKWukgmgSVp6tF5m0KBBsm/fPtc6/Qeo94cOHVpr+z59+khpaamUlJS4lvHjx8vIkSPN/2t3krYE6VBz92109JbW93z++efmefS5b968aVqFnPbv329eWwubndvoiK579+65ttGRXr1795Z27dr58jaBWh+2Oipw1KhR5lbvAwjsHx3OwKP0dubMmbT4wHcOHxUUFDhiY2MdH3/8sePPf/6zIzc31xEfH+8oKyszj2dnZzvmz59f5/7Tpk1z/PjHP673NZKTkx2rVq3yWPfss886Bg4c6Dhy5IijuLjYkZqa6viXf/kX1+M3b950JCYmmtc/ceKEOc6WLVs61q1b1+D3duvWLYeeEr0F1IULFxyRkZHm34VziYqKMusBBMb+/fs9fgedS1FRUbAPDc1EQ7+/fereUllZWXLt2jVZuHChKRAeMGCAGU7uLBo+f/68aXpsajokffbs2TJ69Gjz/D/5yU/kt7/9retxLUTevXu3zJo1y7RGaVecHqP7XD6Ar7RLy/nXpXv365kzZ+jmAgJEu5X1c9/9d1FLLVJSUoJ6XAg9EZp8gn0QzYUOWdfwpEXNOvMzoM3n2qVV88NWa80IPUDgaLeydmnpHx36O7hu3TpqeuDz9zfX3goARhyELg02WjCpH7LK+WFL4AECSwOO/rGhn6V6S+BBY9DS4+eWHkYchAcNrNqlpc3pBB4ACM3vb0KPH0MPXSMAAPgf3VvNvAgWAAAEFqEnACMO3DHiAACA4CD0+BFFsAAANB/U9ARgyDpFsAAABP/72+fJCeE7DTqEHQAAgovuLQAAYAVCDwAAsAKhBwAAWIHQAwAArEDoAQAAViD0AAAAKxB6AACAFQg9AADACoQeAABgBUIPAACwAqEHAABYgdADAACsQOgBAABWIPQAAAArEHoAAIAVCD0AAMAKhB4AAGAFQg8AALACoQcAAFiB0AMAAKxA6AEAAFYg9AAAACsQegAAgBUIPQAAwAqEHgAAYAVCDwAAsAKhBwAAWIHQAwAArEDoAQAAViD0AAAAKxB6AACAFRoVevLz86V79+4SFxcn6enpcvTo0QbtV1BQIBERETJhwgSP9YsWLZI+ffpIq1atpF27djJmzBg5cuSI6/EvvvjC7Odt+dOf/mS2OXfunNfHDx8+3Ji3CAAAbA8927Ztk7lz50peXp4cP35c+vfvL5mZmXL16tV699NQMm/ePMnIyKj1WK9eveSDDz6Q0tJSKS4uNoFq7Nixcu3aNfP4sGHD5MqVKx7Lz3/+c+nRo4ekpaV5PNfevXs9ths0aJCvbxFAGLp48aIUFRWZWwB2inA4HA5fdtCWncGDB5uQoqqrqyUpKUnmzJkj8+fP97pPVVWVjBgxQl588UU5ePCg3Lx5U3bu3Fnna9y+fVvatm1rAszo0aNrPX7v3j3p2rWrec1f//rXrlClIeirr76SAQMG+PKWar3urVu3pE2bNo16DgDNz6ZNmyQ3N9d8XkVGRsr69eslJycn2IcFoIk09Pvbp5aeyspKOXbsmOl+cj1BZKS5f+jQoTr3W7JkiSQkJDToQ0ZfQz+Q9OC1FcmbTz/9VP77v/9bpk+fXuux8ePHm9caPny42a4+d+/eNSfKfQEQXrRlxxl4lN7OnDmTFh/AQj6FnuvXr5tWm8TERI/1er+srMzrPtpdpX9lbdiwod7n3rVrlzz66KOmTmjVqlWyZ88e6dixo9dt9fm0S61bt26udbrve++9J5988ol89tlnJvRo7VB9wWfZsmUmXDkXbbECEF5Onz7tCjxO+jl25syZoB0TgOCI9ueTV1RUSHZ2tgk8dQUYp5EjR0pJSYkJVrr9pEmTTDGzttq407/OPv/8c/n973/vsV6fX2uNnLQL7vLly7JixQrT+uPNggULPPbRlh6CDxBeUlNTTYu0e/CJioqSlJSUoB4XgGbe0qPBQj8sysvLPdbr/U6dOtXa/uzZs6bWZty4cRIdHW2W3/3ud6b1Rf9fH3fSkVv6IfTUU0+Zlhx9XG9r+uijj6RDhw51Bpma9Uf1/TUXGxtr+v7cFwDhRVuEtctcP7uU3q5bt86jpRiAHXxq6YmJiTGjofbt2+cadq5/Pen92bNn19peh6HriCx3b775pmkBWrNmTb2tKvq8WnPjTmuuNfRMnTpVWrRo8cDj1Zajzp07+/AOAYQjrSfULnH9I0j/uCLwAHbyuXtLu4OmTZtmhooPGTJEVq9eLXfu3HEVFWsg0ZFVWi+j9Tn9+vXz2D8+Pt7cOtfrvkuXLjUtNxpQtHtL5wG6dOmSTJw40WPf/fv3y1//+lczXL2mLVu2mFA2cOBAc3/79u2yefNm2bhxo69vEUAY0qBD2AHs5nPoycrKMvPnLFy40BQv6/DwwsJCV3Hz+fPnTf95Q2lT88mTJ01o0cCjXVdaj6ND2/v27euxrXZ36Zw92oLkzVtvvSXff/+96RrTbXROoeeff97XtwgAAMKQz/P0hDPm6QEAIPT4ZZ4eAACAUEXoAQAAViD0AAAAKxB6AACAFQg9AADACoQeAABgBUIPAACwAqEHAABYgdADAACsQOgBAABWIPQAAAArEHoAAIAVCD0AAMAKhB4AAGAFQg8AALACoQcAAFiB0AMAAKxA6AEAAFYg9AAAACsQegAAgBUIPQAAwAqEHgAA4HcXL16UoqIicxsshB4AAOBXmzZtkuTkZBk1apS51fvBEOFwOBxBeeVm6Pbt29K2bVu5deuWtGnTJtiHAwBAyLt48aIJOtXV1a51UVFRcu7cOenWrVtAv79p6QEAAH5z+vRpj8Cjqqqq5MyZMxJohB4AAOA3qampEhnpGTe0pSclJUUCjdADAAD8Rruw1q9fb4KO0tt169Y1WdeWL6jpcUNNDwAA/qvt0S4tbeFp6sDT0O/v6CZ9VQAAAC806ASjdccd3VsAAMAKhB4AAGAFQg8AALACoQcAAFiB0AMAAKxA6AEAAFYg9AAAACsQegAAgBUIPQAAwAqEHgAAYIVGhZ78/Hzp3r27xMXFSXp6uhw9erRB+xUUFEhERIRMmDDBY/2iRYukT58+0qpVK2nXrp2MGTNGjhw54rGNvp7u6768/fbbHtt8/fXXkpGRYY4rKSlJli9f3pi3BwAAwpDPoWfbtm0yd+5cycvLk+PHj0v//v0lMzNTrl69Wu9+586dk3nz5plQUlOvXr3kgw8+kNLSUikuLjYBZ+zYsXLt2jWP7ZYsWSJXrlxxLXPmzPG42Jjuk5ycLMeOHZMVK1aYMKVXdgUAAPD5KuvasjN48GATUlR1dbVpVdEAMn/+fK/7VFVVyYgRI+TFF1+UgwcPys2bN2Xnzp0PvFrq3r17ZfTo0WadBqF//dd/NYs3H374obzxxhtSVlYmMTExZp0ej77OyZMnG/TeuMo6AAChp6Hf3z619FRWVppWFO1+cj1BZKS5f+jQoTr30xaahIQEycnJadBraOuMHry2IrnT7qwOHTrIwIEDTUvO/fv3XY/p62uwcgYepS1Qp06dkhs3bnh9rbt375oT5b4AAIDwFO3LxtevXzetNomJiR7r9X5drSnaXbVp0yYpKSmp97l37dolL7zwgvzjH/+Qzp07y549e6Rjx46ux19++WX50Y9+JO3bt5cvv/xSFixYYLq4Vq5caR7XFp4ePXrUOi7nY1orVNOyZctk8eLFPpwBAABgRejxVUVFhWRnZ8uGDRs8Aow3I0eONMFIg5VuP2nSJFPMrC1ESuuInJ588knTojNz5kwTXGJjYxt1fBqc3J9XW3q0qw4AAFgeejS4REVFSXl5ucd6vd+pU6da2589e9YUMI8bN861TmuAzAtHR5uup549e5r7OnIrJSXFLE899ZSkpqaaFiINJnXVFmn3lj5/7969zet7Oy7l7diUhqXGBiYAABBafKrp0daVQYMGyb59+zxCjN4fOnRore11GLqOyNIWHOcyfvx4V6tOfa0q+rxac1MX3V/riZwtQfr6Bw4ckHv37rm20S4yDUTeurYAAIBdfO7e0u6gadOmSVpamgwZMkRWr14td+7ckenTp5vHp06dKl27djXdTjpfTr9+/Tz2j4+PN7fO9brv0qVLTRjSWh7t3tJ5gC5duiQTJ050FSlrV5eGpdatW5v7r7zyivz0pz91BZrJkyeb+hwtln799dflxIkTsmbNGlm1atXDnyUAAGBf6MnKyjLz5yxcuNAUCA8YMEAKCwtdRcPnz583LTANpd1lWgS9ZcsWE3h0dJYOideh7X379jXbaBeUTmyo8+5o648WLGvoca/H0dFeu3fvllmzZpnWKO2K02PMzc319S0CAIAw5PM8PeGMeXoAAAg9fpmnBwAAIFQRegAAgBUIPQAAwAqEHgAAYAVCDwAAsAKhBwAAWIHQAwAArEDoAQAAViD0AAAAKxB6AACAFQg9AADACoQeAABgBUIPAACwAqEHAABYgdADAACsQOgBAABWIPQAAAArEHoAAIAVCD0AAMAKhB4AAGAFQg8AALACoQcAAFiB0AMAAKxA6AEAAFYg9AAAACsQegAAgBUIPQAAwAqEHgAAYAVCDwAAsAKhBwAAWIHQAwAArEDoAQAAViD0AAAAKxB6AACAFQg9AADACoQeAABgBUIPAACwAqEHAABYgdADAACs0KjQk5+fL927d5e4uDhJT0+Xo0ePNmi/goICiYiIkAkTJnisX7RokfTp00datWol7dq1kzFjxsiRI0dcj587d05ycnKkR48e8sgjj0jPnj0lLy9PKisrPbbR5665HD58uDFvEQAA2B56tm3bJnPnzjWh4/jx49K/f3/JzMyUq1ev1rufhpJ58+ZJRkZGrcd69eolH3zwgZSWlkpxcbEJVGPHjpVr166Zx0+ePCnV1dWybt06+eabb2TVqlWydu1a+dWvflXrufbu3StXrlxxLYMGDfL1LQIAgDAU4XA4HL7soC07gwcPNiFFaRhJSkqSOXPmyPz5873uU1VVJSNGjJAXX3xRDh48KDdv3pSdO3fW+Rq3b9+Wtm3bmgAzevRor9usWLFCPvzwQ/nuu+9coUpbgr766isZMGCAL2+p1uveunVL2rRp06jnAAAAgdXQ72+fWnq0O+nYsWOm+8n1BJGR5v6hQ4fq3G/JkiWSkJBguqga8hrr1683B6+tSHXRN9a+ffta68ePH29ea/jw4fLpp5/W+1p37941J8p9AQAA4cmn0HP9+nXTapOYmOixXu+XlZV53Ue7qzZt2iQbNmyo97l37doljz76qKkT0u6rPXv2SMeOHb1ue+bMGXn//fdl5syZrnW673vvvSeffPKJfPbZZyb0aO1QfcFn2bJlJlw5F22xAgAA4Snan09eUVEh2dnZJvDUFWCcRo4cKSUlJSZY6faTJk0yxczaauPu0qVL8uyzz8rEiRNlxowZrvX6/Fpr5KRdcJcvXzbdYNr6482CBQs89tGWHoIPAADhyafQo8EiKipKysvLPdbr/U6dOtXa/uzZs6bWZty4ca51WgNkXjg6Wk6dOmVGYikduZWSkmKWp556SlJTU00LkQYTJw0xGo6GDRtmusAaUn+kLUZ1iY2NNQsAAAh/PnVvxcTEmNFQ+/bt8wgxen/o0KG1ttdh6DoiS1twnIu2ujhbdeprVdHn1Zob9xaeZ555xrz+Rx99ZGqJHkRfo3Pnzr68RQAAEKZ87t7S7qBp06ZJWlqaDBkyRFavXi137tyR6dOnm8enTp0qXbt2NfUyWp/Tr18/j/3j4+PNrXO97rt06VIThjSgaPeWzgOkIUe7sNwDT3Jysrz77ruuoezK2cK0ZcsWE8oGDhxo7m/fvl02b94sGzdubPzZAQAA9oaerKwsEzoWLlxoipd1eHhhYaGruPn8+fMNaoVx0u4ynYdHQ4sGng4dOph6HB3a3rdvX7ONdlFp8bIu3bp189jffcT9W2+9Jd9//73pOtNWJp1T6Pnnn/f1LQIAgDDk8zw94Yx5egAACD1+macHAAAgVBF6AACAFQg9AADACoQeAABgBUIPAACwAqEHAABYgdADAACsQOgBAABWIPQAAAArEHoAAIAVCD0AAMAKhB4AAGAFQg8AALACoQcAAFiB0AMAAKxA6AEAAFYg9AAAACsQegAAgBUIPQAAwAqEHgAAYAVCDwAAsAKhBwAAWIHQAwAArEDoAQAAViD0AAAAKxB6AACAFQg9AADACoQeAABgBUIPAACwAqEHAABYgdADAACsQOgBAABWIPQAAAArEHoAAIAVCD0AAMAKhB4AAGAFQg8AALACoQcAAFiB0AMAAKzQqNCTn58v3bt3l7i4OElPT5ejR482aL+CggKJiIiQCRMmeKxftGiR9OnTR1q1aiXt2rWTMWPGyJEjRzy2+dvf/iZTpkyRNm3aSHx8vOTk5Mjf//53j22+/vprycjIMMeVlJQky5cvb8zbAwAAYcjn0LNt2zaZO3eu5OXlyfHjx6V///6SmZkpV69erXe/c+fOybx580woqalXr17ywQcfSGlpqRQXF5tANXbsWLl27ZprGw0833zzjezZs0d27dolBw4ckNzcXNfjt2/fNvskJyfLsWPHZMWKFSZMrV+/3te3CAAAwlCEw+Fw+LKDtuwMHjzYhBRVXV1tWlXmzJkj8+fP97pPVVWVjBgxQl588UU5ePCg3Lx5U3bu3Fnna2iAadu2rezdu1dGjx4t3377rTzxxBPypz/9SdLS0sw2hYWF8txzz8nFixelS5cu8uGHH8obb7whZWVlEhMTY7bR49HXOXnyZIPem/N1b926ZVqUAABA89fQ72+fWnoqKytNK4p2P7meIDLS3D906FCd+y1ZskQSEhJMl1RDXkNbZ/TgtRVJ6XNrl5Yz8Ch9TX1tZzeYbqPByhl4lLZAnTp1Sm7cuOH1te7evWtOlPsCAADCk0+h5/r166bVJjEx0WO93tcWFm+0u2rTpk2yYcOGep9bu6weffRRU4+zatUq043VsWNH85g+t4Ymd9HR0dK+fXvX6+qtt+NyPubNsmXLTLhyLtpiBQAAwpNfR29VVFRIdna2CTzOAFOXkSNHSklJiXz55Zfy7LPPyqRJkx5YJ/SwFixYYJrCnMuFCxf8+noAACB4on3ZWINLVFSUlJeXe6zX+506daq1/dmzZ00B87hx41zrtAbIvHB0tOl66tmzp7mvI7dSUlLM8tRTT0lqaqppIdJgos9dMwDdv3/fjOhyvq7eejsu52PexMbGmgUAAIQ/n1p6tF5m0KBBsm/fPo8Qo/eHDh1aa3sdhq4jsrQFx7mMHz/e1apTX3eSPq/W3Ch9bi1+1noip/3795tttLDauY2O6Lp3755rG+0i6927txkGDwAA7OZTS4/S4erTpk0zRcVDhgyR1atXy507d2T69Onm8alTp0rXrl1NvYzW5/Tr189jfy1IVs71uu/SpUtNGOrcubOpG9J5gC5duiQTJ0402/zgBz8wXV4zZsyQtWvXmmAze/ZseeGFF8zILTV58mRZvHixKZZ+/fXX5cSJE7JmzRpTHwQAAOBz6MnKyjLz5yxcuNAUCA8YMMAMH3cWDZ8/f96Mqmoo7S7TIeVbtmwxgadDhw5mSLwObe/bt69ru61bt5qgo0PY9fl/8pOfyG9/+1vX41qIvHv3bpk1a5ZpjdKuOD1G97l8AACAvXyepyecMU8PAAChxy/z9AAAADSGTiZcVFRkboOF0AMAAPxKR2PrZaJGjRplbvV+MNC95YbuLQAAmpa27GjQcU5Z46zn1SltunXr1iSvQfcWAAAIutOnT3sEHqVXdzhz5kzAj4XQAwAA/EYnG645qltbenQy4kAj9AAAAL/RLiy9kLgGHaW369ata7KuLV9Q0+OGmh4AAPxX26NdWtrC09SBp6Hf3z5PTggAAOArDTrBaN1xR/cWAACwAqEHAABYgdADAACsQOgBAABWIPQAAAArEHoAAIAVCD0AAMAKhB4AAGAFQg8AALACoQcAAFiB0AMAAKzAtbfcOK+9qhcuAwAAocH5vf2ga6gTetxUVFSY26SkpGAfCgAAaMT3uF5tvS4RjgfFIotUV1fL5cuXpXXr1hIREdGkCVSD1IULF+q95D0eHuc6MDjPgcF5DgzOc+ifZ40yGni6dOkikZF1V+7Q0uNGT5Q/L3uvP2R+oQKDcx0YnOfA4DwHBuc5tM9zfS08ThQyAwAAKxB6AACAFQg9ARAbGyt5eXnmFv7FuQ4MznNgcJ4Dg/Nsz3mmkBkAAFiBlh4AAGAFQg8AALACoQcAAFiB0AMAAKxA6Gki+fn50r17d4mLi5P09HQ5evRovdt/8skn0qdPH7P9D3/4Q/nDH/4QsGO16Vxv2LBBMjIypF27dmYZM2bMA382aNy/aaeCggIzo/mECRP8fow2nuebN2/KrFmzpHPnzmYUTK9evfj88MN5Xr16tfTu3VseeeQRM4vwK6+8Iv/7v/8bsOMNRQcOHJBx48aZWZH1M2Dnzp0P3OeLL76QH/3oR+bfckpKinz88cf+PUgdvYWHU1BQ4IiJiXFs3rzZ8c033zhmzJjhiI+Pd5SXl3vd/o9//KMjKirKsXz5csef//xnx5tvvulo0aKFo7S0NODHHu7nevLkyY78/HzHV1995fj2228dP/vZzxxt27Z1XLx4MeDHHs7n2emvf/2ro2vXro6MjAzHj3/844Adry3n+e7du460tDTHc8895yguLjbn+4svvnCUlJQE/NjD+Txv3brVERsba271HH/++eeOzp07O1555ZWAH3so+cMf/uB44403HNu3b9dR4Y4dO3bUu/13333naNmypWPu3Lnmu/D99983342FhYV+O0ZCTxMYMmSIY9asWa77VVVVji5dujiWLVvmdftJkyY5/vmf/9ljXXp6umPmzJl+P1bbznVN9+/fd7Ru3dqxZcsWPx6lnedZz+2wYcMcGzdudEybNo3Q44fz/OGHHzoef/xxR2VlZQCP0r7zrNuOGjXKY51+MT/99NN+P9ZwIQ0IPb/85S8dffv29ViXlZXlyMzM9Ntx0b31kCorK+XYsWOm28T9Gl56/9ChQ1730fXu26vMzMw6t0fjz3VN//jHP+TevXvSvn17Px6pned5yZIlkpCQIDk5OQE6UvvO86effipDhw413VuJiYnSr18/+c1vfiNVVVUBPPLwP8/Dhg0z+zi7wL777jvThfjcc88F7LhtcCgI34VccPQhXb9+3Xzg6AeQO71/8uRJr/uUlZV53V7Xo2nPdU2vv/666W+u+YuGhzvPxcXFsmnTJikpKQnQUdp5nvXLd//+/TJlyhTzJXzmzBn5xS9+YYK8znSLpjnPkydPNvsNHz7cXL37/v378tJLL8mvfvWrAB21Hcrq+C7Uq7H/z//8j6mnamq09MAab7/9timy3bFjhylmRNOoqKiQ7OxsUzTesWPHYB9OWKuurjataevXr5dBgwZJVlaWvPHGG7J27dpgH1pY0eJabUH793//dzl+/Lhs375dPvvsM3nrrbeCfWh4SLT0PCT9kI+KipLy8nKP9Xq/U6dOXvfR9b5sj8afa6d3333XhJ69e/fKk08+6ecjtes8nz17Vs6dO2dGbbh/Oavo6Gg5deqU9OzZMwBHHv7/nnXEVosWLcx+Tj/4wQ/MX8zajRMTE+P347bhPP/61782Qf7nP/+5ua8jbO/cuSO5ubkmZGr3GB5eXd+Fbdq08Usrj+In95D0Q0b/4tq3b5/HB77e1753b3S9+/Zqz549dW6Pxp9rtXz5cvMXWmFhoaSlpQXoaO05zzr1Qmlpqenaci7jx4+XkSNHmv/X4b5omn/PTz/9tOnScoZK9Ze//MWEIQJP051nrf2rGWycQZPLVTadoHwX+q1E2rLhkDq88eOPPzbD7nJzc81wyLKyMvN4dna2Y/78+R5D1qOjox3vvvuuGUadl5fHkHU/neu3337bDFX9z//8T8eVK1dcS0VFRRDfRfid55oYveWf83z+/Hkz+nD27NmOU6dOOXbt2uVISEhw/Nu//VsQ30X4nWf9TNbz/B//8R9mWPXu3bsdPXv2NCNvUTf9XNXpQXTReLFy5Urz/99//715XM+xnuuaQ9Zfe+01812o04swZD1E6PwCjz32mPmC1eGRhw8fdj32T//0T+ZLwN3vf/97R69evcz2OmTvs88+C8JRh/+5Tk5ONr98NRf9UEPT/pt2R+jx33n+8ssvzRQX+iWuw9eXLl1qpgtA053ne/fuORYtWmSCTlxcnCMpKcnxi1/8wnHjxo0gHX1oKCoq8vp56zy3eqvnuuY+AwYMMD8X/ff80Ucf+fUYI/Q//mtHAgAAaB6o6QEAAFYg9AAAACsQegAAgBUIPQAAwAqEHgAAYAVCDwAAsAKhBwAAWIHQAwAArEDoAQAAViD0AAAAKxB6AACAFQg9AABAbPB/mp6n5MhbWusAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key, value in evaluate.items():\n",
    "    plt.plot(key[1], value[5], 'k.')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "71865a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "259cadeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "y = []\n",
    "z = []\n",
    "for key, value in evaluate.items():\n",
    "    x.append(key[0])\n",
    "    y.append(key[1])\n",
    "    z.append(value[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "e0a4044b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0.25, 0.25, 0.25, 0.25, 0.25, 0.5, 0.5, 0.5, 0.5, 0.5, 0.75, 0.75, 0.75, 0.75, 0.75, 1, 1, 1, 1, 1]\n",
      "[0, 0.25, 0.5, 0.75, 1, 0, 0.25, 0.5, 0.75, 1, 0, 0.25, 0.5, 0.75, 1, 0, 0.25, 0.5, 0.75, 1, 0, 0.25, 0.5, 0.75, 1]\n",
      "[0.4548, 0.4548, 0.4536, 0.4572, 0.4528, 0.4548, 0.4572, 0.456, 0.458, 0.4548, 0.4532, 0.4552, 0.4516, 0.4544, 0.456, 0.4544, 0.4532, 0.4536, 0.4528, 0.45, 0.456, 0.458, 0.4528, 0.4488, 0.4496]\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goemotions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
