{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "710d8ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b6bc31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ems = \"\"\"\n",
    "admiration\n",
    "amusement\n",
    "anger\n",
    "annoyance\n",
    "approval\n",
    "caring\n",
    "confusion\n",
    "curiosity\n",
    "desire\n",
    "disappointment\n",
    "disapproval\n",
    "disgust\n",
    "embarrassment\n",
    "excitement\n",
    "fear\n",
    "gratitude\n",
    "grief\n",
    "joy\n",
    "love\n",
    "nervousness\n",
    "optimism\n",
    "pride\n",
    "realization\n",
    "relief\n",
    "remorse\n",
    "sadness\n",
    "surprise\n",
    "neutral\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4a196e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotions_to_categorical(df):\n",
    "    res = []\n",
    "\n",
    "    for i in df['emotions']:\n",
    "        tmp = [0 for _ in range(28)]\n",
    "        for j in i:\n",
    "            tmp[j] = 1\n",
    "        res.append(tmp)\n",
    "    tmp_df = pd.DataFrame(res, columns=ems.split())\n",
    "    \n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "975c4f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotions_to_ekman(df):\n",
    "    # anger disgust fear joy sadness surprise neutral\n",
    "    ekman = [3, 3, 0, 0, 3, 3, 5, 5, 3, 4, 0, 1, 4, 3, 2, 3, 4, 3, 3, 2, 3, 3, 5, 3, 4, 4, 5, 6]\n",
    "    res = []\n",
    "\n",
    "    for i in df:\n",
    "        tmp = [0, 0, 0, 0, 0, 0, 0]\n",
    "        for j in range(len(i)):\n",
    "            if i[j] == 1:\n",
    "                tmp[ekman[j]] = 1\n",
    "        res.append(tmp)\n",
    "    tmp_df = pd.DataFrame(res, columns=['angry', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'neutral'])\n",
    "    \n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "628b9fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_init(path = \"../data/dev.tsv\"):\n",
    "    df = pd.read_csv(path, sep=\"\\t\", encoding = \"utf-8\", header=None)\n",
    "    df.columns = ['text', 'emotions', 'id']\n",
    "    df['emotions'] = list(map(lambda s : list(map(int, s.split(','))), df['emotions']))\n",
    "    df = pd.concat([df, emotions_to_categorical(df)], axis=1)\n",
    "    df = df.drop(columns=['emotions', 'id'])\n",
    "    df['text'] = list(map(lambda s : s.replace('\\\\', '\\\\\\\\').replace('\"', '\\\\\"'), list(df['text']))) \n",
    "    return df.iloc[:2500, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "144fb321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(original_df, emotion_res):\n",
    "    emotions_list = ems.split()\n",
    "    df = original_df\n",
    "    predicted_df = pd.DataFrame(data = [[0 for _ in range(28)] for _ in range(len(df))], columns=emotions_list)\n",
    "    for i in range(len(emotion_res)):\n",
    "        for j in emotion_res[i]:\n",
    "            if j in emotions_list:\n",
    "                predicted_df.loc[i, j] = 1\n",
    "    predicted = predicted_df.to_numpy()\n",
    "    original = df.iloc[:,1:].to_numpy()\n",
    "    \n",
    "    \n",
    "    accuracy = accuracy_score(original, predicted)\n",
    "    \n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
    "        original, predicted, average='micro'\n",
    "    )\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        original, predicted, average='macro'\n",
    "    )\n",
    "    \n",
    "    precision_per_label, recall_per_label, f1_per_label, _ = precision_recall_fscore_support(\n",
    "        original, predicted, average=None\n",
    "    )\n",
    "\n",
    "    precision_macro_std = np.std(precision_per_label)\n",
    "    recall_macro_std = np.std(recall_per_label)\n",
    "    f1_macro_std = np.std(f1_per_label)\n",
    "\n",
    "    print(\"--- 모델 평가 결과 ---\")\n",
    "    print(f\"전체 샘플에 대한 정확도 (Exact Match Accuracy): {accuracy:.4f}\")\n",
    "    print(\"\\n--- Micro 평균 지표 ---\")\n",
    "    print(f\"Precision (Micro): {precision_micro:.4f}\")\n",
    "    print(f\"Recall (Micro): {recall_micro:.4f}\")\n",
    "    print(f\"F1-Score (Micro): {f1_micro:.4f}\")\n",
    "    print(\"\\n--- Macro 평균 지표 ---\")\n",
    "    print(f\"Precision (Macro): {precision_macro:.4f}\")\n",
    "    print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
    "    print(f\"F1-Score (Macro): {f1_macro:.4f}\")\n",
    "    \n",
    "    print(\"\\n--- 라벨별 지표 ---\")\n",
    "    for i in range(len(emotions_list)):\n",
    "        print(f\"{emotions_list[i]} - Precision: {precision_per_label[i]:.4f}, Recall: {recall_per_label[i]:.4f}, F1-Score: {f1_per_label[i]:.4f}\")\n",
    "    \n",
    "    print(f\"\\nPrecision (Macro) 표준편차: {precision_macro_std:.4f}\")\n",
    "    print(f\"Recall (Macro) 표준편차: {recall_macro_std:.4f}\")\n",
    "    print(f\"F1-Score (Macro) 표준편차: {f1_macro_std:.4f}\")\n",
    "\n",
    "    return accuracy, f1_micro, f1_macro, precision_recall_fscore_support(original, predicted, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "078a66fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_ekman(original_df, emotion_res):\n",
    "    emotions_list = 'anger disgust fear joy sadness surprise neutral'.split()\n",
    "    predicted_df = pd.DataFrame(data = [[0 for _ in range(28)] for _ in range(len(original_df))], columns=ems.split())\n",
    "    for i in range(len(emotion_res)):\n",
    "        for j in emotion_res[i]:\n",
    "            if j in ems.split():\n",
    "                predicted_df.loc[i, j] = 1\n",
    "    predicted = emotions_to_ekman(predicted_df.to_numpy()).to_numpy()\n",
    "    original = emotions_to_ekman(original_df.iloc[:,1:].to_numpy()).to_numpy()\n",
    "\n",
    "    accuracy = accuracy_score(original, predicted)\n",
    "    \n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
    "        original, predicted, average='micro'\n",
    "    )\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        original, predicted, average='macro'\n",
    "    )\n",
    "    \n",
    "    precision_per_label, recall_per_label, f1_per_label, _ = precision_recall_fscore_support(\n",
    "        original, predicted, average=None\n",
    "    )\n",
    "\n",
    "    precision_macro_std = np.std(precision_per_label)\n",
    "    recall_macro_std = np.std(recall_per_label)\n",
    "    f1_macro_std = np.std(f1_per_label)\n",
    "\n",
    "    print(\"--- 모델 평가 결과 ---\")\n",
    "    print(f\"전체 샘플에 대한 정확도 (Exact Match Accuracy): {accuracy:.4f}\")\n",
    "    print(\"\\n--- Micro 평균 지표 ---\")\n",
    "    print(f\"Precision (Micro): {precision_micro:.4f}\")\n",
    "    print(f\"Recall (Micro): {recall_micro:.4f}\")\n",
    "    print(f\"F1-Score (Micro): {f1_micro:.4f}\")\n",
    "    print(\"\\n--- Macro 평균 지표 ---\")\n",
    "    print(f\"Precision (Macro): {precision_macro:.4f}\")\n",
    "    print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
    "    print(f\"F1-Score (Macro): {f1_macro:.4f}\")\n",
    "    \n",
    "    print(\"\\n--- 라벨별 지표 ---\")\n",
    "    for i in range(len(emotions_list)):\n",
    "        print(f\"{emotions_list[i]} - Precision: {precision_per_label[i]:.4f}, Recall: {recall_per_label[i]:.4f}, F1-Score: {f1_per_label[i]:.4f}\")\n",
    "    \n",
    "    print(f\"\\nPrecision (Macro) 표준편차: {precision_macro_std:.4f}\")\n",
    "    print(f\"Recall (Macro) 표준편차: {recall_macro_std:.4f}\")\n",
    "    print(f\"F1-Score (Macro) 표준편차: {f1_macro_std:.4f}\")\n",
    "\n",
    "    return accuracy, f1_micro, f1_macro, precision_recall_fscore_support(original, predicted, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "902084ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_init():\n",
    "    file_dict = {}\n",
    "    file_names = {\n",
    "        'persona': './prompt/persona.txt',\n",
    "        'guidelines': './prompt/guidelines.txt',\n",
    "        'output_structure': './prompt/output_structure.txt',\n",
    "        'few_shot': './prompt/few_shot.txt',\n",
    "        'few_shot_4': './prompt/few_shot_4.txt',\n",
    "        'few_shot_8': './prompt/few_shot_8.txt',\n",
    "        'few_shot_12': './prompt/few_shot_12.txt',\n",
    "        'few_shot_16': './prompt/few_shot_16.txt',\n",
    "        'few_shot_20': './prompt/few_shot_20.txt',\n",
    "        'cot': './prompt/chain_of_thought.txt',\n",
    "        'description':  './prompt/emotion_description.txt'\n",
    "    }\n",
    "    for key, value in file_names.items():\n",
    "        file = open(value, 'r')\n",
    "        file_dict[key] = file.read()\n",
    "        file.close()\n",
    "    return file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9153854b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = file_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "defcfc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "systems = {\n",
    "    4: f\"{files['persona']}{files['description']}{files['guidelines']}{files['output_structure']}{files['few_shot_4']}\",\n",
    "    8: f\"{files['persona']}{files['description']}{files['guidelines']}{files['output_structure']}{files['few_shot_8']}\",\n",
    "    12: f\"{files['persona']}{files['description']}{files['guidelines']}{files['output_structure']}{files['few_shot_12']}\",\n",
    "    16: f\"{files['persona']}{files['description']}{files['guidelines']}{files['output_structure']}{files['few_shot_16']}\",\n",
    "    20: f\"{files['persona']}{files['description']}{files['guidelines']}{files['output_structure']}{files['few_shot_20']}\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66b36c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b8f4d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "it = [(0.25, 0.75), (0.00, 0.25),(0.50, 1.00)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3b90955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in systems.items():\n",
    "    i = 0\n",
    "    for j in it:\n",
    "        with open(f\"./inputs/few_shot_grid/version2/few_shot_grid_{key}_{i}.jsonl\", \"w\") as f:\n",
    "            k = 0\n",
    "            for record in data[\"text\"]:\n",
    "                baseQuery = {\n",
    "                \"custom_id\": f\"query{k}\",\n",
    "                \"method\": \"POST\",\n",
    "                \"url\": \"/v1/responses\",\n",
    "                \"body\": {\n",
    "                        \"model\": \"gpt-4o-mini\",\n",
    "                        \"temperature\": j[0],\n",
    "                        \"top_p\": j[1],\n",
    "                        \"input\": [{\n",
    "                            \"role\": \"developer\",\n",
    "                            \"content\": f\"{value}\"\n",
    "                        }, \n",
    "                        {\n",
    "                            \"role\": \"user\",\n",
    "                            \"content\": f\"{record}\"\n",
    "                        }], \n",
    "                        \"max_output_tokens\": 1000,\n",
    "                        \"text\": {\n",
    "                            \"format\": {\n",
    "                                \"type\": \"json_schema\",\n",
    "                                \"name\": \"result\",\n",
    "                                \"strict\": True,\n",
    "                                \"schema\": {\n",
    "                                    \"type\": \"object\",\n",
    "                                    \"properties\": {\n",
    "                                        \"analysis\": {\n",
    "                                            \"type\": \"array\",\n",
    "                                            \"items\": {\n",
    "                                                \"type\": \"object\",\n",
    "                                                \"properties\": {\n",
    "                                                    \"emotion\": {\n",
    "                                                        \"type\": \"string\",\n",
    "                                                        \"enum\": [ \"admiration\", \"amusement\", \"anger\", \"annoyance\", \"approval\", \"caring\", \"confusion\", \"curiosity\", \"desire\", \"disappointment\", \"disapproval\", \"disgust\", \"embarrassment\", \"excitement\", \"fear\", \"gratitude\", \"grief\", \"joy\", \"love\", \"nervousness\", \"optimism\", \"pride\", \"realization\", \"relief\", \"remorse\", \"sadness\", \"surprise\", \"neutral\" ]\n",
    "                                                    },\n",
    "                                                    \"reason\": {\n",
    "                                                        \"type\": \"string\"\n",
    "                                                    }\n",
    "                                                },\n",
    "                                                \"required\": [\"emotion\", \"reason\"],\n",
    "                                                \"additionalProperties\": False\n",
    "                                            }\n",
    "                                        }\n",
    "                                    },\n",
    "                                    \"required\": [\"analysis\"],\n",
    "                                    \"additionalProperties\": False\n",
    "                                }\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "                k += 1\n",
    "                f.write(json.dumps(baseQuery) + \"\\n\")\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09d73f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_file = open('./key/openai_key.txt', 'r')\n",
    "api_key = key_file.readline()\n",
    "key_file.close()\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9d3cd597",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fbbf8057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-Y4uMoNsQfFa87VzGHPpMy7', bytes=29057821, created_at=1762145807, filename='few_shot_grid_20_2.jsonl', object='file', purpose='batch', status='processed', expires_at=1764737807, status_details=None)\n"
     ]
    }
   ],
   "source": [
    "for i in range(20, 21, 4):\n",
    "    for j in range(2, 3):\n",
    "        batch_input_file = client.files.create(\n",
    "            file=open(f\"./inputs/few_shot_grid/version2/few_shot_grid_{i}_{j}.jsonl\", \"rb\"),\n",
    "            purpose='batch'\n",
    "        )\n",
    "        print(batch_input_file)\n",
    "        \n",
    "        batch_input_file_id = batch_input_file.id\n",
    "        create_batch=client.batches.create(\n",
    "            input_file_id=batch_input_file_id,\n",
    "            endpoint=\"/v1/responses\",\n",
    "            completion_window=\"24h\",\n",
    "        )\n",
    "        batch_list.append(create_batch.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6aa9aef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_690812716c3481909126d96df05787a9\n",
      "batch_69081289c3648190acf68565aeb6f3c5\n",
      "batch_690812a18dd881908da20eee396e18b7\n",
      "batch_690812bd536c8190a484251bdf45bc08\n",
      "batch_690812d8837881909669e212451a3f9c\n",
      "batch_690812f417d88190be3cb7974508c624\n",
      "batch_69081312faa08190a5a4ea0498a3bdf7\n",
      "batch_690813326a008190a1fa91e968abcb21\n",
      "batch_690813528d488190a152474917246d77\n",
      "batch_69081d0790788190acd811022212212a\n",
      "batch_69081d23e14481908d88e0a2eb8e7ca1\n",
      "batch_69081d3b698c81909b8818ed1c973aeb\n",
      "batch_69081d5933a481909b17ef0fbf593c46\n",
      "batch_69081d73d5bc8190ac048b1741b3e28d\n",
      "batch_69081d8ea1fc819092550a0a6c9537cc\n"
     ]
    }
   ],
   "source": [
    "for i in batch_list:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3f95f91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_res = [0] * len(batch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5703c90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 done!\n",
      "1 done!\n",
      "2 done!\n",
      "3 done!\n",
      "4 done!\n",
      "5 done!\n",
      "6 done!\n",
      "7 done!\n",
      "8 done!\n",
      "9 done!\n",
      "10 it does not finish yet\n",
      "in_progress\n",
      "BatchRequestCounts(completed=2497, failed=0, total=2500)\n",
      "11 it does not finish yet\n",
      "in_progress\n",
      "BatchRequestCounts(completed=2491, failed=0, total=2500)\n",
      "12 it does not finish yet\n",
      "in_progress\n",
      "BatchRequestCounts(completed=2444, failed=16, total=2500)\n",
      "13 done!\n",
      "14 it does not finish yet\n",
      "in_progress\n",
      "BatchRequestCounts(completed=1666, failed=12, total=2500)\n",
      "11 / 15\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in range(len(batch_list)):\n",
    "    print(i, end=\" \")\n",
    "    if batch_res[i] != 0:\n",
    "        print(\"done\")\n",
    "        cnt += 1\n",
    "        continue\n",
    "    batch = client.batches.retrieve(batch_list[i])\n",
    "    result = None\n",
    "    if batch.status == 'completed':\n",
    "        out = batch.output_file_id\n",
    "        if out != None:\n",
    "            cnt += 1\n",
    "            print('done!')\n",
    "            result = client.files.content(out)\n",
    "            batch_res[i] = result\n",
    "        else:\n",
    "            print('error')\n",
    "            result = client.files.content(batch.error_file_id).text\n",
    "            batch_res[i] = result\n",
    "    elif batch.status == 'failed':\n",
    "        print('failed')\n",
    "        print(batch.errors)\n",
    "    else:\n",
    "        print('it does not finish yet')\n",
    "        print(batch.status)\n",
    "        print(batch.request_counts)\n",
    "print(cnt, \"/\", len(batch_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "431afe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_res = []\n",
    "\n",
    "for i in range(4, 21, 4):\n",
    "    for j in range(3):\n",
    "        file = open(f'./output/20251103/adjusted_fewshot_{i}_{j}.jsonl', 'r')\n",
    "        batch_res.append(file.read())\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "46a9dfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------4-(0.25, 0.75)------------------------\n",
      "                                                   text  admiration  \\\n",
      "0     Is this in New Orleans?? I really feel like th...           0   \n",
      "1     You know the answer man, you are programmed to...           0   \n",
      "2                  I've never been this sad in my life!           0   \n",
      "3     The economy is heavily controlled and subsidiz...           0   \n",
      "4     He could have easily taken a real camera from ...           0   \n",
      "...                                                 ...         ...   \n",
      "2495                    You got this, good luck brother           0   \n",
      "2496                        You smile warmly at people.           1   \n",
      "2497  yuck, I'd be embarrassed to walk around with a...           0   \n",
      "2498  Ok then youre leaving the enmey widow uncontes...           1   \n",
      "2499  Oh, also forgot to add, LOTION! ALWAYS lotion ...           0   \n",
      "\n",
      "      amusement  anger  annoyance  approval  caring  confusion  curiosity  \\\n",
      "0             0      0          0         0       0          0          0   \n",
      "1             0      0          0         1       0          0          0   \n",
      "2             0      0          0         0       0          0          0   \n",
      "3             0      0          0         1       0          0          0   \n",
      "4             0      0          0         0       0          0          0   \n",
      "...         ...    ...        ...       ...     ...        ...        ...   \n",
      "2495          0      0          0         0       0          0          0   \n",
      "2496          0      0          0         0       0          0          0   \n",
      "2497          0      0          0         0       0          0          0   \n",
      "2498          0      0          0         0       0          0          0   \n",
      "2499          0      0          0         0       0          0          0   \n",
      "\n",
      "      desire  ...  love  nervousness  optimism  pride  realization  relief  \\\n",
      "0          0  ...     0            0         0      0            0       0   \n",
      "1          0  ...     0            0         0      0            0       0   \n",
      "2          0  ...     0            0         0      0            0       0   \n",
      "3          0  ...     0            0         0      0            0       0   \n",
      "4          0  ...     0            0         1      0            0       0   \n",
      "...      ...  ...   ...          ...       ...    ...          ...     ...   \n",
      "2495       0  ...     0            0         1      0            0       0   \n",
      "2496       0  ...     0            0         0      0            0       0   \n",
      "2497       0  ...     0            0         0      0            0       0   \n",
      "2498       0  ...     0            0         0      0            0       0   \n",
      "2499       0  ...     0            0         0      0            1       0   \n",
      "\n",
      "      remorse  sadness  surprise  neutral  \n",
      "0           0        0         0        1  \n",
      "1           0        0         0        1  \n",
      "2           0        1         0        0  \n",
      "3           0        0         0        1  \n",
      "4           0        0         0        0  \n",
      "...       ...      ...       ...      ...  \n",
      "2495        0        0         0        0  \n",
      "2496        0        0         0        0  \n",
      "2497        0        0         0        0  \n",
      "2498        0        0         0        0  \n",
      "2499        0        0         0        0  \n",
      "\n",
      "[2500 rows x 29 columns]\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2300\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3154\n",
      "Recall (Micro): 0.2816\n",
      "F1-Score (Micro): 0.2975\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3703\n",
      "Recall (Macro): 0.3334\n",
      "F1-Score (Macro): 0.3034\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.6825, Recall: 0.1886, F1-Score: 0.2955\n",
      "amusement - Precision: 0.3378, Recall: 0.6824, F1-Score: 0.4519\n",
      "anger - Precision: 0.2311, Recall: 0.6778, F1-Score: 0.3446\n",
      "annoyance - Precision: 0.1667, Recall: 0.1071, F1-Score: 0.1304\n",
      "approval - Precision: 0.2785, Recall: 0.1272, F1-Score: 0.1746\n",
      "caring - Precision: 0.2556, Recall: 0.3538, F1-Score: 0.2968\n",
      "confusion - Precision: 0.1461, Recall: 0.4706, F1-Score: 0.2230\n",
      "curiosity - Precision: 0.2748, Recall: 0.3130, F1-Score: 0.2927\n",
      "desire - Precision: 0.3810, Recall: 0.2353, F1-Score: 0.2909\n",
      "disappointment - Precision: 0.1557, Recall: 0.2405, F1-Score: 0.1891\n",
      "disapproval - Precision: 0.1829, Recall: 0.3381, F1-Score: 0.2374\n",
      "disgust - Precision: 0.3864, Recall: 0.3333, F1-Score: 0.3579\n",
      "embarrassment - Precision: 0.5385, Recall: 0.4667, F1-Score: 0.5000\n",
      "excitement - Precision: 0.2812, Recall: 0.2195, F1-Score: 0.2466\n",
      "fear - Precision: 0.3385, Recall: 0.5116, F1-Score: 0.4074\n",
      "gratitude - Precision: 0.9420, Recall: 0.3916, F1-Score: 0.5532\n",
      "grief - Precision: 0.3571, Recall: 0.5556, F1-Score: 0.4348\n",
      "joy - Precision: 0.1855, Recall: 0.4946, F1-Score: 0.2698\n",
      "love - Precision: 0.7297, Recall: 0.2500, F1-Score: 0.3724\n",
      "nervousness - Precision: 0.4286, Recall: 0.2727, F1-Score: 0.3333\n",
      "optimism - Precision: 0.4138, Recall: 0.3429, F1-Score: 0.3750\n",
      "pride - Precision: 0.4000, Recall: 0.6000, F1-Score: 0.4800\n",
      "realization - Precision: 0.2727, Recall: 0.0469, F1-Score: 0.0800\n",
      "relief - Precision: 0.0500, Recall: 0.1429, F1-Score: 0.0741\n",
      "remorse - Precision: 0.6000, Recall: 0.0789, F1-Score: 0.1395\n",
      "sadness - Precision: 0.3100, Recall: 0.4697, F1-Score: 0.3735\n",
      "surprise - Precision: 0.3810, Recall: 0.2623, F1-Score: 0.3107\n",
      "neutral - Precision: 0.6598, Recall: 0.1624, F1-Score: 0.2607\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1989\n",
      "Recall (Macro) 표준편차: 0.1744\n",
      "F1-Score (Macro) 표준편차: 0.1209\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4564\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5319\n",
      "Recall (Micro): 0.4991\n",
      "F1-Score (Micro): 0.5150\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4737\n",
      "Recall (Macro): 0.4919\n",
      "F1-Score (Macro): 0.4511\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3602, Recall: 0.6385, F1-Score: 0.4606\n",
      "disgust - Precision: 0.3864, Recall: 0.3333, F1-Score: 0.3579\n",
      "fear - Precision: 0.4028, Recall: 0.5472, F1-Score: 0.4640\n",
      "joy - Precision: 0.7167, Recall: 0.7014, F1-Score: 0.7090\n",
      "sadness - Precision: 0.4111, Recall: 0.5417, F1-Score: 0.4674\n",
      "surprise - Precision: 0.3791, Recall: 0.5188, F1-Score: 0.4380\n",
      "neutral - Precision: 0.6598, Recall: 0.1624, F1-Score: 0.2607\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1374\n",
      "Recall (Macro) 표준편차: 0.1713\n",
      "F1-Score (Macro) 표준편차: 0.1266\n",
      "------------------------4-(0.0, 0.25)------------------------\n",
      "                                                   text  admiration  \\\n",
      "0     Is this in New Orleans?? I really feel like th...           0   \n",
      "1     You know the answer man, you are programmed to...           0   \n",
      "2                  I've never been this sad in my life!           0   \n",
      "3     The economy is heavily controlled and subsidiz...           0   \n",
      "4     He could have easily taken a real camera from ...           0   \n",
      "...                                                 ...         ...   \n",
      "2495                    You got this, good luck brother           0   \n",
      "2496                        You smile warmly at people.           1   \n",
      "2497  yuck, I'd be embarrassed to walk around with a...           0   \n",
      "2498  Ok then youre leaving the enmey widow uncontes...           1   \n",
      "2499  Oh, also forgot to add, LOTION! ALWAYS lotion ...           0   \n",
      "\n",
      "      amusement  anger  annoyance  approval  caring  confusion  curiosity  \\\n",
      "0             0      0          0         0       0          0          0   \n",
      "1             0      0          0         1       0          0          0   \n",
      "2             0      0          0         0       0          0          0   \n",
      "3             0      0          0         1       0          0          0   \n",
      "4             0      0          0         0       0          0          0   \n",
      "...         ...    ...        ...       ...     ...        ...        ...   \n",
      "2495          0      0          0         0       0          0          0   \n",
      "2496          0      0          0         0       0          0          0   \n",
      "2497          0      0          0         0       0          0          0   \n",
      "2498          0      0          0         0       0          0          0   \n",
      "2499          0      0          0         0       0          0          0   \n",
      "\n",
      "      desire  ...  love  nervousness  optimism  pride  realization  relief  \\\n",
      "0          0  ...     0            0         0      0            0       0   \n",
      "1          0  ...     0            0         0      0            0       0   \n",
      "2          0  ...     0            0         0      0            0       0   \n",
      "3          0  ...     0            0         0      0            0       0   \n",
      "4          0  ...     0            0         1      0            0       0   \n",
      "...      ...  ...   ...          ...       ...    ...          ...     ...   \n",
      "2495       0  ...     0            0         1      0            0       0   \n",
      "2496       0  ...     0            0         0      0            0       0   \n",
      "2497       0  ...     0            0         0      0            0       0   \n",
      "2498       0  ...     0            0         0      0            0       0   \n",
      "2499       0  ...     0            0         0      0            1       0   \n",
      "\n",
      "      remorse  sadness  surprise  neutral  \n",
      "0           0        0         0        1  \n",
      "1           0        0         0        1  \n",
      "2           0        1         0        0  \n",
      "3           0        0         0        1  \n",
      "4           0        0         0        0  \n",
      "...       ...      ...       ...      ...  \n",
      "2495        0        0         0        0  \n",
      "2496        0        0         0        0  \n",
      "2497        0        0         0        0  \n",
      "2498        0        0         0        0  \n",
      "2499        0        0         0        0  \n",
      "\n",
      "[2500 rows x 29 columns]\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2304\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3163\n",
      "Recall (Micro): 0.2829\n",
      "F1-Score (Micro): 0.2987\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3665\n",
      "Recall (Macro): 0.3367\n",
      "F1-Score (Macro): 0.3058\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.6364, Recall: 0.1842, F1-Score: 0.2857\n",
      "amusement - Precision: 0.3378, Recall: 0.6757, F1-Score: 0.4505\n",
      "anger - Precision: 0.2460, Recall: 0.6889, F1-Score: 0.3626\n",
      "annoyance - Precision: 0.1630, Recall: 0.1071, F1-Score: 0.1293\n",
      "approval - Precision: 0.2727, Recall: 0.1214, F1-Score: 0.1680\n",
      "caring - Precision: 0.2500, Recall: 0.3231, F1-Score: 0.2819\n",
      "confusion - Precision: 0.1514, Recall: 0.4853, F1-Score: 0.2308\n",
      "curiosity - Precision: 0.2609, Recall: 0.3130, F1-Score: 0.2846\n",
      "desire - Precision: 0.4167, Recall: 0.2941, F1-Score: 0.3448\n",
      "disappointment - Precision: 0.1545, Recall: 0.2405, F1-Score: 0.1881\n",
      "disapproval - Precision: 0.1905, Recall: 0.3741, F1-Score: 0.2524\n",
      "disgust - Precision: 0.4000, Recall: 0.3529, F1-Score: 0.3750\n",
      "embarrassment - Precision: 0.5000, Recall: 0.4667, F1-Score: 0.4828\n",
      "excitement - Precision: 0.2647, Recall: 0.2195, F1-Score: 0.2400\n",
      "fear - Precision: 0.3793, Recall: 0.5116, F1-Score: 0.4356\n",
      "gratitude - Precision: 0.9265, Recall: 0.3795, F1-Score: 0.5385\n",
      "grief - Precision: 0.3846, Recall: 0.5556, F1-Score: 0.4545\n",
      "joy - Precision: 0.1878, Recall: 0.4946, F1-Score: 0.2722\n",
      "love - Precision: 0.7368, Recall: 0.2593, F1-Score: 0.3836\n",
      "nervousness - Precision: 0.3750, Recall: 0.2727, F1-Score: 0.3158\n",
      "optimism - Precision: 0.4096, Recall: 0.3238, F1-Score: 0.3617\n",
      "pride - Precision: 0.4286, Recall: 0.6000, F1-Score: 0.5000\n",
      "realization - Precision: 0.2727, Recall: 0.0469, F1-Score: 0.0800\n",
      "relief - Precision: 0.0500, Recall: 0.1429, F1-Score: 0.0741\n",
      "remorse - Precision: 0.5000, Recall: 0.0526, F1-Score: 0.0952\n",
      "sadness - Precision: 0.3143, Recall: 0.5000, F1-Score: 0.3860\n",
      "surprise - Precision: 0.4048, Recall: 0.2787, F1-Score: 0.3301\n",
      "neutral - Precision: 0.6465, Recall: 0.1624, F1-Score: 0.2596\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1904\n",
      "Recall (Macro) 표준편차: 0.1768\n",
      "F1-Score (Macro) 표준편차: 0.1253\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4540\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5297\n",
      "Recall (Micro): 0.4987\n",
      "F1-Score (Micro): 0.5137\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4759\n",
      "Recall (Macro): 0.4940\n",
      "F1-Score (Macro): 0.4543\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3622, Recall: 0.6472, F1-Score: 0.4644\n",
      "disgust - Precision: 0.4000, Recall: 0.3529, F1-Score: 0.3750\n",
      "fear - Precision: 0.4242, Recall: 0.5283, F1-Score: 0.4706\n",
      "joy - Precision: 0.7140, Recall: 0.6947, F1-Score: 0.7042\n",
      "sadness - Precision: 0.4054, Recall: 0.5469, F1-Score: 0.4656\n",
      "surprise - Precision: 0.3793, Recall: 0.5256, F1-Score: 0.4406\n",
      "neutral - Precision: 0.6465, Recall: 0.1624, F1-Score: 0.2596\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1317\n",
      "Recall (Macro) 표준편차: 0.1684\n",
      "F1-Score (Macro) 표준편차: 0.1238\n",
      "------------------------4-(0.5, 1.0)------------------------\n",
      "                                                   text  admiration  \\\n",
      "0     Is this in New Orleans?? I really feel like th...           0   \n",
      "1     You know the answer man, you are programmed to...           0   \n",
      "2                  I've never been this sad in my life!           0   \n",
      "3     The economy is heavily controlled and subsidiz...           0   \n",
      "4     He could have easily taken a real camera from ...           0   \n",
      "...                                                 ...         ...   \n",
      "2495                    You got this, good luck brother           0   \n",
      "2496                        You smile warmly at people.           1   \n",
      "2497  yuck, I'd be embarrassed to walk around with a...           0   \n",
      "2498  Ok then youre leaving the enmey widow uncontes...           1   \n",
      "2499  Oh, also forgot to add, LOTION! ALWAYS lotion ...           0   \n",
      "\n",
      "      amusement  anger  annoyance  approval  caring  confusion  curiosity  \\\n",
      "0             0      0          0         0       0          0          0   \n",
      "1             0      0          0         1       0          0          0   \n",
      "2             0      0          0         0       0          0          0   \n",
      "3             0      0          0         1       0          0          0   \n",
      "4             0      0          0         0       0          0          0   \n",
      "...         ...    ...        ...       ...     ...        ...        ...   \n",
      "2495          0      0          0         0       0          0          0   \n",
      "2496          0      0          0         0       0          0          0   \n",
      "2497          0      0          0         0       0          0          0   \n",
      "2498          0      0          0         0       0          0          0   \n",
      "2499          0      0          0         0       0          0          0   \n",
      "\n",
      "      desire  ...  love  nervousness  optimism  pride  realization  relief  \\\n",
      "0          0  ...     0            0         0      0            0       0   \n",
      "1          0  ...     0            0         0      0            0       0   \n",
      "2          0  ...     0            0         0      0            0       0   \n",
      "3          0  ...     0            0         0      0            0       0   \n",
      "4          0  ...     0            0         1      0            0       0   \n",
      "...      ...  ...   ...          ...       ...    ...          ...     ...   \n",
      "2495       0  ...     0            0         1      0            0       0   \n",
      "2496       0  ...     0            0         0      0            0       0   \n",
      "2497       0  ...     0            0         0      0            0       0   \n",
      "2498       0  ...     0            0         0      0            0       0   \n",
      "2499       0  ...     0            0         0      0            1       0   \n",
      "\n",
      "      remorse  sadness  surprise  neutral  \n",
      "0           0        0         0        1  \n",
      "1           0        0         0        1  \n",
      "2           0        1         0        0  \n",
      "3           0        0         0        1  \n",
      "4           0        0         0        0  \n",
      "...       ...      ...       ...      ...  \n",
      "2495        0        0         0        0  \n",
      "2496        0        0         0        0  \n",
      "2497        0        0         0        0  \n",
      "2498        0        0         0        0  \n",
      "2499        0        0         0        0  \n",
      "\n",
      "[2500 rows x 29 columns]\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2244\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3099\n",
      "Recall (Micro): 0.2778\n",
      "F1-Score (Micro): 0.2930\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3685\n",
      "Recall (Macro): 0.3371\n",
      "F1-Score (Macro): 0.3033\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.6515, Recall: 0.1886, F1-Score: 0.2925\n",
      "amusement - Precision: 0.3412, Recall: 0.6824, F1-Score: 0.4550\n",
      "anger - Precision: 0.2366, Recall: 0.6889, F1-Score: 0.3523\n",
      "annoyance - Precision: 0.1522, Recall: 0.1000, F1-Score: 0.1207\n",
      "approval - Precision: 0.2750, Recall: 0.1272, F1-Score: 0.1739\n",
      "caring - Precision: 0.2588, Recall: 0.3385, F1-Score: 0.2933\n",
      "confusion - Precision: 0.1460, Recall: 0.4853, F1-Score: 0.2245\n",
      "curiosity - Precision: 0.2519, Recall: 0.2957, F1-Score: 0.2720\n",
      "desire - Precision: 0.3600, Recall: 0.2647, F1-Score: 0.3051\n",
      "disappointment - Precision: 0.1393, Recall: 0.2152, F1-Score: 0.1692\n",
      "disapproval - Precision: 0.1835, Recall: 0.3525, F1-Score: 0.2414\n",
      "disgust - Precision: 0.3864, Recall: 0.3333, F1-Score: 0.3579\n",
      "embarrassment - Precision: 0.5000, Recall: 0.4000, F1-Score: 0.4444\n",
      "excitement - Precision: 0.2812, Recall: 0.2195, F1-Score: 0.2466\n",
      "fear - Precision: 0.3443, Recall: 0.4884, F1-Score: 0.4038\n",
      "gratitude - Precision: 0.9077, Recall: 0.3554, F1-Score: 0.5108\n",
      "grief - Precision: 0.3125, Recall: 0.5556, F1-Score: 0.4000\n",
      "joy - Precision: 0.1903, Recall: 0.5054, F1-Score: 0.2765\n",
      "love - Precision: 0.7059, Recall: 0.2222, F1-Score: 0.3380\n",
      "nervousness - Precision: 0.5714, Recall: 0.3636, F1-Score: 0.4444\n",
      "optimism - Precision: 0.4416, Recall: 0.3238, F1-Score: 0.3736\n",
      "pride - Precision: 0.3889, Recall: 0.7000, F1-Score: 0.5000\n",
      "realization - Precision: 0.3125, Recall: 0.0781, F1-Score: 0.1250\n",
      "relief - Precision: 0.0556, Recall: 0.1429, F1-Score: 0.0800\n",
      "remorse - Precision: 0.6000, Recall: 0.0789, F1-Score: 0.1395\n",
      "sadness - Precision: 0.3333, Recall: 0.5303, F1-Score: 0.4094\n",
      "surprise - Precision: 0.3571, Recall: 0.2459, F1-Score: 0.2913\n",
      "neutral - Precision: 0.6340, Recall: 0.1561, F1-Score: 0.2505\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1941\n",
      "Recall (Macro) 표준편차: 0.1815\n",
      "F1-Score (Macro) 표준편차: 0.1167\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4468\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5234\n",
      "Recall (Micro): 0.4944\n",
      "F1-Score (Micro): 0.5085\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4675\n",
      "Recall (Macro): 0.4884\n",
      "F1-Score (Macro): 0.4467\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3570, Recall: 0.6443, F1-Score: 0.4595\n",
      "disgust - Precision: 0.3864, Recall: 0.3333, F1-Score: 0.3579\n",
      "fear - Precision: 0.4118, Recall: 0.5283, F1-Score: 0.4628\n",
      "joy - Precision: 0.7119, Recall: 0.6899, F1-Score: 0.7007\n",
      "sadness - Precision: 0.3923, Recall: 0.5312, F1-Score: 0.4513\n",
      "surprise - Precision: 0.3792, Recall: 0.5358, F1-Score: 0.4441\n",
      "neutral - Precision: 0.6340, Recall: 0.1561, F1-Score: 0.2505\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1324\n",
      "Recall (Macro) 표준편차: 0.1712\n",
      "F1-Score (Macro) 표준편차: 0.1261\n",
      "------------------------8-(0.25, 0.75)------------------------\n",
      "                                                   text  admiration  \\\n",
      "0     Is this in New Orleans?? I really feel like th...           0   \n",
      "1     You know the answer man, you are programmed to...           0   \n",
      "2                  I've never been this sad in my life!           0   \n",
      "3     The economy is heavily controlled and subsidiz...           0   \n",
      "4     He could have easily taken a real camera from ...           0   \n",
      "...                                                 ...         ...   \n",
      "2495                    You got this, good luck brother           0   \n",
      "2496                        You smile warmly at people.           1   \n",
      "2497  yuck, I'd be embarrassed to walk around with a...           0   \n",
      "2498  Ok then youre leaving the enmey widow uncontes...           1   \n",
      "2499  Oh, also forgot to add, LOTION! ALWAYS lotion ...           0   \n",
      "\n",
      "      amusement  anger  annoyance  approval  caring  confusion  curiosity  \\\n",
      "0             0      0          0         0       0          0          0   \n",
      "1             0      0          0         1       0          0          0   \n",
      "2             0      0          0         0       0          0          0   \n",
      "3             0      0          0         1       0          0          0   \n",
      "4             0      0          0         0       0          0          0   \n",
      "...         ...    ...        ...       ...     ...        ...        ...   \n",
      "2495          0      0          0         0       0          0          0   \n",
      "2496          0      0          0         0       0          0          0   \n",
      "2497          0      0          0         0       0          0          0   \n",
      "2498          0      0          0         0       0          0          0   \n",
      "2499          0      0          0         0       0          0          0   \n",
      "\n",
      "      desire  ...  love  nervousness  optimism  pride  realization  relief  \\\n",
      "0          0  ...     0            0         0      0            0       0   \n",
      "1          0  ...     0            0         0      0            0       0   \n",
      "2          0  ...     0            0         0      0            0       0   \n",
      "3          0  ...     0            0         0      0            0       0   \n",
      "4          0  ...     0            0         1      0            0       0   \n",
      "...      ...  ...   ...          ...       ...    ...          ...     ...   \n",
      "2495       0  ...     0            0         1      0            0       0   \n",
      "2496       0  ...     0            0         0      0            0       0   \n",
      "2497       0  ...     0            0         0      0            0       0   \n",
      "2498       0  ...     0            0         0      0            0       0   \n",
      "2499       0  ...     0            0         0      0            1       0   \n",
      "\n",
      "      remorse  sadness  surprise  neutral  \n",
      "0           0        0         0        1  \n",
      "1           0        0         0        1  \n",
      "2           0        1         0        0  \n",
      "3           0        0         0        1  \n",
      "4           0        0         0        0  \n",
      "...       ...      ...       ...      ...  \n",
      "2495        0        0         0        0  \n",
      "2496        0        0         0        0  \n",
      "2497        0        0         0        0  \n",
      "2498        0        0         0        0  \n",
      "2499        0        0         0        0  \n",
      "\n",
      "[2500 rows x 29 columns]\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2412\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3264\n",
      "Recall (Micro): 0.2856\n",
      "F1-Score (Micro): 0.3046\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3716\n",
      "Recall (Macro): 0.3284\n",
      "F1-Score (Macro): 0.3056\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.7059, Recall: 0.2105, F1-Score: 0.3243\n",
      "amusement - Precision: 0.3255, Recall: 0.6554, F1-Score: 0.4350\n",
      "anger - Precision: 0.2743, Recall: 0.6889, F1-Score: 0.3924\n",
      "annoyance - Precision: 0.1860, Recall: 0.1143, F1-Score: 0.1416\n",
      "approval - Precision: 0.2381, Recall: 0.1156, F1-Score: 0.1556\n",
      "caring - Precision: 0.2651, Recall: 0.3385, F1-Score: 0.2973\n",
      "confusion - Precision: 0.1574, Recall: 0.5000, F1-Score: 0.2394\n",
      "curiosity - Precision: 0.2431, Recall: 0.3043, F1-Score: 0.2703\n",
      "desire - Precision: 0.4688, Recall: 0.4412, F1-Score: 0.4545\n",
      "disappointment - Precision: 0.1795, Recall: 0.2658, F1-Score: 0.2143\n",
      "disapproval - Precision: 0.2056, Recall: 0.3669, F1-Score: 0.2636\n",
      "disgust - Precision: 0.3878, Recall: 0.3725, F1-Score: 0.3800\n",
      "embarrassment - Precision: 0.4615, Recall: 0.4000, F1-Score: 0.4286\n",
      "excitement - Precision: 0.2903, Recall: 0.2195, F1-Score: 0.2500\n",
      "fear - Precision: 0.3667, Recall: 0.5116, F1-Score: 0.4272\n",
      "gratitude - Precision: 0.9206, Recall: 0.3494, F1-Score: 0.5066\n",
      "grief - Precision: 0.3077, Recall: 0.4444, F1-Score: 0.3636\n",
      "joy - Precision: 0.2072, Recall: 0.4946, F1-Score: 0.2921\n",
      "love - Precision: 0.7222, Recall: 0.2407, F1-Score: 0.3611\n",
      "nervousness - Precision: 0.6667, Recall: 0.3636, F1-Score: 0.4706\n",
      "optimism - Precision: 0.4000, Recall: 0.3619, F1-Score: 0.3800\n",
      "pride - Precision: 0.3846, Recall: 0.5000, F1-Score: 0.4348\n",
      "realization - Precision: 0.2353, Recall: 0.0625, F1-Score: 0.0988\n",
      "relief - Precision: 0.0000, Recall: 0.0000, F1-Score: 0.0000\n",
      "remorse - Precision: 0.5000, Recall: 0.0263, F1-Score: 0.0500\n",
      "sadness - Precision: 0.3146, Recall: 0.4242, F1-Score: 0.3613\n",
      "surprise - Precision: 0.3488, Recall: 0.2459, F1-Score: 0.2885\n",
      "neutral - Precision: 0.6419, Recall: 0.1751, F1-Score: 0.2752\n",
      "\n",
      "Precision (Macro) 표준편차: 0.2010\n",
      "Recall (Macro) 표준편차: 0.1725\n",
      "F1-Score (Macro) 표준편차: 0.1272\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4632\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5371\n",
      "Recall (Micro): 0.4987\n",
      "F1-Score (Micro): 0.5172\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4754\n",
      "Recall (Macro): 0.4889\n",
      "F1-Score (Macro): 0.4556\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3757, Recall: 0.6122, F1-Score: 0.4656\n",
      "disgust - Precision: 0.3878, Recall: 0.3725, F1-Score: 0.3800\n",
      "fear - Precision: 0.4242, Recall: 0.5283, F1-Score: 0.4706\n",
      "joy - Precision: 0.7165, Recall: 0.7034, F1-Score: 0.7099\n",
      "sadness - Precision: 0.4145, Recall: 0.5052, F1-Score: 0.4554\n",
      "surprise - Precision: 0.3675, Recall: 0.5256, F1-Score: 0.4326\n",
      "neutral - Precision: 0.6419, Recall: 0.1751, F1-Score: 0.2752\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1317\n",
      "Recall (Macro) 표준편차: 0.1587\n",
      "F1-Score (Macro) 표준편차: 0.1218\n",
      "------------------------8-(0.0, 0.25)------------------------\n",
      "                                                   text  admiration  \\\n",
      "0     Is this in New Orleans?? I really feel like th...           0   \n",
      "1     You know the answer man, you are programmed to...           0   \n",
      "2                  I've never been this sad in my life!           0   \n",
      "3     The economy is heavily controlled and subsidiz...           0   \n",
      "4     He could have easily taken a real camera from ...           0   \n",
      "...                                                 ...         ...   \n",
      "2495                    You got this, good luck brother           0   \n",
      "2496                        You smile warmly at people.           1   \n",
      "2497  yuck, I'd be embarrassed to walk around with a...           0   \n",
      "2498  Ok then youre leaving the enmey widow uncontes...           1   \n",
      "2499  Oh, also forgot to add, LOTION! ALWAYS lotion ...           0   \n",
      "\n",
      "      amusement  anger  annoyance  approval  caring  confusion  curiosity  \\\n",
      "0             0      0          0         0       0          0          0   \n",
      "1             0      0          0         1       0          0          0   \n",
      "2             0      0          0         0       0          0          0   \n",
      "3             0      0          0         1       0          0          0   \n",
      "4             0      0          0         0       0          0          0   \n",
      "...         ...    ...        ...       ...     ...        ...        ...   \n",
      "2495          0      0          0         0       0          0          0   \n",
      "2496          0      0          0         0       0          0          0   \n",
      "2497          0      0          0         0       0          0          0   \n",
      "2498          0      0          0         0       0          0          0   \n",
      "2499          0      0          0         0       0          0          0   \n",
      "\n",
      "      desire  ...  love  nervousness  optimism  pride  realization  relief  \\\n",
      "0          0  ...     0            0         0      0            0       0   \n",
      "1          0  ...     0            0         0      0            0       0   \n",
      "2          0  ...     0            0         0      0            0       0   \n",
      "3          0  ...     0            0         0      0            0       0   \n",
      "4          0  ...     0            0         1      0            0       0   \n",
      "...      ...  ...   ...          ...       ...    ...          ...     ...   \n",
      "2495       0  ...     0            0         1      0            0       0   \n",
      "2496       0  ...     0            0         0      0            0       0   \n",
      "2497       0  ...     0            0         0      0            0       0   \n",
      "2498       0  ...     0            0         0      0            0       0   \n",
      "2499       0  ...     0            0         0      0            1       0   \n",
      "\n",
      "      remorse  sadness  surprise  neutral  \n",
      "0           0        0         0        1  \n",
      "1           0        0         0        1  \n",
      "2           0        1         0        0  \n",
      "3           0        0         0        1  \n",
      "4           0        0         0        0  \n",
      "...       ...      ...       ...      ...  \n",
      "2495        0        0         0        0  \n",
      "2496        0        0         0        0  \n",
      "2497        0        0         0        0  \n",
      "2498        0        0         0        0  \n",
      "2499        0        0         0        0  \n",
      "\n",
      "[2500 rows x 29 columns]\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2368\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3227\n",
      "Recall (Micro): 0.2816\n",
      "F1-Score (Micro): 0.3007\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3730\n",
      "Recall (Macro): 0.3288\n",
      "F1-Score (Macro): 0.3035\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.7167, Recall: 0.1886, F1-Score: 0.2986\n",
      "amusement - Precision: 0.3168, Recall: 0.6486, F1-Score: 0.4257\n",
      "anger - Precision: 0.2723, Recall: 0.6778, F1-Score: 0.3885\n",
      "annoyance - Precision: 0.1839, Recall: 0.1143, F1-Score: 0.1410\n",
      "approval - Precision: 0.2500, Recall: 0.1156, F1-Score: 0.1581\n",
      "caring - Precision: 0.2791, Recall: 0.3692, F1-Score: 0.3179\n",
      "confusion - Precision: 0.1636, Recall: 0.5147, F1-Score: 0.2482\n",
      "curiosity - Precision: 0.2448, Recall: 0.3043, F1-Score: 0.2713\n",
      "desire - Precision: 0.4839, Recall: 0.4412, F1-Score: 0.4615\n",
      "disappointment - Precision: 0.1754, Recall: 0.2532, F1-Score: 0.2073\n",
      "disapproval - Precision: 0.1903, Recall: 0.3381, F1-Score: 0.2435\n",
      "disgust - Precision: 0.3519, Recall: 0.3725, F1-Score: 0.3619\n",
      "embarrassment - Precision: 0.5000, Recall: 0.4000, F1-Score: 0.4444\n",
      "excitement - Precision: 0.3000, Recall: 0.2195, F1-Score: 0.2535\n",
      "fear - Precision: 0.3729, Recall: 0.5116, F1-Score: 0.4314\n",
      "gratitude - Precision: 0.9138, Recall: 0.3193, F1-Score: 0.4732\n",
      "grief - Precision: 0.3077, Recall: 0.4444, F1-Score: 0.3636\n",
      "joy - Precision: 0.2000, Recall: 0.5054, F1-Score: 0.2866\n",
      "love - Precision: 0.7714, Recall: 0.2500, F1-Score: 0.3776\n",
      "nervousness - Precision: 0.5000, Recall: 0.2727, F1-Score: 0.3529\n",
      "optimism - Precision: 0.4066, Recall: 0.3524, F1-Score: 0.3776\n",
      "pride - Precision: 0.3846, Recall: 0.5000, F1-Score: 0.4348\n",
      "realization - Precision: 0.2667, Recall: 0.0625, F1-Score: 0.1013\n",
      "relief - Precision: 0.0588, Recall: 0.1429, F1-Score: 0.0833\n",
      "remorse - Precision: 0.5000, Recall: 0.0263, F1-Score: 0.0500\n",
      "sadness - Precision: 0.3187, Recall: 0.4394, F1-Score: 0.3694\n",
      "surprise - Precision: 0.3846, Recall: 0.2459, F1-Score: 0.3000\n",
      "neutral - Precision: 0.6301, Recall: 0.1751, F1-Score: 0.2741\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1942\n",
      "Recall (Macro) 표준편차: 0.1654\n",
      "F1-Score (Macro) 표준편차: 0.1159\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4632\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5374\n",
      "Recall (Micro): 0.4980\n",
      "F1-Score (Micro): 0.5170\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4714\n",
      "Recall (Macro): 0.4889\n",
      "F1-Score (Macro): 0.4546\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3763, Recall: 0.6122, F1-Score: 0.4661\n",
      "disgust - Precision: 0.3519, Recall: 0.3725, F1-Score: 0.3619\n",
      "fear - Precision: 0.4308, Recall: 0.5283, F1-Score: 0.4746\n",
      "joy - Precision: 0.7160, Recall: 0.7014, F1-Score: 0.7086\n",
      "sadness - Precision: 0.4224, Recall: 0.5104, F1-Score: 0.4623\n",
      "surprise - Precision: 0.3723, Recall: 0.5222, F1-Score: 0.4347\n",
      "neutral - Precision: 0.6301, Recall: 0.1751, F1-Score: 0.2741\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1321\n",
      "Recall (Macro) 표준편차: 0.1583\n",
      "F1-Score (Macro) 표준편차: 0.1235\n",
      "------------------------8-(0.5, 1.0)------------------------\n",
      "                                                   text  admiration  \\\n",
      "0     Is this in New Orleans?? I really feel like th...           0   \n",
      "1     You know the answer man, you are programmed to...           0   \n",
      "2                  I've never been this sad in my life!           0   \n",
      "3     The economy is heavily controlled and subsidiz...           0   \n",
      "4     He could have easily taken a real camera from ...           0   \n",
      "...                                                 ...         ...   \n",
      "2495                    You got this, good luck brother           0   \n",
      "2496                        You smile warmly at people.           1   \n",
      "2497  yuck, I'd be embarrassed to walk around with a...           0   \n",
      "2498  Ok then youre leaving the enmey widow uncontes...           1   \n",
      "2499  Oh, also forgot to add, LOTION! ALWAYS lotion ...           0   \n",
      "\n",
      "      amusement  anger  annoyance  approval  caring  confusion  curiosity  \\\n",
      "0             0      0          0         0       0          0          0   \n",
      "1             0      0          0         1       0          0          0   \n",
      "2             0      0          0         0       0          0          0   \n",
      "3             0      0          0         1       0          0          0   \n",
      "4             0      0          0         0       0          0          0   \n",
      "...         ...    ...        ...       ...     ...        ...        ...   \n",
      "2495          0      0          0         0       0          0          0   \n",
      "2496          0      0          0         0       0          0          0   \n",
      "2497          0      0          0         0       0          0          0   \n",
      "2498          0      0          0         0       0          0          0   \n",
      "2499          0      0          0         0       0          0          0   \n",
      "\n",
      "      desire  ...  love  nervousness  optimism  pride  realization  relief  \\\n",
      "0          0  ...     0            0         0      0            0       0   \n",
      "1          0  ...     0            0         0      0            0       0   \n",
      "2          0  ...     0            0         0      0            0       0   \n",
      "3          0  ...     0            0         0      0            0       0   \n",
      "4          0  ...     0            0         1      0            0       0   \n",
      "...      ...  ...   ...          ...       ...    ...          ...     ...   \n",
      "2495       0  ...     0            0         1      0            0       0   \n",
      "2496       0  ...     0            0         0      0            0       0   \n",
      "2497       0  ...     0            0         0      0            0       0   \n",
      "2498       0  ...     0            0         0      0            0       0   \n",
      "2499       0  ...     0            0         0      0            1       0   \n",
      "\n",
      "      remorse  sadness  surprise  neutral  \n",
      "0           0        0         0        1  \n",
      "1           0        0         0        1  \n",
      "2           0        1         0        0  \n",
      "3           0        0         0        1  \n",
      "4           0        0         0        0  \n",
      "...       ...      ...       ...      ...  \n",
      "2495        0        0         0        0  \n",
      "2496        0        0         0        0  \n",
      "2497        0        0         0        0  \n",
      "2498        0        0         0        0  \n",
      "2499        0        0         0        0  \n",
      "\n",
      "[2500 rows x 29 columns]\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2392\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3253\n",
      "Recall (Micro): 0.2849\n",
      "F1-Score (Micro): 0.3038\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3603\n",
      "Recall (Macro): 0.3270\n",
      "F1-Score (Macro): 0.3000\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.6901, Recall: 0.2149, F1-Score: 0.3278\n",
      "amusement - Precision: 0.3276, Recall: 0.6486, F1-Score: 0.4354\n",
      "anger - Precision: 0.2703, Recall: 0.6667, F1-Score: 0.3846\n",
      "annoyance - Precision: 0.2048, Recall: 0.1214, F1-Score: 0.1525\n",
      "approval - Precision: 0.2333, Recall: 0.1214, F1-Score: 0.1597\n",
      "caring - Precision: 0.2706, Recall: 0.3538, F1-Score: 0.3067\n",
      "confusion - Precision: 0.1560, Recall: 0.5000, F1-Score: 0.2378\n",
      "curiosity - Precision: 0.2500, Recall: 0.3130, F1-Score: 0.2780\n",
      "desire - Precision: 0.4688, Recall: 0.4412, F1-Score: 0.4545\n",
      "disappointment - Precision: 0.1667, Recall: 0.2405, F1-Score: 0.1969\n",
      "disapproval - Precision: 0.2072, Recall: 0.3741, F1-Score: 0.2667\n",
      "disgust - Precision: 0.3333, Recall: 0.3333, F1-Score: 0.3333\n",
      "embarrassment - Precision: 0.4000, Recall: 0.4000, F1-Score: 0.4000\n",
      "excitement - Precision: 0.3000, Recall: 0.2195, F1-Score: 0.2535\n",
      "fear - Precision: 0.3571, Recall: 0.4651, F1-Score: 0.4040\n",
      "gratitude - Precision: 0.9322, Recall: 0.3313, F1-Score: 0.4889\n",
      "grief - Precision: 0.2857, Recall: 0.4444, F1-Score: 0.3478\n",
      "joy - Precision: 0.2045, Recall: 0.4839, F1-Score: 0.2875\n",
      "love - Precision: 0.7250, Recall: 0.2685, F1-Score: 0.3919\n",
      "nervousness - Precision: 0.3750, Recall: 0.2727, F1-Score: 0.3158\n",
      "optimism - Precision: 0.4176, Recall: 0.3619, F1-Score: 0.3878\n",
      "pride - Precision: 0.3571, Recall: 0.5000, F1-Score: 0.4167\n",
      "realization - Precision: 0.2667, Recall: 0.0625, F1-Score: 0.1013\n",
      "relief - Precision: 0.0526, Recall: 0.1429, F1-Score: 0.0769\n",
      "remorse - Precision: 0.5000, Recall: 0.0263, F1-Score: 0.0500\n",
      "sadness - Precision: 0.3182, Recall: 0.4242, F1-Score: 0.3636\n",
      "surprise - Precision: 0.3947, Recall: 0.2459, F1-Score: 0.3030\n",
      "neutral - Precision: 0.6222, Recall: 0.1777, F1-Score: 0.2764\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1877\n",
      "Recall (Macro) 표준편차: 0.1597\n",
      "F1-Score (Macro) 표준편차: 0.1128\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4588\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5335\n",
      "Recall (Micro): 0.4947\n",
      "F1-Score (Micro): 0.5134\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4631\n",
      "Recall (Macro): 0.4772\n",
      "F1-Score (Macro): 0.4455\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3705, Recall: 0.6006, F1-Score: 0.4583\n",
      "disgust - Precision: 0.3333, Recall: 0.3333, F1-Score: 0.3333\n",
      "fear - Precision: 0.4062, Recall: 0.4906, F1-Score: 0.4444\n",
      "joy - Precision: 0.7108, Recall: 0.6957, F1-Score: 0.7031\n",
      "sadness - Precision: 0.4206, Recall: 0.5104, F1-Score: 0.4612\n",
      "surprise - Precision: 0.3777, Recall: 0.5324, F1-Score: 0.4419\n",
      "neutral - Precision: 0.6222, Recall: 0.1777, F1-Score: 0.2764\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1333\n",
      "Recall (Macro) 표준편차: 0.1593\n",
      "F1-Score (Macro) 표준편차: 0.1242\n",
      "------------------------12-(0.25, 0.75)------------------------\n",
      "                                                   text  admiration  \\\n",
      "0     Is this in New Orleans?? I really feel like th...           0   \n",
      "1     You know the answer man, you are programmed to...           0   \n",
      "2                  I've never been this sad in my life!           0   \n",
      "3     The economy is heavily controlled and subsidiz...           0   \n",
      "4     He could have easily taken a real camera from ...           0   \n",
      "...                                                 ...         ...   \n",
      "2495                    You got this, good luck brother           0   \n",
      "2496                        You smile warmly at people.           1   \n",
      "2497  yuck, I'd be embarrassed to walk around with a...           0   \n",
      "2498  Ok then youre leaving the enmey widow uncontes...           1   \n",
      "2499  Oh, also forgot to add, LOTION! ALWAYS lotion ...           0   \n",
      "\n",
      "      amusement  anger  annoyance  approval  caring  confusion  curiosity  \\\n",
      "0             0      0          0         0       0          0          0   \n",
      "1             0      0          0         1       0          0          0   \n",
      "2             0      0          0         0       0          0          0   \n",
      "3             0      0          0         1       0          0          0   \n",
      "4             0      0          0         0       0          0          0   \n",
      "...         ...    ...        ...       ...     ...        ...        ...   \n",
      "2495          0      0          0         0       0          0          0   \n",
      "2496          0      0          0         0       0          0          0   \n",
      "2497          0      0          0         0       0          0          0   \n",
      "2498          0      0          0         0       0          0          0   \n",
      "2499          0      0          0         0       0          0          0   \n",
      "\n",
      "      desire  ...  love  nervousness  optimism  pride  realization  relief  \\\n",
      "0          0  ...     0            0         0      0            0       0   \n",
      "1          0  ...     0            0         0      0            0       0   \n",
      "2          0  ...     0            0         0      0            0       0   \n",
      "3          0  ...     0            0         0      0            0       0   \n",
      "4          0  ...     0            0         1      0            0       0   \n",
      "...      ...  ...   ...          ...       ...    ...          ...     ...   \n",
      "2495       0  ...     0            0         1      0            0       0   \n",
      "2496       0  ...     0            0         0      0            0       0   \n",
      "2497       0  ...     0            0         0      0            0       0   \n",
      "2498       0  ...     0            0         0      0            0       0   \n",
      "2499       0  ...     0            0         0      0            1       0   \n",
      "\n",
      "      remorse  sadness  surprise  neutral  \n",
      "0           0        0         0        1  \n",
      "1           0        0         0        1  \n",
      "2           0        1         0        0  \n",
      "3           0        0         0        1  \n",
      "4           0        0         0        0  \n",
      "...       ...      ...       ...      ...  \n",
      "2495        0        0         0        0  \n",
      "2496        0        0         0        0  \n",
      "2497        0        0         0        0  \n",
      "2498        0        0         0        0  \n",
      "2499        0        0         0        0  \n",
      "\n",
      "[2500 rows x 29 columns]\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2440\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3325\n",
      "Recall (Micro): 0.2992\n",
      "F1-Score (Micro): 0.3149\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3825\n",
      "Recall (Macro): 0.3500\n",
      "F1-Score (Macro): 0.3223\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.7571, Recall: 0.2325, F1-Score: 0.3557\n",
      "amusement - Precision: 0.3415, Recall: 0.6622, F1-Score: 0.4506\n",
      "anger - Precision: 0.2941, Recall: 0.6667, F1-Score: 0.4082\n",
      "annoyance - Precision: 0.2118, Recall: 0.1286, F1-Score: 0.1600\n",
      "approval - Precision: 0.2222, Recall: 0.1272, F1-Score: 0.1618\n",
      "caring - Precision: 0.2449, Recall: 0.3692, F1-Score: 0.2945\n",
      "confusion - Precision: 0.1628, Recall: 0.5147, F1-Score: 0.2473\n",
      "curiosity - Precision: 0.2500, Recall: 0.3478, F1-Score: 0.2909\n",
      "desire - Precision: 0.4706, Recall: 0.4706, F1-Score: 0.4706\n",
      "disappointment - Precision: 0.1600, Recall: 0.2532, F1-Score: 0.1961\n",
      "disapproval - Precision: 0.1851, Recall: 0.3741, F1-Score: 0.2476\n",
      "disgust - Precision: 0.3750, Recall: 0.4118, F1-Score: 0.3925\n",
      "embarrassment - Precision: 0.5455, Recall: 0.4000, F1-Score: 0.4615\n",
      "excitement - Precision: 0.2368, Recall: 0.2195, F1-Score: 0.2278\n",
      "fear - Precision: 0.3667, Recall: 0.5116, F1-Score: 0.4272\n",
      "gratitude - Precision: 0.9118, Recall: 0.3735, F1-Score: 0.5299\n",
      "grief - Precision: 0.3077, Recall: 0.4444, F1-Score: 0.3636\n",
      "joy - Precision: 0.2280, Recall: 0.4731, F1-Score: 0.3077\n",
      "love - Precision: 0.7742, Recall: 0.4444, F1-Score: 0.5647\n",
      "nervousness - Precision: 0.5714, Recall: 0.3636, F1-Score: 0.4444\n",
      "optimism - Precision: 0.4000, Recall: 0.3048, F1-Score: 0.3459\n",
      "pride - Precision: 0.3571, Recall: 0.5000, F1-Score: 0.4167\n",
      "realization - Precision: 0.3333, Recall: 0.0938, F1-Score: 0.1463\n",
      "relief - Precision: 0.0400, Recall: 0.1429, F1-Score: 0.0625\n",
      "remorse - Precision: 0.6667, Recall: 0.0526, F1-Score: 0.0976\n",
      "sadness - Precision: 0.3158, Recall: 0.4545, F1-Score: 0.3727\n",
      "surprise - Precision: 0.3333, Recall: 0.2951, F1-Score: 0.3130\n",
      "neutral - Precision: 0.6471, Recall: 0.1675, F1-Score: 0.2661\n",
      "\n",
      "Precision (Macro) 표준편차: 0.2079\n",
      "Recall (Macro) 표준편차: 0.1597\n",
      "F1-Score (Macro) 표준편차: 0.1275\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4576\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5340\n",
      "Recall (Micro): 0.5042\n",
      "F1-Score (Micro): 0.5187\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4750\n",
      "Recall (Macro): 0.5055\n",
      "F1-Score (Macro): 0.4608\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3768, Recall: 0.6239, F1-Score: 0.4698\n",
      "disgust - Precision: 0.3750, Recall: 0.4118, F1-Score: 0.3925\n",
      "fear - Precision: 0.4328, Recall: 0.5472, F1-Score: 0.4833\n",
      "joy - Precision: 0.7163, Recall: 0.7024, F1-Score: 0.7093\n",
      "sadness - Precision: 0.4008, Recall: 0.5156, F1-Score: 0.4510\n",
      "surprise - Precision: 0.3761, Recall: 0.5700, F1-Score: 0.4532\n",
      "neutral - Precision: 0.6471, Recall: 0.1675, F1-Score: 0.2661\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1334\n",
      "Recall (Macro) 표준편차: 0.1612\n",
      "F1-Score (Macro) 표준편차: 0.1225\n",
      "------------------------12-(0.0, 0.25)------------------------\n",
      "                                                   text  admiration  \\\n",
      "0     Is this in New Orleans?? I really feel like th...           0   \n",
      "1     You know the answer man, you are programmed to...           0   \n",
      "2                  I've never been this sad in my life!           0   \n",
      "3     The economy is heavily controlled and subsidiz...           0   \n",
      "4     He could have easily taken a real camera from ...           0   \n",
      "...                                                 ...         ...   \n",
      "2495                    You got this, good luck brother           0   \n",
      "2496                        You smile warmly at people.           1   \n",
      "2497  yuck, I'd be embarrassed to walk around with a...           0   \n",
      "2498  Ok then youre leaving the enmey widow uncontes...           1   \n",
      "2499  Oh, also forgot to add, LOTION! ALWAYS lotion ...           0   \n",
      "\n",
      "      amusement  anger  annoyance  approval  caring  confusion  curiosity  \\\n",
      "0             0      0          0         0       0          0          0   \n",
      "1             0      0          0         1       0          0          0   \n",
      "2             0      0          0         0       0          0          0   \n",
      "3             0      0          0         1       0          0          0   \n",
      "4             0      0          0         0       0          0          0   \n",
      "...         ...    ...        ...       ...     ...        ...        ...   \n",
      "2495          0      0          0         0       0          0          0   \n",
      "2496          0      0          0         0       0          0          0   \n",
      "2497          0      0          0         0       0          0          0   \n",
      "2498          0      0          0         0       0          0          0   \n",
      "2499          0      0          0         0       0          0          0   \n",
      "\n",
      "      desire  ...  love  nervousness  optimism  pride  realization  relief  \\\n",
      "0          0  ...     0            0         0      0            0       0   \n",
      "1          0  ...     0            0         0      0            0       0   \n",
      "2          0  ...     0            0         0      0            0       0   \n",
      "3          0  ...     0            0         0      0            0       0   \n",
      "4          0  ...     0            0         1      0            0       0   \n",
      "...      ...  ...   ...          ...       ...    ...          ...     ...   \n",
      "2495       0  ...     0            0         1      0            0       0   \n",
      "2496       0  ...     0            0         0      0            0       0   \n",
      "2497       0  ...     0            0         0      0            0       0   \n",
      "2498       0  ...     0            0         0      0            0       0   \n",
      "2499       0  ...     0            0         0      0            1       0   \n",
      "\n",
      "      remorse  sadness  surprise  neutral  \n",
      "0           0        0         0        1  \n",
      "1           0        0         0        1  \n",
      "2           0        1         0        0  \n",
      "3           0        0         0        1  \n",
      "4           0        0         0        0  \n",
      "...       ...      ...       ...      ...  \n",
      "2495        0        0         0        0  \n",
      "2496        0        0         0        0  \n",
      "2497        0        0         0        0  \n",
      "2498        0        0         0        0  \n",
      "2499        0        0         0        0  \n",
      "\n",
      "[2500 rows x 29 columns]\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2444\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3321\n",
      "Recall (Micro): 0.2978\n",
      "F1-Score (Micro): 0.3140\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3657\n",
      "Recall (Macro): 0.3513\n",
      "F1-Score (Macro): 0.3194\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.7463, Recall: 0.2193, F1-Score: 0.3390\n",
      "amusement - Precision: 0.3472, Recall: 0.6757, F1-Score: 0.4587\n",
      "anger - Precision: 0.3069, Recall: 0.6889, F1-Score: 0.4247\n",
      "annoyance - Precision: 0.1954, Recall: 0.1214, F1-Score: 0.1498\n",
      "approval - Precision: 0.2062, Recall: 0.1156, F1-Score: 0.1481\n",
      "caring - Precision: 0.2553, Recall: 0.3692, F1-Score: 0.3019\n",
      "confusion - Precision: 0.1675, Recall: 0.5147, F1-Score: 0.2527\n",
      "curiosity - Precision: 0.2470, Recall: 0.3565, F1-Score: 0.2918\n",
      "desire - Precision: 0.4722, Recall: 0.5000, F1-Score: 0.4857\n",
      "disappointment - Precision: 0.1591, Recall: 0.2658, F1-Score: 0.1991\n",
      "disapproval - Precision: 0.1971, Recall: 0.3957, F1-Score: 0.2632\n",
      "disgust - Precision: 0.3750, Recall: 0.4118, F1-Score: 0.3925\n",
      "embarrassment - Precision: 0.4615, Recall: 0.4000, F1-Score: 0.4286\n",
      "excitement - Precision: 0.2571, Recall: 0.2195, F1-Score: 0.2368\n",
      "fear - Precision: 0.3684, Recall: 0.4884, F1-Score: 0.4200\n",
      "gratitude - Precision: 0.8841, Recall: 0.3675, F1-Score: 0.5191\n",
      "grief - Precision: 0.2857, Recall: 0.4444, F1-Score: 0.3478\n",
      "joy - Precision: 0.2228, Recall: 0.4839, F1-Score: 0.3051\n",
      "love - Precision: 0.7667, Recall: 0.4259, F1-Score: 0.5476\n",
      "nervousness - Precision: 0.5000, Recall: 0.3636, F1-Score: 0.4211\n",
      "optimism - Precision: 0.3902, Recall: 0.3048, F1-Score: 0.3422\n",
      "pride - Precision: 0.3571, Recall: 0.5000, F1-Score: 0.4167\n",
      "realization - Precision: 0.3500, Recall: 0.1094, F1-Score: 0.1667\n",
      "relief - Precision: 0.0417, Recall: 0.1429, F1-Score: 0.0645\n",
      "remorse - Precision: 0.3333, Recall: 0.0263, F1-Score: 0.0488\n",
      "sadness - Precision: 0.3333, Recall: 0.4697, F1-Score: 0.3899\n",
      "surprise - Precision: 0.3600, Recall: 0.2951, F1-Score: 0.3243\n",
      "neutral - Precision: 0.6528, Recall: 0.1599, F1-Score: 0.2569\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1924\n",
      "Recall (Macro) 표준편차: 0.1651\n",
      "F1-Score (Macro) 표준편차: 0.1279\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4616\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5378\n",
      "Recall (Micro): 0.5060\n",
      "F1-Score (Micro): 0.5214\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4781\n",
      "Recall (Macro): 0.5069\n",
      "F1-Score (Macro): 0.4619\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3848, Recall: 0.6327, F1-Score: 0.4785\n",
      "disgust - Precision: 0.3750, Recall: 0.4118, F1-Score: 0.3925\n",
      "fear - Precision: 0.4308, Recall: 0.5283, F1-Score: 0.4746\n",
      "joy - Precision: 0.7198, Recall: 0.7072, F1-Score: 0.7135\n",
      "sadness - Precision: 0.4078, Recall: 0.5417, F1-Score: 0.4653\n",
      "surprise - Precision: 0.3756, Recall: 0.5666, F1-Score: 0.4517\n",
      "neutral - Precision: 0.6528, Recall: 0.1599, F1-Score: 0.2569\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1341\n",
      "Recall (Macro) 표준편차: 0.1650\n",
      "F1-Score (Macro) 표준편차: 0.1257\n",
      "------------------------12-(0.5, 1.0)------------------------\n",
      "                                                   text  admiration  \\\n",
      "0     Is this in New Orleans?? I really feel like th...           0   \n",
      "1     You know the answer man, you are programmed to...           0   \n",
      "2                  I've never been this sad in my life!           0   \n",
      "3     The economy is heavily controlled and subsidiz...           0   \n",
      "4     He could have easily taken a real camera from ...           0   \n",
      "...                                                 ...         ...   \n",
      "2495                    You got this, good luck brother           0   \n",
      "2496                        You smile warmly at people.           1   \n",
      "2497  yuck, I'd be embarrassed to walk around with a...           0   \n",
      "2498  Ok then youre leaving the enmey widow uncontes...           1   \n",
      "2499  Oh, also forgot to add, LOTION! ALWAYS lotion ...           0   \n",
      "\n",
      "      amusement  anger  annoyance  approval  caring  confusion  curiosity  \\\n",
      "0             0      0          0         0       0          0          0   \n",
      "1             0      0          0         1       0          0          0   \n",
      "2             0      0          0         0       0          0          0   \n",
      "3             0      0          0         1       0          0          0   \n",
      "4             0      0          0         0       0          0          0   \n",
      "...         ...    ...        ...       ...     ...        ...        ...   \n",
      "2495          0      0          0         0       0          0          0   \n",
      "2496          0      0          0         0       0          0          0   \n",
      "2497          0      0          0         0       0          0          0   \n",
      "2498          0      0          0         0       0          0          0   \n",
      "2499          0      0          0         0       0          0          0   \n",
      "\n",
      "      desire  ...  love  nervousness  optimism  pride  realization  relief  \\\n",
      "0          0  ...     0            0         0      0            0       0   \n",
      "1          0  ...     0            0         0      0            0       0   \n",
      "2          0  ...     0            0         0      0            0       0   \n",
      "3          0  ...     0            0         0      0            0       0   \n",
      "4          0  ...     0            0         1      0            0       0   \n",
      "...      ...  ...   ...          ...       ...    ...          ...     ...   \n",
      "2495       0  ...     0            0         1      0            0       0   \n",
      "2496       0  ...     0            0         0      0            0       0   \n",
      "2497       0  ...     0            0         0      0            0       0   \n",
      "2498       0  ...     0            0         0      0            0       0   \n",
      "2499       0  ...     0            0         0      0            1       0   \n",
      "\n",
      "      remorse  sadness  surprise  neutral  \n",
      "0           0        0         0        1  \n",
      "1           0        0         0        1  \n",
      "2           0        1         0        0  \n",
      "3           0        0         0        1  \n",
      "4           0        0         0        0  \n",
      "...       ...      ...       ...      ...  \n",
      "2495        0        0         0        0  \n",
      "2496        0        0         0        0  \n",
      "2497        0        0         0        0  \n",
      "2498        0        0         0        0  \n",
      "2499        0        0         0        0  \n",
      "\n",
      "[2500 rows x 29 columns]\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2412\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3321\n",
      "Recall (Micro): 0.2985\n",
      "F1-Score (Micro): 0.3144\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3684\n",
      "Recall (Macro): 0.3475\n",
      "F1-Score (Macro): 0.3202\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.7429, Recall: 0.2281, F1-Score: 0.3490\n",
      "amusement - Precision: 0.3392, Recall: 0.6554, F1-Score: 0.4470\n",
      "anger - Precision: 0.2892, Recall: 0.6556, F1-Score: 0.4014\n",
      "annoyance - Precision: 0.1860, Recall: 0.1143, F1-Score: 0.1416\n",
      "approval - Precision: 0.2308, Recall: 0.1214, F1-Score: 0.1591\n",
      "caring - Precision: 0.2553, Recall: 0.3692, F1-Score: 0.3019\n",
      "confusion - Precision: 0.1574, Recall: 0.5000, F1-Score: 0.2394\n",
      "curiosity - Precision: 0.2532, Recall: 0.3478, F1-Score: 0.2930\n",
      "desire - Precision: 0.4688, Recall: 0.4412, F1-Score: 0.4545\n",
      "disappointment - Precision: 0.1439, Recall: 0.2405, F1-Score: 0.1801\n",
      "disapproval - Precision: 0.1864, Recall: 0.3741, F1-Score: 0.2488\n",
      "disgust - Precision: 0.3462, Recall: 0.3529, F1-Score: 0.3495\n",
      "embarrassment - Precision: 0.5000, Recall: 0.4000, F1-Score: 0.4444\n",
      "excitement - Precision: 0.2571, Recall: 0.2195, F1-Score: 0.2368\n",
      "fear - Precision: 0.3860, Recall: 0.5116, F1-Score: 0.4400\n",
      "gratitude - Precision: 0.9275, Recall: 0.3855, F1-Score: 0.5447\n",
      "grief - Precision: 0.4167, Recall: 0.5556, F1-Score: 0.4762\n",
      "joy - Precision: 0.2206, Recall: 0.4839, F1-Score: 0.3030\n",
      "love - Precision: 0.7937, Recall: 0.4630, F1-Score: 0.5848\n",
      "nervousness - Precision: 0.3333, Recall: 0.2727, F1-Score: 0.3000\n",
      "optimism - Precision: 0.4198, Recall: 0.3238, F1-Score: 0.3656\n",
      "pride - Precision: 0.3846, Recall: 0.5000, F1-Score: 0.4348\n",
      "realization - Precision: 0.3889, Recall: 0.1094, F1-Score: 0.1707\n",
      "relief - Precision: 0.0476, Recall: 0.1429, F1-Score: 0.0714\n",
      "remorse - Precision: 0.3333, Recall: 0.0263, F1-Score: 0.0488\n",
      "sadness - Precision: 0.3297, Recall: 0.4545, F1-Score: 0.3822\n",
      "surprise - Precision: 0.3519, Recall: 0.3115, F1-Score: 0.3304\n",
      "neutral - Precision: 0.6262, Recall: 0.1701, F1-Score: 0.2675\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1972\n",
      "Recall (Macro) 표준편차: 0.1639\n",
      "F1-Score (Macro) 표준편차: 0.1329\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4528\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5312\n",
      "Recall (Micro): 0.5005\n",
      "F1-Score (Micro): 0.5154\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4659\n",
      "Recall (Macro): 0.4917\n",
      "F1-Score (Macro): 0.4514\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3777, Recall: 0.6210, F1-Score: 0.4697\n",
      "disgust - Precision: 0.3462, Recall: 0.3529, F1-Score: 0.3495\n",
      "fear - Precision: 0.4308, Recall: 0.5283, F1-Score: 0.4746\n",
      "joy - Precision: 0.7168, Recall: 0.6995, F1-Score: 0.7081\n",
      "sadness - Precision: 0.3920, Recall: 0.5104, F1-Score: 0.4434\n",
      "surprise - Precision: 0.3719, Recall: 0.5597, F1-Score: 0.4469\n",
      "neutral - Precision: 0.6262, Recall: 0.1701, F1-Score: 0.2675\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1343\n",
      "Recall (Macro) 표준편차: 0.1643\n",
      "F1-Score (Macro) 표준편차: 0.1260\n",
      "------------------------16-(0.25, 0.75)------------------------\n",
      "                                                   text  admiration  \\\n",
      "0     Is this in New Orleans?? I really feel like th...           0   \n",
      "1     You know the answer man, you are programmed to...           0   \n",
      "2                  I've never been this sad in my life!           0   \n",
      "3     The economy is heavily controlled and subsidiz...           0   \n",
      "4     He could have easily taken a real camera from ...           0   \n",
      "...                                                 ...         ...   \n",
      "2495                    You got this, good luck brother           0   \n",
      "2496                        You smile warmly at people.           1   \n",
      "2497  yuck, I'd be embarrassed to walk around with a...           0   \n",
      "2498  Ok then youre leaving the enmey widow uncontes...           1   \n",
      "2499  Oh, also forgot to add, LOTION! ALWAYS lotion ...           0   \n",
      "\n",
      "      amusement  anger  annoyance  approval  caring  confusion  curiosity  \\\n",
      "0             0      0          0         0       0          0          0   \n",
      "1             0      0          0         1       0          0          0   \n",
      "2             0      0          0         0       0          0          0   \n",
      "3             0      0          0         1       0          0          0   \n",
      "4             0      0          0         0       0          0          0   \n",
      "...         ...    ...        ...       ...     ...        ...        ...   \n",
      "2495          0      0          0         0       0          0          0   \n",
      "2496          0      0          0         0       0          0          0   \n",
      "2497          0      0          0         0       0          0          0   \n",
      "2498          0      0          0         0       0          0          0   \n",
      "2499          0      0          0         0       0          0          0   \n",
      "\n",
      "      desire  ...  love  nervousness  optimism  pride  realization  relief  \\\n",
      "0          0  ...     0            0         0      0            0       0   \n",
      "1          0  ...     0            0         0      0            0       0   \n",
      "2          0  ...     0            0         0      0            0       0   \n",
      "3          0  ...     0            0         0      0            0       0   \n",
      "4          0  ...     0            0         1      0            0       0   \n",
      "...      ...  ...   ...          ...       ...    ...          ...     ...   \n",
      "2495       0  ...     0            0         1      0            0       0   \n",
      "2496       0  ...     0            0         0      0            0       0   \n",
      "2497       0  ...     0            0         0      0            0       0   \n",
      "2498       0  ...     0            0         0      0            0       0   \n",
      "2499       0  ...     0            0         0      0            1       0   \n",
      "\n",
      "      remorse  sadness  surprise  neutral  \n",
      "0           0        0         0        1  \n",
      "1           0        0         0        1  \n",
      "2           0        1         0        0  \n",
      "3           0        0         0        1  \n",
      "4           0        0         0        0  \n",
      "...       ...      ...       ...      ...  \n",
      "2495        0        0         0        0  \n",
      "2496        0        0         0        0  \n",
      "2497        0        0         0        0  \n",
      "2498        0        0         0        0  \n",
      "2499        0        0         0        0  \n",
      "\n",
      "[2500 rows x 29 columns]\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2472\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3378\n",
      "Recall (Micro): 0.2971\n",
      "F1-Score (Micro): 0.3162\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3783\n",
      "Recall (Macro): 0.3402\n",
      "F1-Score (Macro): 0.3157\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.7778, Recall: 0.2149, F1-Score: 0.3368\n",
      "amusement - Precision: 0.3493, Recall: 0.6419, F1-Score: 0.4524\n",
      "anger - Precision: 0.2844, Recall: 0.6667, F1-Score: 0.3987\n",
      "annoyance - Precision: 0.2154, Recall: 0.1000, F1-Score: 0.1366\n",
      "approval - Precision: 0.2609, Recall: 0.1387, F1-Score: 0.1811\n",
      "caring - Precision: 0.2907, Recall: 0.3846, F1-Score: 0.3311\n",
      "confusion - Precision: 0.1660, Recall: 0.5735, F1-Score: 0.2574\n",
      "curiosity - Precision: 0.2745, Recall: 0.3652, F1-Score: 0.3134\n",
      "desire - Precision: 0.5333, Recall: 0.4706, F1-Score: 0.5000\n",
      "disappointment - Precision: 0.1667, Recall: 0.2405, F1-Score: 0.1969\n",
      "disapproval - Precision: 0.1922, Recall: 0.3885, F1-Score: 0.2571\n",
      "disgust - Precision: 0.3469, Recall: 0.3333, F1-Score: 0.3400\n",
      "embarrassment - Precision: 0.4000, Recall: 0.2667, F1-Score: 0.3200\n",
      "excitement - Precision: 0.3333, Recall: 0.1951, F1-Score: 0.2462\n",
      "fear - Precision: 0.3929, Recall: 0.5116, F1-Score: 0.4444\n",
      "gratitude - Precision: 0.8750, Recall: 0.3373, F1-Score: 0.4870\n",
      "grief - Precision: 0.2857, Recall: 0.4444, F1-Score: 0.3478\n",
      "joy - Precision: 0.2153, Recall: 0.4839, F1-Score: 0.2980\n",
      "love - Precision: 0.7869, Recall: 0.4444, F1-Score: 0.5680\n",
      "nervousness - Precision: 0.5000, Recall: 0.2727, F1-Score: 0.3529\n",
      "optimism - Precision: 0.4205, Recall: 0.3524, F1-Score: 0.3834\n",
      "pride - Precision: 0.3846, Recall: 0.5000, F1-Score: 0.4348\n",
      "realization - Precision: 0.2692, Recall: 0.1094, F1-Score: 0.1556\n",
      "relief - Precision: 0.0476, Recall: 0.1429, F1-Score: 0.0714\n",
      "remorse - Precision: 0.5000, Recall: 0.0263, F1-Score: 0.0500\n",
      "sadness - Precision: 0.3333, Recall: 0.4545, F1-Score: 0.3846\n",
      "surprise - Precision: 0.3600, Recall: 0.2951, F1-Score: 0.3243\n",
      "neutral - Precision: 0.6308, Recall: 0.1713, F1-Score: 0.2695\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1935\n",
      "Recall (Macro) 표준편차: 0.1648\n",
      "F1-Score (Macro) 표준편차: 0.1240\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4640\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5400\n",
      "Recall (Micro): 0.5024\n",
      "F1-Score (Micro): 0.5205\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4765\n",
      "Recall (Macro): 0.4922\n",
      "F1-Score (Macro): 0.4570\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3788, Recall: 0.6152, F1-Score: 0.4689\n",
      "disgust - Precision: 0.3469, Recall: 0.3333, F1-Score: 0.3400\n",
      "fear - Precision: 0.4516, Recall: 0.5283, F1-Score: 0.4870\n",
      "joy - Precision: 0.7290, Recall: 0.6966, F1-Score: 0.7125\n",
      "sadness - Precision: 0.4174, Recall: 0.5000, F1-Score: 0.4550\n",
      "surprise - Precision: 0.3810, Recall: 0.6007, F1-Score: 0.4662\n",
      "neutral - Precision: 0.6308, Recall: 0.1713, F1-Score: 0.2695\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1348\n",
      "Recall (Macro) 표준편차: 0.1683\n",
      "F1-Score (Macro) 표준편차: 0.1283\n",
      "------------------------16-(0.0, 0.25)------------------------\n",
      "                                                   text  admiration  \\\n",
      "0     Is this in New Orleans?? I really feel like th...           0   \n",
      "1     You know the answer man, you are programmed to...           0   \n",
      "2                  I've never been this sad in my life!           0   \n",
      "3     The economy is heavily controlled and subsidiz...           0   \n",
      "4     He could have easily taken a real camera from ...           0   \n",
      "...                                                 ...         ...   \n",
      "2495                    You got this, good luck brother           0   \n",
      "2496                        You smile warmly at people.           1   \n",
      "2497  yuck, I'd be embarrassed to walk around with a...           0   \n",
      "2498  Ok then youre leaving the enmey widow uncontes...           1   \n",
      "2499  Oh, also forgot to add, LOTION! ALWAYS lotion ...           0   \n",
      "\n",
      "      amusement  anger  annoyance  approval  caring  confusion  curiosity  \\\n",
      "0             0      0          0         0       0          0          0   \n",
      "1             0      0          0         1       0          0          0   \n",
      "2             0      0          0         0       0          0          0   \n",
      "3             0      0          0         1       0          0          0   \n",
      "4             0      0          0         0       0          0          0   \n",
      "...         ...    ...        ...       ...     ...        ...        ...   \n",
      "2495          0      0          0         0       0          0          0   \n",
      "2496          0      0          0         0       0          0          0   \n",
      "2497          0      0          0         0       0          0          0   \n",
      "2498          0      0          0         0       0          0          0   \n",
      "2499          0      0          0         0       0          0          0   \n",
      "\n",
      "      desire  ...  love  nervousness  optimism  pride  realization  relief  \\\n",
      "0          0  ...     0            0         0      0            0       0   \n",
      "1          0  ...     0            0         0      0            0       0   \n",
      "2          0  ...     0            0         0      0            0       0   \n",
      "3          0  ...     0            0         0      0            0       0   \n",
      "4          0  ...     0            0         1      0            0       0   \n",
      "...      ...  ...   ...          ...       ...    ...          ...     ...   \n",
      "2495       0  ...     0            0         1      0            0       0   \n",
      "2496       0  ...     0            0         0      0            0       0   \n",
      "2497       0  ...     0            0         0      0            0       0   \n",
      "2498       0  ...     0            0         0      0            0       0   \n",
      "2499       0  ...     0            0         0      0            1       0   \n",
      "\n",
      "      remorse  sadness  surprise  neutral  \n",
      "0           0        0         0        1  \n",
      "1           0        0         0        1  \n",
      "2           0        1         0        0  \n",
      "3           0        0         0        1  \n",
      "4           0        0         0        0  \n",
      "...       ...      ...       ...      ...  \n",
      "2495        0        0         0        0  \n",
      "2496        0        0         0        0  \n",
      "2497        0        0         0        0  \n",
      "2498        0        0         0        0  \n",
      "2499        0        0         0        0  \n",
      "\n",
      "[2500 rows x 29 columns]\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2436\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3326\n",
      "Recall (Micro): 0.2924\n",
      "F1-Score (Micro): 0.3112\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3873\n",
      "Recall (Macro): 0.3421\n",
      "F1-Score (Macro): 0.3193\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.7188, Recall: 0.2018, F1-Score: 0.3151\n",
      "amusement - Precision: 0.3540, Recall: 0.6554, F1-Score: 0.4597\n",
      "anger - Precision: 0.2850, Recall: 0.6778, F1-Score: 0.4013\n",
      "annoyance - Precision: 0.1875, Recall: 0.0857, F1-Score: 0.1176\n",
      "approval - Precision: 0.2527, Recall: 0.1329, F1-Score: 0.1742\n",
      "caring - Precision: 0.2841, Recall: 0.3846, F1-Score: 0.3268\n",
      "confusion - Precision: 0.1602, Recall: 0.5441, F1-Score: 0.2475\n",
      "curiosity - Precision: 0.2692, Recall: 0.3652, F1-Score: 0.3100\n",
      "desire - Precision: 0.5714, Recall: 0.4706, F1-Score: 0.5161\n",
      "disappointment - Precision: 0.1500, Recall: 0.2278, F1-Score: 0.1809\n",
      "disapproval - Precision: 0.1792, Recall: 0.3597, F1-Score: 0.2392\n",
      "disgust - Precision: 0.3878, Recall: 0.3725, F1-Score: 0.3800\n",
      "embarrassment - Precision: 0.4545, Recall: 0.3333, F1-Score: 0.3846\n",
      "excitement - Precision: 0.3200, Recall: 0.1951, F1-Score: 0.2424\n",
      "fear - Precision: 0.4000, Recall: 0.5116, F1-Score: 0.4490\n",
      "gratitude - Precision: 0.8889, Recall: 0.3373, F1-Score: 0.4891\n",
      "grief - Precision: 0.3077, Recall: 0.4444, F1-Score: 0.3636\n",
      "joy - Precision: 0.2095, Recall: 0.4731, F1-Score: 0.2904\n",
      "love - Precision: 0.7797, Recall: 0.4259, F1-Score: 0.5509\n",
      "nervousness - Precision: 0.5000, Recall: 0.2727, F1-Score: 0.3529\n",
      "optimism - Precision: 0.4270, Recall: 0.3619, F1-Score: 0.3918\n",
      "pride - Precision: 0.3846, Recall: 0.5000, F1-Score: 0.4348\n",
      "realization - Precision: 0.2500, Recall: 0.0938, F1-Score: 0.1364\n",
      "relief - Precision: 0.0435, Recall: 0.1429, F1-Score: 0.0667\n",
      "remorse - Precision: 0.7500, Recall: 0.0789, F1-Score: 0.1429\n",
      "sadness - Precision: 0.3297, Recall: 0.4545, F1-Score: 0.3822\n",
      "surprise - Precision: 0.3654, Recall: 0.3115, F1-Score: 0.3363\n",
      "neutral - Precision: 0.6337, Recall: 0.1624, F1-Score: 0.2586\n",
      "\n",
      "Precision (Macro) 표준편차: 0.2061\n",
      "Recall (Macro) 표준편차: 0.1632\n",
      "F1-Score (Macro) 표준편차: 0.1239\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4600\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5357\n",
      "Recall (Micro): 0.4987\n",
      "F1-Score (Micro): 0.5165\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4795\n",
      "Recall (Macro): 0.4937\n",
      "F1-Score (Macro): 0.4582\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3698, Recall: 0.6006, F1-Score: 0.4578\n",
      "disgust - Precision: 0.3878, Recall: 0.3725, F1-Score: 0.3800\n",
      "fear - Precision: 0.4590, Recall: 0.5283, F1-Score: 0.4912\n",
      "joy - Precision: 0.7262, Recall: 0.6995, F1-Score: 0.7126\n",
      "sadness - Precision: 0.4059, Recall: 0.5052, F1-Score: 0.4501\n",
      "surprise - Precision: 0.3739, Recall: 0.5870, F1-Score: 0.4568\n",
      "neutral - Precision: 0.6337, Recall: 0.1624, F1-Score: 0.2586\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1320\n",
      "Recall (Macro) 표준편차: 0.1640\n",
      "F1-Score (Macro) 표준편차: 0.1264\n",
      "------------------------16-(0.5, 1.0)------------------------\n",
      "                                                   text  admiration  \\\n",
      "0     Is this in New Orleans?? I really feel like th...           0   \n",
      "1     You know the answer man, you are programmed to...           0   \n",
      "2                  I've never been this sad in my life!           0   \n",
      "3     The economy is heavily controlled and subsidiz...           0   \n",
      "4     He could have easily taken a real camera from ...           0   \n",
      "...                                                 ...         ...   \n",
      "2495                    You got this, good luck brother           0   \n",
      "2496                        You smile warmly at people.           1   \n",
      "2497  yuck, I'd be embarrassed to walk around with a...           0   \n",
      "2498  Ok then youre leaving the enmey widow uncontes...           1   \n",
      "2499  Oh, also forgot to add, LOTION! ALWAYS lotion ...           0   \n",
      "\n",
      "      amusement  anger  annoyance  approval  caring  confusion  curiosity  \\\n",
      "0             0      0          0         0       0          0          0   \n",
      "1             0      0          0         1       0          0          0   \n",
      "2             0      0          0         0       0          0          0   \n",
      "3             0      0          0         1       0          0          0   \n",
      "4             0      0          0         0       0          0          0   \n",
      "...         ...    ...        ...       ...     ...        ...        ...   \n",
      "2495          0      0          0         0       0          0          0   \n",
      "2496          0      0          0         0       0          0          0   \n",
      "2497          0      0          0         0       0          0          0   \n",
      "2498          0      0          0         0       0          0          0   \n",
      "2499          0      0          0         0       0          0          0   \n",
      "\n",
      "      desire  ...  love  nervousness  optimism  pride  realization  relief  \\\n",
      "0          0  ...     0            0         0      0            0       0   \n",
      "1          0  ...     0            0         0      0            0       0   \n",
      "2          0  ...     0            0         0      0            0       0   \n",
      "3          0  ...     0            0         0      0            0       0   \n",
      "4          0  ...     0            0         1      0            0       0   \n",
      "...      ...  ...   ...          ...       ...    ...          ...     ...   \n",
      "2495       0  ...     0            0         1      0            0       0   \n",
      "2496       0  ...     0            0         0      0            0       0   \n",
      "2497       0  ...     0            0         0      0            0       0   \n",
      "2498       0  ...     0            0         0      0            0       0   \n",
      "2499       0  ...     0            0         0      0            1       0   \n",
      "\n",
      "      remorse  sadness  surprise  neutral  \n",
      "0           0        0         0        1  \n",
      "1           0        0         0        1  \n",
      "2           0        1         0        0  \n",
      "3           0        0         0        1  \n",
      "4           0        0         0        0  \n",
      "...       ...      ...       ...      ...  \n",
      "2495        0        0         0        0  \n",
      "2496        0        0         0        0  \n",
      "2497        0        0         0        0  \n",
      "2498        0        0         0        0  \n",
      "2499        0        0         0        0  \n",
      "\n",
      "[2500 rows x 29 columns]\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2468\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3354\n",
      "Recall (Micro): 0.2951\n",
      "F1-Score (Micro): 0.3140\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3875\n",
      "Recall (Macro): 0.3402\n",
      "F1-Score (Macro): 0.3174\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.7385, Recall: 0.2105, F1-Score: 0.3276\n",
      "amusement - Precision: 0.3478, Recall: 0.6486, F1-Score: 0.4528\n",
      "anger - Precision: 0.2670, Recall: 0.6556, F1-Score: 0.3794\n",
      "annoyance - Precision: 0.2273, Recall: 0.1071, F1-Score: 0.1456\n",
      "approval - Precision: 0.2360, Recall: 0.1214, F1-Score: 0.1603\n",
      "caring - Precision: 0.2826, Recall: 0.4000, F1-Score: 0.3312\n",
      "confusion - Precision: 0.1586, Recall: 0.5294, F1-Score: 0.2441\n",
      "curiosity - Precision: 0.2548, Recall: 0.3478, F1-Score: 0.2941\n",
      "desire - Precision: 0.5517, Recall: 0.4706, F1-Score: 0.5079\n",
      "disappointment - Precision: 0.1607, Recall: 0.2278, F1-Score: 0.1885\n",
      "disapproval - Precision: 0.1861, Recall: 0.3669, F1-Score: 0.2470\n",
      "disgust - Precision: 0.4000, Recall: 0.3922, F1-Score: 0.3960\n",
      "embarrassment - Precision: 0.4444, Recall: 0.2667, F1-Score: 0.3333\n",
      "excitement - Precision: 0.2800, Recall: 0.1707, F1-Score: 0.2121\n",
      "fear - Precision: 0.4000, Recall: 0.5116, F1-Score: 0.4490\n",
      "gratitude - Precision: 0.9206, Recall: 0.3494, F1-Score: 0.5066\n",
      "grief - Precision: 0.2500, Recall: 0.4444, F1-Score: 0.3200\n",
      "joy - Precision: 0.2233, Recall: 0.4946, F1-Score: 0.3077\n",
      "love - Precision: 0.7903, Recall: 0.4537, F1-Score: 0.5765\n",
      "nervousness - Precision: 0.6000, Recall: 0.2727, F1-Score: 0.3750\n",
      "optimism - Precision: 0.4045, Recall: 0.3429, F1-Score: 0.3711\n",
      "pride - Precision: 0.3846, Recall: 0.5000, F1-Score: 0.4348\n",
      "realization - Precision: 0.2593, Recall: 0.1094, F1-Score: 0.1538\n",
      "relief - Precision: 0.0476, Recall: 0.1429, F1-Score: 0.0714\n",
      "remorse - Precision: 0.6667, Recall: 0.0526, F1-Score: 0.0976\n",
      "sadness - Precision: 0.3258, Recall: 0.4394, F1-Score: 0.3742\n",
      "surprise - Precision: 0.4082, Recall: 0.3279, F1-Score: 0.3636\n",
      "neutral - Precision: 0.6333, Recall: 0.1688, F1-Score: 0.2665\n",
      "\n",
      "Precision (Macro) 표준편차: 0.2083\n",
      "Recall (Macro) 표준편차: 0.1628\n",
      "F1-Score (Macro) 표준편차: 0.1256\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4648\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5415\n",
      "Recall (Micro): 0.5042\n",
      "F1-Score (Micro): 0.5222\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4855\n",
      "Recall (Macro): 0.4992\n",
      "F1-Score (Macro): 0.4649\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3786, Recall: 0.6181, F1-Score: 0.4695\n",
      "disgust - Precision: 0.4000, Recall: 0.3922, F1-Score: 0.3960\n",
      "fear - Precision: 0.4667, Recall: 0.5283, F1-Score: 0.4956\n",
      "joy - Precision: 0.7287, Recall: 0.7034, F1-Score: 0.7158\n",
      "sadness - Precision: 0.4105, Recall: 0.4896, F1-Score: 0.4466\n",
      "surprise - Precision: 0.3807, Recall: 0.5939, F1-Score: 0.4640\n",
      "neutral - Precision: 0.6333, Recall: 0.1688, F1-Score: 0.2665\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1291\n",
      "Recall (Macro) 표준편차: 0.1632\n",
      "F1-Score (Macro) 표준편차: 0.1244\n",
      "------------------------20-(0.25, 0.75)------------------------\n",
      "                                                   text  admiration  \\\n",
      "0     Is this in New Orleans?? I really feel like th...           0   \n",
      "1     You know the answer man, you are programmed to...           0   \n",
      "2                  I've never been this sad in my life!           0   \n",
      "3     The economy is heavily controlled and subsidiz...           0   \n",
      "4     He could have easily taken a real camera from ...           0   \n",
      "...                                                 ...         ...   \n",
      "2495                    You got this, good luck brother           0   \n",
      "2496                        You smile warmly at people.           1   \n",
      "2497  yuck, I'd be embarrassed to walk around with a...           0   \n",
      "2498  Ok then youre leaving the enmey widow uncontes...           1   \n",
      "2499  Oh, also forgot to add, LOTION! ALWAYS lotion ...           0   \n",
      "\n",
      "      amusement  anger  annoyance  approval  caring  confusion  curiosity  \\\n",
      "0             0      0          0         0       0          0          0   \n",
      "1             0      0          0         1       0          0          0   \n",
      "2             0      0          0         0       0          0          0   \n",
      "3             0      0          0         1       0          0          0   \n",
      "4             0      0          0         0       0          0          0   \n",
      "...         ...    ...        ...       ...     ...        ...        ...   \n",
      "2495          0      0          0         0       0          0          0   \n",
      "2496          0      0          0         0       0          0          0   \n",
      "2497          0      0          0         0       0          0          0   \n",
      "2498          0      0          0         0       0          0          0   \n",
      "2499          0      0          0         0       0          0          0   \n",
      "\n",
      "      desire  ...  love  nervousness  optimism  pride  realization  relief  \\\n",
      "0          0  ...     0            0         0      0            0       0   \n",
      "1          0  ...     0            0         0      0            0       0   \n",
      "2          0  ...     0            0         0      0            0       0   \n",
      "3          0  ...     0            0         0      0            0       0   \n",
      "4          0  ...     0            0         1      0            0       0   \n",
      "...      ...  ...   ...          ...       ...    ...          ...     ...   \n",
      "2495       0  ...     0            0         1      0            0       0   \n",
      "2496       0  ...     0            0         0      0            0       0   \n",
      "2497       0  ...     0            0         0      0            0       0   \n",
      "2498       0  ...     0            0         0      0            0       0   \n",
      "2499       0  ...     0            0         0      0            1       0   \n",
      "\n",
      "      remorse  sadness  surprise  neutral  \n",
      "0           0        0         0        1  \n",
      "1           0        0         0        1  \n",
      "2           0        1         0        0  \n",
      "3           0        0         0        1  \n",
      "4           0        0         0        0  \n",
      "...       ...      ...       ...      ...  \n",
      "2495        0        0         0        0  \n",
      "2496        0        0         0        0  \n",
      "2497        0        0         0        0  \n",
      "2498        0        0         0        0  \n",
      "2499        0        0         0        0  \n",
      "\n",
      "[2500 rows x 29 columns]\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2520\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3392\n",
      "Recall (Micro): 0.2992\n",
      "F1-Score (Micro): 0.3179\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3684\n",
      "Recall (Macro): 0.3386\n",
      "F1-Score (Macro): 0.3139\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.7500, Recall: 0.1974, F1-Score: 0.3125\n",
      "amusement - Precision: 0.3404, Recall: 0.6486, F1-Score: 0.4465\n",
      "anger - Precision: 0.2561, Recall: 0.7000, F1-Score: 0.3750\n",
      "annoyance - Precision: 0.1918, Recall: 0.1000, F1-Score: 0.1315\n",
      "approval - Precision: 0.2750, Recall: 0.1272, F1-Score: 0.1739\n",
      "caring - Precision: 0.2889, Recall: 0.4000, F1-Score: 0.3355\n",
      "confusion - Precision: 0.1739, Recall: 0.5294, F1-Score: 0.2618\n",
      "curiosity - Precision: 0.2778, Recall: 0.3478, F1-Score: 0.3089\n",
      "desire - Precision: 0.4828, Recall: 0.4118, F1-Score: 0.4444\n",
      "disappointment - Precision: 0.1509, Recall: 0.2025, F1-Score: 0.1730\n",
      "disapproval - Precision: 0.2016, Recall: 0.3525, F1-Score: 0.2565\n",
      "disgust - Precision: 0.3585, Recall: 0.3725, F1-Score: 0.3654\n",
      "embarrassment - Precision: 0.4000, Recall: 0.2667, F1-Score: 0.3200\n",
      "excitement - Precision: 0.2581, Recall: 0.1951, F1-Score: 0.2222\n",
      "fear - Precision: 0.3684, Recall: 0.4884, F1-Score: 0.4200\n",
      "gratitude - Precision: 0.8788, Recall: 0.3494, F1-Score: 0.5000\n",
      "grief - Precision: 0.3846, Recall: 0.5556, F1-Score: 0.4545\n",
      "joy - Precision: 0.2110, Recall: 0.4946, F1-Score: 0.2958\n",
      "love - Precision: 0.7895, Recall: 0.4167, F1-Score: 0.5455\n",
      "nervousness - Precision: 0.4286, Recall: 0.2727, F1-Score: 0.3333\n",
      "optimism - Precision: 0.4368, Recall: 0.3619, F1-Score: 0.3958\n",
      "pride - Precision: 0.4545, Recall: 0.5000, F1-Score: 0.4762\n",
      "realization - Precision: 0.2800, Recall: 0.1094, F1-Score: 0.1573\n",
      "relief - Precision: 0.0476, Recall: 0.1429, F1-Score: 0.0714\n",
      "remorse - Precision: 0.3333, Recall: 0.0263, F1-Score: 0.0488\n",
      "sadness - Precision: 0.3232, Recall: 0.4848, F1-Score: 0.3879\n",
      "surprise - Precision: 0.3415, Recall: 0.2295, F1-Score: 0.2745\n",
      "neutral - Precision: 0.6316, Recall: 0.1980, F1-Score: 0.3014\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1904\n",
      "Recall (Macro) 표준편차: 0.1703\n",
      "F1-Score (Macro) 표준편차: 0.1257\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4668\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5410\n",
      "Recall (Micro): 0.5049\n",
      "F1-Score (Micro): 0.5223\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4727\n",
      "Recall (Macro): 0.4903\n",
      "F1-Score (Macro): 0.4582\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3732, Recall: 0.6093, F1-Score: 0.4629\n",
      "disgust - Precision: 0.3585, Recall: 0.3725, F1-Score: 0.3654\n",
      "fear - Precision: 0.4219, Recall: 0.5094, F1-Score: 0.4615\n",
      "joy - Precision: 0.7228, Recall: 0.7005, F1-Score: 0.7115\n",
      "sadness - Precision: 0.4156, Recall: 0.5000, F1-Score: 0.4539\n",
      "surprise - Precision: 0.3850, Recall: 0.5427, F1-Score: 0.4504\n",
      "neutral - Precision: 0.6316, Recall: 0.1980, F1-Score: 0.3014\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1332\n",
      "Recall (Macro) 표준편차: 0.1516\n",
      "F1-Score (Macro) 표준편차: 0.1180\n",
      "------------------------20-(0.0, 0.25)------------------------\n",
      "                                                   text  admiration  \\\n",
      "0     Is this in New Orleans?? I really feel like th...           0   \n",
      "1     You know the answer man, you are programmed to...           0   \n",
      "2                  I've never been this sad in my life!           0   \n",
      "3     The economy is heavily controlled and subsidiz...           0   \n",
      "4     He could have easily taken a real camera from ...           0   \n",
      "...                                                 ...         ...   \n",
      "2495                    You got this, good luck brother           0   \n",
      "2496                        You smile warmly at people.           1   \n",
      "2497  yuck, I'd be embarrassed to walk around with a...           0   \n",
      "2498  Ok then youre leaving the enmey widow uncontes...           1   \n",
      "2499  Oh, also forgot to add, LOTION! ALWAYS lotion ...           0   \n",
      "\n",
      "      amusement  anger  annoyance  approval  caring  confusion  curiosity  \\\n",
      "0             0      0          0         0       0          0          0   \n",
      "1             0      0          0         1       0          0          0   \n",
      "2             0      0          0         0       0          0          0   \n",
      "3             0      0          0         1       0          0          0   \n",
      "4             0      0          0         0       0          0          0   \n",
      "...         ...    ...        ...       ...     ...        ...        ...   \n",
      "2495          0      0          0         0       0          0          0   \n",
      "2496          0      0          0         0       0          0          0   \n",
      "2497          0      0          0         0       0          0          0   \n",
      "2498          0      0          0         0       0          0          0   \n",
      "2499          0      0          0         0       0          0          0   \n",
      "\n",
      "      desire  ...  love  nervousness  optimism  pride  realization  relief  \\\n",
      "0          0  ...     0            0         0      0            0       0   \n",
      "1          0  ...     0            0         0      0            0       0   \n",
      "2          0  ...     0            0         0      0            0       0   \n",
      "3          0  ...     0            0         0      0            0       0   \n",
      "4          0  ...     0            0         1      0            0       0   \n",
      "...      ...  ...   ...          ...       ...    ...          ...     ...   \n",
      "2495       0  ...     0            0         1      0            0       0   \n",
      "2496       0  ...     0            0         0      0            0       0   \n",
      "2497       0  ...     0            0         0      0            0       0   \n",
      "2498       0  ...     0            0         0      0            0       0   \n",
      "2499       0  ...     0            0         0      0            1       0   \n",
      "\n",
      "      remorse  sadness  surprise  neutral  \n",
      "0           0        0         0        1  \n",
      "1           0        0         0        1  \n",
      "2           0        1         0        0  \n",
      "3           0        0         0        1  \n",
      "4           0        0         0        0  \n",
      "...       ...      ...       ...      ...  \n",
      "2495        0        0         0        0  \n",
      "2496        0        0         0        0  \n",
      "2497        0        0         0        0  \n",
      "2498        0        0         0        0  \n",
      "2499        0        0         0        0  \n",
      "\n",
      "[2500 rows x 29 columns]\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2492\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3369\n",
      "Recall (Micro): 0.2968\n",
      "F1-Score (Micro): 0.3156\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3722\n",
      "Recall (Macro): 0.3371\n",
      "F1-Score (Macro): 0.3131\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.7414, Recall: 0.1886, F1-Score: 0.3007\n",
      "amusement - Precision: 0.3368, Recall: 0.6486, F1-Score: 0.4434\n",
      "anger - Precision: 0.2520, Recall: 0.6889, F1-Score: 0.3690\n",
      "annoyance - Precision: 0.2286, Recall: 0.1143, F1-Score: 0.1524\n",
      "approval - Precision: 0.2368, Recall: 0.1040, F1-Score: 0.1446\n",
      "caring - Precision: 0.2809, Recall: 0.3846, F1-Score: 0.3247\n",
      "confusion - Precision: 0.1765, Recall: 0.5294, F1-Score: 0.2647\n",
      "curiosity - Precision: 0.2603, Recall: 0.3304, F1-Score: 0.2912\n",
      "desire - Precision: 0.4688, Recall: 0.4412, F1-Score: 0.4545\n",
      "disappointment - Precision: 0.1468, Recall: 0.2025, F1-Score: 0.1702\n",
      "disapproval - Precision: 0.1984, Recall: 0.3525, F1-Score: 0.2539\n",
      "disgust - Precision: 0.3654, Recall: 0.3725, F1-Score: 0.3689\n",
      "embarrassment - Precision: 0.5000, Recall: 0.3333, F1-Score: 0.4000\n",
      "excitement - Precision: 0.2667, Recall: 0.1951, F1-Score: 0.2254\n",
      "fear - Precision: 0.3750, Recall: 0.4884, F1-Score: 0.4242\n",
      "gratitude - Precision: 0.8769, Recall: 0.3434, F1-Score: 0.4935\n",
      "grief - Precision: 0.3333, Recall: 0.4444, F1-Score: 0.3810\n",
      "joy - Precision: 0.2055, Recall: 0.4839, F1-Score: 0.2885\n",
      "love - Precision: 0.7966, Recall: 0.4352, F1-Score: 0.5629\n",
      "nervousness - Precision: 0.4286, Recall: 0.2727, F1-Score: 0.3333\n",
      "optimism - Precision: 0.4205, Recall: 0.3524, F1-Score: 0.3834\n",
      "pride - Precision: 0.3571, Recall: 0.5000, F1-Score: 0.4167\n",
      "realization - Precision: 0.2857, Recall: 0.1250, F1-Score: 0.1739\n",
      "relief - Precision: 0.0526, Recall: 0.1429, F1-Score: 0.0769\n",
      "remorse - Precision: 0.5000, Recall: 0.0526, F1-Score: 0.0952\n",
      "sadness - Precision: 0.3299, Recall: 0.4848, F1-Score: 0.3926\n",
      "surprise - Precision: 0.3590, Recall: 0.2295, F1-Score: 0.2800\n",
      "neutral - Precision: 0.6405, Recall: 0.1967, F1-Score: 0.3010\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1925\n",
      "Recall (Macro) 표준편차: 0.1637\n",
      "F1-Score (Macro) 표준편차: 0.1193\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4648\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5388\n",
      "Recall (Micro): 0.5016\n",
      "F1-Score (Micro): 0.5195\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4740\n",
      "Recall (Macro): 0.4885\n",
      "F1-Score (Macro): 0.4572\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3712, Recall: 0.6093, F1-Score: 0.4614\n",
      "disgust - Precision: 0.3654, Recall: 0.3725, F1-Score: 0.3689\n",
      "fear - Precision: 0.4286, Recall: 0.5094, F1-Score: 0.4655\n",
      "joy - Precision: 0.7194, Recall: 0.6937, F1-Score: 0.7063\n",
      "sadness - Precision: 0.4095, Recall: 0.4948, F1-Score: 0.4481\n",
      "surprise - Precision: 0.3831, Recall: 0.5427, F1-Score: 0.4492\n",
      "neutral - Precision: 0.6405, Recall: 0.1967, F1-Score: 0.3010\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1335\n",
      "Recall (Macro) 표준편차: 0.1506\n",
      "F1-Score (Macro) 표준편차: 0.1162\n",
      "------------------------20-(0.5, 1.0)------------------------\n",
      "                                                   text  admiration  \\\n",
      "0     Is this in New Orleans?? I really feel like th...           0   \n",
      "1     You know the answer man, you are programmed to...           0   \n",
      "2                  I've never been this sad in my life!           0   \n",
      "3     The economy is heavily controlled and subsidiz...           0   \n",
      "4     He could have easily taken a real camera from ...           0   \n",
      "...                                                 ...         ...   \n",
      "2495                    You got this, good luck brother           0   \n",
      "2496                        You smile warmly at people.           1   \n",
      "2497  yuck, I'd be embarrassed to walk around with a...           0   \n",
      "2498  Ok then youre leaving the enmey widow uncontes...           1   \n",
      "2499  Oh, also forgot to add, LOTION! ALWAYS lotion ...           0   \n",
      "\n",
      "      amusement  anger  annoyance  approval  caring  confusion  curiosity  \\\n",
      "0             0      0          0         0       0          0          0   \n",
      "1             0      0          0         1       0          0          0   \n",
      "2             0      0          0         0       0          0          0   \n",
      "3             0      0          0         1       0          0          0   \n",
      "4             0      0          0         0       0          0          0   \n",
      "...         ...    ...        ...       ...     ...        ...        ...   \n",
      "2495          0      0          0         0       0          0          0   \n",
      "2496          0      0          0         0       0          0          0   \n",
      "2497          0      0          0         0       0          0          0   \n",
      "2498          0      0          0         0       0          0          0   \n",
      "2499          0      0          0         0       0          0          0   \n",
      "\n",
      "      desire  ...  love  nervousness  optimism  pride  realization  relief  \\\n",
      "0          0  ...     0            0         0      0            0       0   \n",
      "1          0  ...     0            0         0      0            0       0   \n",
      "2          0  ...     0            0         0      0            0       0   \n",
      "3          0  ...     0            0         0      0            0       0   \n",
      "4          0  ...     0            0         1      0            0       0   \n",
      "...      ...  ...   ...          ...       ...    ...          ...     ...   \n",
      "2495       0  ...     0            0         1      0            0       0   \n",
      "2496       0  ...     0            0         0      0            0       0   \n",
      "2497       0  ...     0            0         0      0            0       0   \n",
      "2498       0  ...     0            0         0      0            0       0   \n",
      "2499       0  ...     0            0         0      0            1       0   \n",
      "\n",
      "      remorse  sadness  surprise  neutral  \n",
      "0           0        0         0        1  \n",
      "1           0        0         0        1  \n",
      "2           0        1         0        0  \n",
      "3           0        0         0        1  \n",
      "4           0        0         0        0  \n",
      "...       ...      ...       ...      ...  \n",
      "2495        0        0         0        0  \n",
      "2496        0        0         0        0  \n",
      "2497        0        0         0        0  \n",
      "2498        0        0         0        0  \n",
      "2499        0        0         0        0  \n",
      "\n",
      "[2500 rows x 29 columns]\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2500\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3341\n",
      "Recall (Micro): 0.2954\n",
      "F1-Score (Micro): 0.3136\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3710\n",
      "Recall (Macro): 0.3326\n",
      "F1-Score (Macro): 0.3095\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.7241, Recall: 0.1842, F1-Score: 0.2937\n",
      "amusement - Precision: 0.3443, Recall: 0.6351, F1-Score: 0.4466\n",
      "anger - Precision: 0.2520, Recall: 0.7000, F1-Score: 0.3706\n",
      "annoyance - Precision: 0.1974, Recall: 0.1071, F1-Score: 0.1389\n",
      "approval - Precision: 0.2500, Recall: 0.1156, F1-Score: 0.1581\n",
      "caring - Precision: 0.2577, Recall: 0.3846, F1-Score: 0.3086\n",
      "confusion - Precision: 0.1729, Recall: 0.5441, F1-Score: 0.2624\n",
      "curiosity - Precision: 0.2590, Recall: 0.3130, F1-Score: 0.2835\n",
      "desire - Precision: 0.4688, Recall: 0.4412, F1-Score: 0.4545\n",
      "disappointment - Precision: 0.1379, Recall: 0.2025, F1-Score: 0.1641\n",
      "disapproval - Precision: 0.2125, Recall: 0.3669, F1-Score: 0.2691\n",
      "disgust - Precision: 0.3529, Recall: 0.3529, F1-Score: 0.3529\n",
      "embarrassment - Precision: 0.4167, Recall: 0.3333, F1-Score: 0.3704\n",
      "excitement - Precision: 0.2286, Recall: 0.1951, F1-Score: 0.2105\n",
      "fear - Precision: 0.3636, Recall: 0.4651, F1-Score: 0.4082\n",
      "gratitude - Precision: 0.8939, Recall: 0.3554, F1-Score: 0.5086\n",
      "grief - Precision: 0.4000, Recall: 0.4444, F1-Score: 0.4211\n",
      "joy - Precision: 0.2140, Recall: 0.4946, F1-Score: 0.2987\n",
      "love - Precision: 0.7857, Recall: 0.4074, F1-Score: 0.5366\n",
      "nervousness - Precision: 0.5000, Recall: 0.2727, F1-Score: 0.3529\n",
      "optimism - Precision: 0.4167, Recall: 0.3333, F1-Score: 0.3704\n",
      "pride - Precision: 0.4545, Recall: 0.5000, F1-Score: 0.4762\n",
      "realization - Precision: 0.2400, Recall: 0.0938, F1-Score: 0.1348\n",
      "relief - Precision: 0.0455, Recall: 0.1429, F1-Score: 0.0690\n",
      "remorse - Precision: 0.5000, Recall: 0.0263, F1-Score: 0.0500\n",
      "sadness - Precision: 0.3232, Recall: 0.4848, F1-Score: 0.3879\n",
      "surprise - Precision: 0.3421, Recall: 0.2131, F1-Score: 0.2626\n",
      "neutral - Precision: 0.6335, Recall: 0.2018, F1-Score: 0.3061\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1954\n",
      "Recall (Macro) 표준편차: 0.1668\n",
      "F1-Score (Macro) 표준편차: 0.1265\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4644\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5383\n",
      "Recall (Micro): 0.5027\n",
      "F1-Score (Micro): 0.5199\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4693\n",
      "Recall (Macro): 0.4835\n",
      "F1-Score (Macro): 0.4533\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3752, Recall: 0.6181, F1-Score: 0.4670\n",
      "disgust - Precision: 0.3529, Recall: 0.3529, F1-Score: 0.3529\n",
      "fear - Precision: 0.4262, Recall: 0.4906, F1-Score: 0.4561\n",
      "joy - Precision: 0.7206, Recall: 0.6928, F1-Score: 0.7064\n",
      "sadness - Precision: 0.3849, Recall: 0.4792, F1-Score: 0.4269\n",
      "surprise - Precision: 0.3917, Recall: 0.5495, F1-Score: 0.4574\n",
      "neutral - Precision: 0.6335, Recall: 0.2018, F1-Score: 0.3061\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1350\n",
      "Recall (Macro) 표준편차: 0.1525\n",
      "F1-Score (Macro) 표준편차: 0.1175\n"
     ]
    }
   ],
   "source": [
    "k = 0\n",
    "result = []\n",
    "ek_result = []\n",
    "for i in range(4, 21, 4):\n",
    "    for j in it:\n",
    "        json_res = []\n",
    "        for l in batch_res[k].split('\\n')[:-1]:\n",
    "            json_res.append(json.loads(l))\n",
    "        emotion_res = []\n",
    "\n",
    "        for l in json_res:\n",
    "            tmp = []\n",
    "            n = json.loads(l['response']['body']['output'][0]['content'][0]['text'])\n",
    "        \n",
    "            for m in n['analysis']:\n",
    "                tmp.append(m['emotion'])\n",
    "        \n",
    "            emotion_res.append(tmp)\n",
    "        print(f'------------------------{i}-{j}------------------------')\n",
    "        print(data)\n",
    "        e = evaluation(data, emotion_res)\n",
    "        ek = evaluation_ekman(data, emotion_res)\n",
    "        result.append([i]+list(j)+[e[0], e[1], e[2]])\n",
    "        ek_result.append([i]+list(j)+[ek[0], ek[1], ek[2]])\n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7807a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(result, columns=['shots', 'temperature', 'top_p', 'accuracy', 'micro f1', 'macro f1'])\n",
    "ek_res_df = pd.DataFrame(ek_result, columns=['shots', 'temperature', 'top_p', 'accuracy', 'micro f1', 'macro f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c98c13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shots</th>\n",
       "      <th>temperature</th>\n",
       "      <th>top_p</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>micro f1</th>\n",
       "      <th>macro f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>0.514981</td>\n",
       "      <td>0.451085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4540</td>\n",
       "      <td>0.513741</td>\n",
       "      <td>0.454304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4468</td>\n",
       "      <td>0.508494</td>\n",
       "      <td>0.446688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.4632</td>\n",
       "      <td>0.517222</td>\n",
       "      <td>0.455611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4632</td>\n",
       "      <td>0.516956</td>\n",
       "      <td>0.454610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.513371</td>\n",
       "      <td>0.445528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.4576</td>\n",
       "      <td>0.518671</td>\n",
       "      <td>0.460754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4616</td>\n",
       "      <td>0.521414</td>\n",
       "      <td>0.461851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4528</td>\n",
       "      <td>0.515418</td>\n",
       "      <td>0.451373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.4640</td>\n",
       "      <td>0.520496</td>\n",
       "      <td>0.456994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.516541</td>\n",
       "      <td>0.458164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4648</td>\n",
       "      <td>0.522180</td>\n",
       "      <td>0.464869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.4668</td>\n",
       "      <td>0.522343</td>\n",
       "      <td>0.458154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4648</td>\n",
       "      <td>0.519549</td>\n",
       "      <td>0.457200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4644</td>\n",
       "      <td>0.519895</td>\n",
       "      <td>0.453259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    shots  temperature  top_p  accuracy  micro f1  macro f1\n",
       "0       4         0.25   0.75    0.4564  0.514981  0.451085\n",
       "1       4         0.00   0.25    0.4540  0.513741  0.454304\n",
       "2       4         0.50   1.00    0.4468  0.508494  0.446688\n",
       "3       8         0.25   0.75    0.4632  0.517222  0.455611\n",
       "4       8         0.00   0.25    0.4632  0.516956  0.454610\n",
       "5       8         0.50   1.00    0.4588  0.513371  0.445528\n",
       "6      12         0.25   0.75    0.4576  0.518671  0.460754\n",
       "7      12         0.00   0.25    0.4616  0.521414  0.461851\n",
       "8      12         0.50   1.00    0.4528  0.515418  0.451373\n",
       "9      16         0.25   0.75    0.4640  0.520496  0.456994\n",
       "10     16         0.00   0.25    0.4600  0.516541  0.458164\n",
       "11     16         0.50   1.00    0.4648  0.522180  0.464869\n",
       "12     20         0.25   0.75    0.4668  0.522343  0.458154\n",
       "13     20         0.00   0.25    0.4648  0.519549  0.457200\n",
       "14     20         0.50   1.00    0.4644  0.519895  0.453259"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ek_res_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goemotions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
