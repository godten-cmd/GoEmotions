{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "710d8ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b6bc31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ems = \"\"\"\n",
    "admiration\n",
    "amusement\n",
    "anger\n",
    "annoyance\n",
    "approval\n",
    "caring\n",
    "confusion\n",
    "curiosity\n",
    "desire\n",
    "disappointment\n",
    "disapproval\n",
    "disgust\n",
    "embarrassment\n",
    "excitement\n",
    "fear\n",
    "gratitude\n",
    "grief\n",
    "joy\n",
    "love\n",
    "nervousness\n",
    "optimism\n",
    "pride\n",
    "realization\n",
    "relief\n",
    "remorse\n",
    "sadness\n",
    "surprise\n",
    "neutral\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4a196e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotions_to_categorical(df):\n",
    "    res = []\n",
    "\n",
    "    for i in df['emotions']:\n",
    "        tmp = [0 for _ in range(28)]\n",
    "        for j in i:\n",
    "            tmp[j] = 1\n",
    "        res.append(tmp)\n",
    "    tmp_df = pd.DataFrame(res, columns=ems.split())\n",
    "    \n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "975c4f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def emotions_to_ekman(df):\n",
    "    # anger disgust fear joy sadness surprise neutral\n",
    "    ekman = [3, 3, 0, 0, 3, 3, 5, 5, 3, 4, 0, 1, 4, 3, 2, 3, 4, 3, 3, 2, 3, 3, 5, 3, 4, 4, 5, 6]\n",
    "    res = []\n",
    "\n",
    "    for i in df:\n",
    "        tmp = [0, 0, 0, 0, 0, 0, 0]\n",
    "        for j in range(len(i)):\n",
    "            if i[j] == 1:\n",
    "                tmp[ekman[j]] = 1\n",
    "        res.append(tmp)\n",
    "    tmp_df = pd.DataFrame(res, columns=['angry', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'neutral'])\n",
    "    \n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "628b9fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_init(path = \"../../data/dev.tsv\"):\n",
    "    df = pd.read_csv(path, sep=\"\\t\", encoding = \"utf-8\", header=None)\n",
    "    df.columns = ['text', 'emotions', 'id']\n",
    "    df['emotions'] = list(map(lambda s : list(map(int, s.split(','))), df['emotions']))\n",
    "    df = pd.concat([df, emotions_to_categorical(df)], axis=1)\n",
    "    df = df.drop(columns=['emotions', 'id'])\n",
    "    df['text'] = list(map(lambda s : s.replace('\\\\', '\\\\\\\\').replace('\"', '\\\\\"'), list(df['text']))) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "144fb321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(original_df, emotion_res):\n",
    "    emotions_list = ems.split()\n",
    "    df = original_df\n",
    "    predicted_df = pd.DataFrame(data = [[0 for _ in range(28)] for _ in range(len(df))], columns=emotions_list)\n",
    "    for i in range(len(emotion_res)):\n",
    "        for j in emotion_res[i]:\n",
    "            if j in emotions_list:\n",
    "                predicted_df.loc[i, j] = 1\n",
    "    predicted = predicted_df.to_numpy()\n",
    "    original = df.iloc[:,1:].to_numpy()\n",
    "    \n",
    "    \n",
    "    accuracy = accuracy_score(original, predicted)\n",
    "    \n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
    "        original, predicted, average='micro'\n",
    "    )\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        original, predicted, average='macro'\n",
    "    )\n",
    "    \n",
    "    precision_per_label, recall_per_label, f1_per_label, _ = precision_recall_fscore_support(\n",
    "        original, predicted, average=None\n",
    "    )\n",
    "\n",
    "    precision_macro_std = np.std(precision_per_label)\n",
    "    recall_macro_std = np.std(recall_per_label)\n",
    "    f1_macro_std = np.std(f1_per_label)\n",
    "\n",
    "    print(\"--- 모델 평가 결과 ---\")\n",
    "    print(f\"전체 샘플에 대한 정확도 (Exact Match Accuracy): {accuracy:.4f}\")\n",
    "    print(\"\\n--- Micro 평균 지표 ---\")\n",
    "    print(f\"Precision (Micro): {precision_micro:.4f}\")\n",
    "    print(f\"Recall (Micro): {recall_micro:.4f}\")\n",
    "    print(f\"F1-Score (Micro): {f1_micro:.4f}\")\n",
    "    print(\"\\n--- Macro 평균 지표 ---\")\n",
    "    print(f\"Precision (Macro): {precision_macro:.4f}\")\n",
    "    print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
    "    print(f\"F1-Score (Macro): {f1_macro:.4f}\")\n",
    "    \n",
    "    print(\"\\n--- 라벨별 지표 ---\")\n",
    "    for i in range(len(emotions_list)):\n",
    "        print(f\"{emotions_list[i]} - Precision: {precision_per_label[i]:.4f}, Recall: {recall_per_label[i]:.4f}, F1-Score: {f1_per_label[i]:.4f}\")\n",
    "    \n",
    "    print(f\"\\nPrecision (Macro) 표준편차: {precision_macro_std:.4f}\")\n",
    "    print(f\"Recall (Macro) 표준편차: {recall_macro_std:.4f}\")\n",
    "    print(f\"F1-Score (Macro) 표준편차: {f1_macro_std:.4f}\")\n",
    "\n",
    "    return accuracy, f1_micro, f1_macro, precision_recall_fscore_support(original, predicted, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "078a66fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_ekman(original_df, emotion_res):\n",
    "    emotions_list = 'anger disgust fear joy sadness surprise neutral'.split()\n",
    "    predicted_df = pd.DataFrame(data = [[0 for _ in range(28)] for _ in range(len(original_df))], columns=ems.split())\n",
    "    for i in range(len(emotion_res)):\n",
    "        for j in emotion_res[i]:\n",
    "            if j in ems.split():\n",
    "                predicted_df.loc[i, j] = 1\n",
    "    predicted = emotions_to_ekman(predicted_df.to_numpy()).to_numpy()\n",
    "    original = emotions_to_ekman(original_df.iloc[:,1:].to_numpy()).to_numpy()\n",
    "\n",
    "    accuracy = accuracy_score(original, predicted)\n",
    "    \n",
    "    precision_micro, recall_micro, f1_micro, _ = precision_recall_fscore_support(\n",
    "        original, predicted, average='micro'\n",
    "    )\n",
    "    precision_macro, recall_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "        original, predicted, average='macro'\n",
    "    )\n",
    "    \n",
    "    precision_per_label, recall_per_label, f1_per_label, _ = precision_recall_fscore_support(\n",
    "        original, predicted, average=None\n",
    "    )\n",
    "\n",
    "    precision_macro_std = np.std(precision_per_label)\n",
    "    recall_macro_std = np.std(recall_per_label)\n",
    "    f1_macro_std = np.std(f1_per_label)\n",
    "\n",
    "    print(\"--- 모델 평가 결과 ---\")\n",
    "    print(f\"전체 샘플에 대한 정확도 (Exact Match Accuracy): {accuracy:.4f}\")\n",
    "    print(\"\\n--- Micro 평균 지표 ---\")\n",
    "    print(f\"Precision (Micro): {precision_micro:.4f}\")\n",
    "    print(f\"Recall (Micro): {recall_micro:.4f}\")\n",
    "    print(f\"F1-Score (Micro): {f1_micro:.4f}\")\n",
    "    print(\"\\n--- Macro 평균 지표 ---\")\n",
    "    print(f\"Precision (Macro): {precision_macro:.4f}\")\n",
    "    print(f\"Recall (Macro): {recall_macro:.4f}\")\n",
    "    print(f\"F1-Score (Macro): {f1_macro:.4f}\")\n",
    "    \n",
    "    print(\"\\n--- 라벨별 지표 ---\")\n",
    "    for i in range(len(emotions_list)):\n",
    "        print(f\"{emotions_list[i]} - Precision: {precision_per_label[i]:.4f}, Recall: {recall_per_label[i]:.4f}, F1-Score: {f1_per_label[i]:.4f}\")\n",
    "    \n",
    "    print(f\"\\nPrecision (Macro) 표준편차: {precision_macro_std:.4f}\")\n",
    "    print(f\"Recall (Macro) 표준편차: {recall_macro_std:.4f}\")\n",
    "    print(f\"F1-Score (Macro) 표준편차: {f1_macro_std:.4f}\")\n",
    "\n",
    "    return accuracy, f1_micro, f1_macro, precision_recall_fscore_support(original, predicted, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "902084ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_init():\n",
    "    file_dict = {}\n",
    "    file_names = {\n",
    "        'persona': '../prompt/persona.txt',\n",
    "        'guidelines': '../prompt/guidelines.txt',\n",
    "        'output_structure': '../prompt/output_structure.txt',\n",
    "        'few_shot': '../prompt/few_shot.txt',\n",
    "        'few_shot_4': '../prompt/few_shot_4.txt',\n",
    "        'few_shot_8': '../prompt/few_shot_8.txt',\n",
    "        'few_shot_12': '../prompt/few_shot_12.txt',\n",
    "        'few_shot_16': '../prompt/few_shot_16.txt',\n",
    "        'few_shot_20': '../prompt/few_shot_20.txt',\n",
    "        'cot': '../prompt/chain_of_thought.txt',\n",
    "        'description':  '../prompt/emotion_description.txt'\n",
    "    }\n",
    "    for key, value in file_names.items():\n",
    "        file = open(value, 'r')\n",
    "        file_dict[key] = file.read()\n",
    "        file.close()\n",
    "    return file_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9153854b",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = file_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "defcfc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = f\"{files['persona']}{files['description']}{files['guidelines']}{files['output_structure']}{files['few_shot_16']}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66b36c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b90955b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"../inputs/single_test.jsonl\", \"w\") as f:\n",
    "    k = 0\n",
    "    for record in data[\"text\"]:\n",
    "        baseQuery = {\n",
    "        \"custom_id\": f\"query{k}\",\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/responses\",\n",
    "        \"body\": {\n",
    "                \"model\": \"gpt-4o-mini\",\n",
    "                \"temperature\": 0.5,\n",
    "                \"top_p\": 1.0,\n",
    "                \"input\": [{\n",
    "                    \"role\": \"developer\",\n",
    "                    \"content\": f\"{system}\"\n",
    "                }, \n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"{record}\"\n",
    "                }], \n",
    "                \"max_output_tokens\": 1000,\n",
    "                \"text\": {\n",
    "                    \"format\": {\n",
    "                        \"type\": \"json_schema\",\n",
    "                        \"name\": \"result\",\n",
    "                        \"strict\": True,\n",
    "                        \"schema\": {\n",
    "                            \"type\": \"object\",\n",
    "                            \"properties\": {\n",
    "                                \"analysis\": {\n",
    "                                    \"type\": \"array\",\n",
    "                                    \"items\": {\n",
    "                                        \"type\": \"object\",\n",
    "                                        \"properties\": {\n",
    "                                            \"emotion\": {\n",
    "                                                \"type\": \"string\",\n",
    "                                                \"enum\": [ \"admiration\", \"amusement\", \"anger\", \"annoyance\", \"approval\", \"caring\", \"confusion\", \"curiosity\", \"desire\", \"disappointment\", \"disapproval\", \"disgust\", \"embarrassment\", \"excitement\", \"fear\", \"gratitude\", \"grief\", \"joy\", \"love\", \"nervousness\", \"optimism\", \"pride\", \"realization\", \"relief\", \"remorse\", \"sadness\", \"surprise\", \"neutral\" ]\n",
    "                                            },\n",
    "                                            \"reason\": {\n",
    "                                                \"type\": \"string\"\n",
    "                                            }\n",
    "                                        },\n",
    "                                        \"required\": [\"emotion\", \"reason\"],\n",
    "                                        \"additionalProperties\": False\n",
    "                                    }\n",
    "                                }\n",
    "                            },\n",
    "                            \"required\": [\"analysis\"],\n",
    "                            \"additionalProperties\": False\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        k += 1\n",
    "        f.write(json.dumps(baseQuery) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09d73f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_file = open('../key/openai_key.txt', 'r')\n",
    "api_key = key_file.readline()\n",
    "key_file.close()\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d3cd597",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbbf8057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-WwDRN4qv4c1Y9Hc7FEXntT', bytes=55898879, created_at=1763344770, filename='single_test.jsonl', object='file', purpose='batch', status='processed', expires_at=1765936770, status_details=None)\n"
     ]
    }
   ],
   "source": [
    "batch_input_file = client.files.create(\n",
    "    file=open(f\"../inputs/single_test.jsonl\", \"rb\"),\n",
    "    purpose='batch'\n",
    ")\n",
    "print(batch_input_file)\n",
    "\n",
    "batch_input_file_id = batch_input_file.id\n",
    "create_batch=client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/responses\",\n",
    "    completion_window=\"24h\",\n",
    ")\n",
    "batch_list.append(create_batch.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6aa9aef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_691a81833ca481909d84795bed8ecaa1\n"
     ]
    }
   ],
   "source": [
    "for i in batch_list:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f348ea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_list = ['batch_691a81833ca481909d84795bed8ecaa1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f95f91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_res = [0] * len(batch_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5703c90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 done!\n",
      "1 / 1\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in range(len(batch_list)):\n",
    "    print(i, end=\" \")\n",
    "    if batch_res[i] != 0:\n",
    "        print(\"done\")\n",
    "        cnt += 1\n",
    "        continue\n",
    "    batch = client.batches.retrieve(batch_list[i])\n",
    "    result = None\n",
    "    if batch.status == 'completed':\n",
    "        out = batch.output_file_id\n",
    "        if out != None:\n",
    "            cnt += 1\n",
    "            print('done!')\n",
    "            result = client.files.content(out)\n",
    "            batch_res[i] = result\n",
    "        else:\n",
    "            print('error')\n",
    "            result = client.files.content(batch.error_file_id).text\n",
    "            batch_res[i] = result\n",
    "    elif batch.status == 'failed':\n",
    "        print('failed')\n",
    "        print(batch.errors)\n",
    "    else:\n",
    "        print('it does not finish yet')\n",
    "        print(batch.status)\n",
    "        print(batch.request_counts)\n",
    "print(cnt, \"/\", len(batch_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98100d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<openai._legacy_response.HttpxBinaryResponseContent object at 0x0000029C3908FC70>\n"
     ]
    }
   ],
   "source": [
    "print(batch_res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46a9dfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.2528\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.3307\n",
      "Recall (Micro): 0.2918\n",
      "F1-Score (Micro): 0.3101\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.3504\n",
      "Recall (Macro): 0.3394\n",
      "F1-Score (Macro): 0.2994\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "admiration - Precision: 0.6449, Recall: 0.1766, F1-Score: 0.2773\n",
      "amusement - Precision: 0.3315, Recall: 0.6742, F1-Score: 0.4444\n",
      "anger - Precision: 0.2867, Recall: 0.6212, F1-Score: 0.3923\n",
      "annoyance - Precision: 0.3133, Recall: 0.1469, F1-Score: 0.2000\n",
      "approval - Precision: 0.2273, Recall: 0.1425, F1-Score: 0.1751\n",
      "caring - Precision: 0.2849, Recall: 0.3926, F1-Score: 0.3302\n",
      "confusion - Precision: 0.1725, Recall: 0.5752, F1-Score: 0.2655\n",
      "curiosity - Precision: 0.2811, Recall: 0.3662, F1-Score: 0.3180\n",
      "desire - Precision: 0.3800, Recall: 0.2289, F1-Score: 0.2857\n",
      "disappointment - Precision: 0.1525, Recall: 0.2384, F1-Score: 0.1860\n",
      "disapproval - Precision: 0.1850, Recall: 0.4607, F1-Score: 0.2639\n",
      "disgust - Precision: 0.3596, Recall: 0.2602, F1-Score: 0.3019\n",
      "embarrassment - Precision: 0.2963, Recall: 0.2162, F1-Score: 0.2500\n",
      "excitement - Precision: 0.3250, Recall: 0.2524, F1-Score: 0.2842\n",
      "fear - Precision: 0.3689, Recall: 0.4872, F1-Score: 0.4199\n",
      "gratitude - Precision: 0.8963, Recall: 0.4176, F1-Score: 0.5698\n",
      "grief - Precision: 0.0769, Recall: 0.3333, F1-Score: 0.1250\n",
      "joy - Precision: 0.2026, Recall: 0.5714, F1-Score: 0.2992\n",
      "love - Precision: 0.8051, Recall: 0.3992, F1-Score: 0.5337\n",
      "nervousness - Precision: 0.2353, Recall: 0.1739, F1-Score: 0.2000\n",
      "optimism - Precision: 0.3496, Recall: 0.2312, F1-Score: 0.2783\n",
      "pride - Precision: 0.3000, Recall: 0.3750, F1-Score: 0.3333\n",
      "realization - Precision: 0.2727, Recall: 0.1034, F1-Score: 0.1500\n",
      "relief - Precision: 0.2059, Recall: 0.6364, F1-Score: 0.3111\n",
      "remorse - Precision: 0.4667, Recall: 0.1250, F1-Score: 0.1972\n",
      "sadness - Precision: 0.3538, Recall: 0.4423, F1-Score: 0.3932\n",
      "surprise - Precision: 0.3846, Recall: 0.2837, F1-Score: 0.3265\n",
      "neutral - Precision: 0.6511, Recall: 0.1712, F1-Score: 0.2712\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1860\n",
      "Recall (Macro) 표준편차: 0.1666\n",
      "F1-Score (Macro) 표준편차: 0.1039\n",
      "--- 모델 평가 결과 ---\n",
      "전체 샘플에 대한 정확도 (Exact Match Accuracy): 0.4605\n",
      "\n",
      "--- Micro 평균 지표 ---\n",
      "Precision (Micro): 0.5264\n",
      "Recall (Micro): 0.4930\n",
      "F1-Score (Micro): 0.5092\n",
      "\n",
      "--- Macro 평균 지표 ---\n",
      "Precision (Macro): 0.4685\n",
      "Recall (Macro): 0.4812\n",
      "F1-Score (Macro): 0.4439\n",
      "\n",
      "--- 라벨별 지표 ---\n",
      "anger - Precision: 0.3747, Recall: 0.6405, F1-Score: 0.4728\n",
      "disgust - Precision: 0.3596, Recall: 0.2602, F1-Score: 0.3019\n",
      "fear - Precision: 0.4333, Recall: 0.5306, F1-Score: 0.4771\n",
      "joy - Precision: 0.7113, Recall: 0.6991, F1-Score: 0.7052\n",
      "sadness - Precision: 0.3642, Recall: 0.4776, F1-Score: 0.4132\n",
      "surprise - Precision: 0.3851, Recall: 0.5894, F1-Score: 0.4658\n",
      "neutral - Precision: 0.6511, Recall: 0.1712, F1-Score: 0.2712\n",
      "\n",
      "Precision (Macro) 표준편차: 0.1373\n",
      "Recall (Macro) 표준편차: 0.1820\n",
      "F1-Score (Macro) 표준편차: 0.1318\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "ek_result = []\n",
    "json_res = []\n",
    "for l in batch_res[0].text.split('\\n')[:-1]:\n",
    "    json_res.append(json.loads(l))\n",
    "emotion_res = []\n",
    "\n",
    "for l in json_res:\n",
    "    tmp = []\n",
    "    n = json.loads(l['response']['body']['output'][0]['content'][0]['text'])\n",
    "\n",
    "    for m in n['analysis']:\n",
    "        tmp.append(m['emotion'])\n",
    "\n",
    "    emotion_res.append(tmp)\n",
    "e = evaluation(data, emotion_res)\n",
    "ek = evaluation_ekman(data, emotion_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7807a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame(result, columns=['shots', 'temperature', 'top_p', 'accuracy', 'micro f1', 'macro f1'])\n",
    "ek_res_df = pd.DataFrame(ek_result, columns=['shots', 'temperature', 'top_p', 'accuracy', 'micro f1', 'macro f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c98c13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shots</th>\n",
       "      <th>temperature</th>\n",
       "      <th>top_p</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>micro f1</th>\n",
       "      <th>macro f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>0.514981</td>\n",
       "      <td>0.451085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4540</td>\n",
       "      <td>0.513741</td>\n",
       "      <td>0.454304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4468</td>\n",
       "      <td>0.508494</td>\n",
       "      <td>0.446688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.4632</td>\n",
       "      <td>0.517222</td>\n",
       "      <td>0.455611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4632</td>\n",
       "      <td>0.516956</td>\n",
       "      <td>0.454610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4588</td>\n",
       "      <td>0.513371</td>\n",
       "      <td>0.445528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.4576</td>\n",
       "      <td>0.518671</td>\n",
       "      <td>0.460754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4616</td>\n",
       "      <td>0.521414</td>\n",
       "      <td>0.461851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4528</td>\n",
       "      <td>0.515418</td>\n",
       "      <td>0.451373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.4640</td>\n",
       "      <td>0.520496</td>\n",
       "      <td>0.456994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4600</td>\n",
       "      <td>0.516541</td>\n",
       "      <td>0.458164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4648</td>\n",
       "      <td>0.522180</td>\n",
       "      <td>0.464869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.4668</td>\n",
       "      <td>0.522343</td>\n",
       "      <td>0.458154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.4648</td>\n",
       "      <td>0.519549</td>\n",
       "      <td>0.457200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.4644</td>\n",
       "      <td>0.519895</td>\n",
       "      <td>0.453259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    shots  temperature  top_p  accuracy  micro f1  macro f1\n",
       "0       4         0.25   0.75    0.4564  0.514981  0.451085\n",
       "1       4         0.00   0.25    0.4540  0.513741  0.454304\n",
       "2       4         0.50   1.00    0.4468  0.508494  0.446688\n",
       "3       8         0.25   0.75    0.4632  0.517222  0.455611\n",
       "4       8         0.00   0.25    0.4632  0.516956  0.454610\n",
       "5       8         0.50   1.00    0.4588  0.513371  0.445528\n",
       "6      12         0.25   0.75    0.4576  0.518671  0.460754\n",
       "7      12         0.00   0.25    0.4616  0.521414  0.461851\n",
       "8      12         0.50   1.00    0.4528  0.515418  0.451373\n",
       "9      16         0.25   0.75    0.4640  0.520496  0.456994\n",
       "10     16         0.00   0.25    0.4600  0.516541  0.458164\n",
       "11     16         0.50   1.00    0.4648  0.522180  0.464869\n",
       "12     20         0.25   0.75    0.4668  0.522343  0.458154\n",
       "13     20         0.00   0.25    0.4648  0.519549  0.457200\n",
       "14     20         0.50   1.00    0.4644  0.519895  0.453259"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ek_res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "04e527eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_init()\n",
    "test_dataset = data.drop(columns=['text'])\n",
    "emotion_count = {}\n",
    "for i in test_dataset.to_numpy():\n",
    "    if sum(i) > 1:\n",
    "        tmp = []\n",
    "        for j in range(28):\n",
    "            if i[j] == 1:\n",
    "                tmp.append(j)\n",
    "        ttmp = tuple(tmp)\n",
    "        if ttmp in emotion_count:\n",
    "            emotion_count[ttmp] += 1\n",
    "        else:\n",
    "            emotion_count[ttmp] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "00e8e489",
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_res = sorted(emotion_count.items(), key=lambda x : x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "56dd7c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268\n"
     ]
    }
   ],
   "source": [
    "print(len(emotion_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e0532776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((2, 3), 46)\n",
      "((0, 15), 30)\n",
      "((0, 4), 24)\n",
      "((3, 10), 21)\n",
      "((0, 18), 17)\n",
      "((6, 7), 14)\n",
      "((3, 9), 12)\n",
      "((9, 25), 12)\n",
      "((0, 17), 11)\n",
      "((1, 17), 11)\n",
      "((13, 17), 9)\n",
      "((4, 20), 9)\n",
      "((0, 20), 9)\n",
      "((15, 20), 9)\n",
      "((15, 18), 9)\n",
      "((4, 5), 8)\n",
      "((24, 25), 7)\n",
      "((1, 10), 7)\n",
      "((0, 7), 7)\n",
      "((1, 15), 7)\n",
      "((1, 4), 6)\n",
      "((9, 10), 6)\n",
      "((4, 7), 6)\n",
      "((14, 19), 6)\n",
      "((1, 18), 6)\n",
      "((1, 20), 5)\n",
      "((18, 20), 5)\n",
      "((0, 1), 5)\n",
      "((2, 11), 5)\n",
      "((4, 22), 5)\n",
      "((1, 7), 5)\n",
      "((20, 25), 5)\n",
      "((3, 11), 5)\n",
      "((10, 11), 5)\n",
      "((4, 17), 5)\n",
      "((8, 20), 5)\n",
      "((4, 23), 5)\n",
      "((4, 15), 5)\n",
      "((5, 24), 4)\n",
      "((9, 22), 4)\n",
      "((2, 9), 4)\n",
      "((4, 13), 4)\n",
      "((10, 20), 4)\n",
      "((15, 26), 4)\n",
      "((6, 26), 4)\n",
      "((5, 20), 4)\n",
      "((1, 6), 4)\n",
      "((3, 7), 4)\n",
      "((7, 13), 4)\n",
      "((1, 13), 4)\n",
      "((1, 22), 4)\n",
      "((15, 17), 4)\n",
      "((0, 25), 3)\n",
      "((0, 9), 3)\n",
      "((0, 8), 3)\n",
      "((5, 10), 3)\n",
      "((4, 21), 3)\n",
      "((17, 20), 3)\n",
      "((9, 12), 3)\n",
      "((9, 26), 3)\n",
      "((2, 18), 3)\n",
      "((0, 22), 3)\n",
      "((4, 8), 3)\n",
      "((1, 3), 3)\n",
      "((2, 15), 3)\n",
      "((10, 18), 3)\n",
      "((5, 6), 3)\n",
      "((3, 25), 3)\n",
      "((0, 26), 3)\n",
      "((5, 25), 3)\n",
      "((17, 18), 3)\n",
      "((13, 18), 3)\n",
      "((5, 18), 3)\n",
      "((12, 22), 2)\n",
      "((7, 24), 2)\n",
      "((3, 4), 2)\n",
      "((2, 10), 2)\n",
      "((11, 12), 2)\n",
      "((7, 15), 2)\n",
      "((4, 6, 7), 2)\n",
      "((0, 3), 2)\n",
      "((1, 11), 2)\n",
      "((4, 14), 2)\n",
      "((7, 26), 2)\n",
      "((17, 23), 2)\n",
      "((0, 4, 17), 2)\n",
      "((2, 26), 2)\n",
      "((20, 22), 2)\n",
      "((0, 13), 2)\n",
      "((11, 18), 2)\n",
      "((3, 6), 2)\n",
      "((0, 5), 2)\n",
      "((15, 22), 2)\n",
      "((11, 14), 2)\n",
      "((22, 24), 2)\n",
      "((11, 20), 2)\n",
      "((10, 26), 2)\n",
      "((0, 4, 18), 2)\n",
      "((17, 25), 2)\n",
      "((0, 10), 2)\n",
      "((1, 2), 2)\n",
      "((7, 18), 2)\n",
      "((15, 24), 2)\n",
      "((14, 25), 2)\n",
      "((8, 15), 2)\n",
      "((2, 4), 2)\n",
      "((5, 19), 2)\n",
      "((3, 15), 2)\n",
      "((1, 9), 2)\n",
      "((22, 25), 2)\n",
      "((3, 14), 2)\n",
      "((13, 25), 2)\n",
      "((18, 22), 2)\n",
      "((13, 26), 2)\n",
      "((0, 14), 2)\n",
      "((6, 22), 2)\n",
      "((3, 22), 2)\n",
      "((13, 20), 2)\n",
      "((1, 3, 25), 1)\n",
      "((1, 6, 7, 24), 1)\n",
      "((1, 10, 15), 1)\n",
      "((11, 26), 1)\n",
      "((12, 26), 1)\n",
      "((1, 5), 1)\n",
      "((13, 17, 21), 1)\n",
      "((1, 26), 1)\n",
      "((7, 8), 1)\n",
      "((7, 19), 1)\n",
      "((10, 15), 1)\n",
      "((0, 5, 20), 1)\n",
      "((3, 9, 25), 1)\n",
      "((14, 22), 1)\n",
      "((16, 18), 1)\n",
      "((16, 24, 25), 1)\n",
      "((17, 24), 1)\n",
      "((13, 15, 26), 1)\n",
      "((3, 5, 22), 1)\n",
      "((2, 25), 1)\n",
      "((0, 20, 24), 1)\n",
      "((7, 11, 25), 1)\n",
      "((8, 18), 1)\n",
      "((19, 20), 1)\n",
      "((4, 24), 1)\n",
      "((3, 9, 16), 1)\n",
      "((5, 24, 25), 1)\n",
      "((14, 26), 1)\n",
      "((22, 26), 1)\n",
      "((10, 25), 1)\n",
      "((15, 23), 1)\n",
      "((0, 9, 10), 1)\n",
      "((0, 9, 15), 1)\n",
      "((3, 6, 18), 1)\n",
      "((1, 4, 13, 17), 1)\n",
      "((0, 2, 18), 1)\n",
      "((4, 17, 22, 23), 1)\n",
      "((0, 11), 1)\n",
      "((9, 18), 1)\n",
      "((0, 16, 25), 1)\n",
      "((8, 16), 1)\n",
      "((9, 14), 1)\n",
      "((17, 22), 1)\n",
      "((20, 21), 1)\n",
      "((2, 9, 22), 1)\n",
      "((3, 26), 1)\n",
      "((5, 11), 1)\n",
      "((1, 3, 18), 1)\n",
      "((4, 15, 17), 1)\n",
      "((4, 18), 1)\n",
      "((15, 19), 1)\n",
      "((14, 18), 1)\n",
      "((14, 20), 1)\n",
      "((2, 6, 22), 1)\n",
      "((15, 22, 26), 1)\n",
      "((15, 20, 22), 1)\n",
      "((12, 24), 1)\n",
      "((0, 1, 9), 1)\n",
      "((12, 15), 1)\n",
      "((1, 15, 18), 1)\n",
      "((9, 11, 14), 1)\n",
      "((10, 23), 1)\n",
      "((10, 24), 1)\n",
      "((8, 25), 1)\n",
      "((2, 8), 1)\n",
      "((4, 9, 20), 1)\n",
      "((2, 8, 18), 1)\n",
      "((0, 13, 20), 1)\n",
      "((10, 22), 1)\n",
      "((6, 9), 1)\n",
      "((0, 18, 26), 1)\n",
      "((4, 25), 1)\n",
      "((4, 8, 20), 1)\n",
      "((13, 15), 1)\n",
      "((0, 11, 14), 1)\n",
      "((5, 9), 1)\n",
      "((8, 18, 25), 1)\n",
      "((0, 13, 18, 20), 1)\n",
      "((2, 22), 1)\n",
      "((3, 6, 7), 1)\n",
      "((6, 14, 26), 1)\n",
      "((3, 18), 1)\n",
      "((0, 17, 18), 1)\n",
      "((2, 3, 10), 1)\n",
      "((7, 10), 1)\n",
      "((11, 25), 1)\n",
      "((7, 20), 1)\n",
      "((4, 5, 7), 1)\n",
      "((11, 24), 1)\n",
      "((4, 14, 18), 1)\n",
      "((19, 25), 1)\n",
      "((11, 14, 20), 1)\n",
      "((7, 25), 1)\n",
      "((5, 14), 1)\n",
      "((5, 8, 20, 25), 1)\n",
      "((5, 15), 1)\n",
      "((3, 12), 1)\n",
      "((2, 20), 1)\n",
      "((3, 9, 14), 1)\n",
      "((8, 22), 1)\n",
      "((5, 20, 24), 1)\n",
      "((1, 5, 18), 1)\n",
      "((4, 26), 1)\n",
      "((7, 17), 1)\n",
      "((13, 17, 18, 20), 1)\n",
      "((0, 6), 1)\n",
      "((0, 4, 20), 1)\n",
      "((16, 25), 1)\n",
      "((7, 11), 1)\n",
      "((5, 8), 1)\n",
      "((4, 9), 1)\n",
      "((6, 20), 1)\n",
      "((0, 8, 20), 1)\n",
      "((15, 21), 1)\n",
      "((7, 22), 1)\n",
      "((2, 7), 1)\n",
      "((5, 9, 24), 1)\n",
      "((4, 12), 1)\n",
      "((0, 4, 9), 1)\n",
      "((0, 13, 15, 26), 1)\n",
      "((0, 17, 22), 1)\n",
      "704\n"
     ]
    }
   ],
   "source": [
    "s = 0\n",
    "for i in emotion_res:\n",
    "    if 27 not in i[0]:\n",
    "        print(i)\n",
    "        s += i[1]\n",
    "           \n",
    "print(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "goemotions",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
